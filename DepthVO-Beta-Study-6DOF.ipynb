{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Robotics Toolbox for Python\n",
      "Based on Matlab Toolbox Version 7  April-2002\n",
      "\n",
      "What's new.\n",
      "  Readme      - New features and enhancements in this version.\n",
      "\n",
      "Homogeneous transformations\n",
      "  eul2tr      - Euler angle to transform \n",
      "  oa2tr       - orientation and approach vector to transform \n",
      "  rotx        - transform for rotation about X-axis \n",
      "  roty        - transform for rotation about Y-axis \n",
      "  rotz        - transform for rotation about Z-axis \n",
      "  rpy2tr      - roll/pitch/yaw angles to transform \n",
      "  tr2eul      - transform to Euler angles \n",
      "  tr2rot      - transform to rotation submatrix\n",
      "  tr2rpy      - transform to roll/pitch/yaw angles\n",
      "  transl      - set or extract the translational component of a transform \n",
      "  trnorm      - normalize a transform \n",
      "  \n",
      "Quaternions\n",
      "  /           - divide quaternion by quaternion or scalar\n",
      "  *           - multiply quaternion by a quaternion or vector\n",
      "  inv         - invert a quaternion \n",
      "  norm        - norm of a quaternion \n",
      "  plot        - display a quaternion as a 3D rotation\n",
      "  qinterp     - interpolate quaternions\n",
      "  unit        - unitize a quaternion \n",
      "\n",
      "Kinematics\n",
      "  diff2tr     - differential motion vector to transform \n",
      "  fkine       - compute forward kinematics \n",
      "  ikine       - compute inverse kinematics \n",
      "  ikine560    - compute inverse kinematics for Puma 560 like arm\n",
      "  jacob0      - compute Jacobian in base coordinate frame\n",
      "  jacobn      - compute Jacobian in end-effector coordinate frame\n",
      "  tr2diff     - transform to differential motion vector \n",
      "  tr2jac      - transform to Jacobian \n",
      "  \n",
      "Dynamics\n",
      "  accel       - compute forward dynamics\n",
      "  cinertia    - compute Cartesian manipulator inertia matrix \n",
      "  coriolis    - compute centripetal/coriolis torque \n",
      "  friction    - joint friction\n",
      "  ftrans      - transform force/moment \n",
      "  gravload    - compute gravity loading \n",
      "  inertia     - compute manipulator inertia matrix \n",
      "  itorque     - compute inertia torque \n",
      "  nofriction  - remove friction from a robot object \n",
      "  rne         - inverse dynamics \n",
      "  \n",
      "Trajectory generation\n",
      "  ctraj       - Cartesian trajectory \n",
      "  jtraj       - joint space trajectory \n",
      "  trinterp    - interpolate transform s\n",
      "  \n",
      "Graphics\n",
      "  drivebot    - drive a graphical  robot \n",
      "  plot        - plot/animate robot \n",
      "  \n",
      "Other\n",
      "  manipblty   - compute manipulability \n",
      "  unit        - unitize a vector\n",
      "\n",
      "Creation of robot models.\n",
      "  link        - construct a robot link object \n",
      "  puma560     - Puma 560 data \n",
      "  puma560akb  - Puma 560 data (modified Denavit-Hartenberg)\n",
      "  robot       - construct a robot object \n",
      "  stanford    - Stanford arm data \n",
      "  twolink     - simple 2-link example \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "from resizeimage import resizeimage\n",
    "from PIL import Image\n",
    "\n",
    "# from objectives.VoObjectives import rmse, vo_loss\n",
    "from models.AbstractModel import AbstractModel\n",
    "from dataset.DataGenerationStrategy import OpticalFlowGenerationStrategy\n",
    "from dataset.Sequence import Sequence\n",
    "import robot as rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_dir = 'D:/KITTI/dataset/'\n",
    "\n",
    "kitti_train_dirs = ['00', '01', '02', '03', '04', '05', '06', '07']\n",
    "kitti_test_dirs = ['08', '09', '10']\n",
    "\n",
    "input_width = 155\n",
    "input_height = 47\n",
    "\n",
    "#input_width = 310\n",
    "#input_height = 94\n",
    "\n",
    "input_channel = 1\n",
    "kitti_is_grayscale = True\n",
    "\n",
    "training_seqs = OrderedDict()\n",
    "test_seqs = OrderedDict()\n",
    "\n",
    "name = 'kitti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "\n",
    "        subdir = 'disparity'\n",
    "\n",
    "        \n",
    "        for dir in kitti_train_dirs:\n",
    "            seq_dir = os.path.normpath(os.path.join(data_set_dir, subdir, dir))\n",
    "            training_seqs[dir] = Sequence(seq_dir,\n",
    "                                               extension='png',\n",
    "                                               label_file=os.path.join(seq_dir, dir  + '.txt'),\n",
    "                                               dir=dir,\n",
    "                                               is_grayscale=kitti_is_grayscale,\n",
    "                                               name='Kitti_train/' + dir)\n",
    "\n",
    "        for dir in kitti_test_dirs:\n",
    "            seq_dir = os.path.normpath(os.path.join(data_set_dir, subdir, dir))\n",
    "            print(dir)\n",
    "            \n",
    "            print(os.path.join(seq_dir, subdir))\n",
    "            test_seqs[dir] = Sequence(seq_dir,\n",
    "                                           extension='png',\n",
    "                                           label_file=os.path.join(seq_dir, dir  + '.txt'),\n",
    "                                           dir=dir,\n",
    "                                           is_grayscale=kitti_is_grayscale,\n",
    "                                           name='Kitti_test/' + dir)\n",
    "            \n",
    "def print_info():\n",
    "\n",
    "        print('--------------------------')\n",
    "        print('------Dataset Info--------')\n",
    "        print('Dataset Name: {}'.format(name))\n",
    "        print('Number of Training dirs: {}'.format(len(training_seqs)))\n",
    "        print('Training dirs:')\n",
    "        for directory in training_seqs:\n",
    "            curr_sequence = training_seqs[directory]\n",
    "            print(directory,\n",
    "                  curr_sequence.sequence_dir,\n",
    "                  'Num imgs: {}'.format(curr_sequence.get_num_imgs()),\n",
    "                  'Num label: {}'.format(curr_sequence.get_num_label()))\n",
    "\n",
    "        print('Number of Test dirs: {}'.format(len(test_seqs)))\n",
    "        print('Test dirs:')\n",
    "        for directory in test_seqs:\n",
    "            curr_sequence = test_seqs[directory]\n",
    "            print(directory,\n",
    "                  curr_sequence.sequence_dir,\n",
    "                  'Num imgs: {}'.format(curr_sequence.get_num_imgs()),\n",
    "    'Num label: {}'.format(curr_sequence.get_num_label()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08\n",
      "D:\\KITTI\\dataset\\disparity\\08\\disparity\n",
      "09\n",
      "D:\\KITTI\\dataset\\disparity\\09\\disparity\n",
      "10\n",
      "D:\\KITTI\\dataset\\disparity\\10\\disparity\n",
      "--------------------------\n",
      "------Dataset Info--------\n",
      "Dataset Name: kitti\n",
      "Number of Training dirs: 8\n",
      "Training dirs:\n",
      "00 D:\\KITTI\\dataset\\disparity\\00 Num imgs: 4541 Num label: 4541\n",
      "01 D:\\KITTI\\dataset\\disparity\\01 Num imgs: 1101 Num label: 1101\n",
      "02 D:\\KITTI\\dataset\\disparity\\02 Num imgs: 4661 Num label: 4661\n",
      "03 D:\\KITTI\\dataset\\disparity\\03 Num imgs: 801 Num label: 801\n",
      "04 D:\\KITTI\\dataset\\disparity\\04 Num imgs: 271 Num label: 271\n",
      "05 D:\\KITTI\\dataset\\disparity\\05 Num imgs: 2761 Num label: 2761\n",
      "06 D:\\KITTI\\dataset\\disparity\\06 Num imgs: 1101 Num label: 1101\n",
      "07 D:\\KITTI\\dataset\\disparity\\07 Num imgs: 1101 Num label: 1101\n",
      "Number of Test dirs: 3\n",
      "Test dirs:\n",
      "08 D:\\KITTI\\dataset\\disparity\\08 Num imgs: 4071 Num label: 4071\n",
      "09 D:\\KITTI\\dataset\\disparity\\09 Num imgs: 1591 Num label: 1591\n",
      "10 D:\\KITTI\\dataset\\disparity\\10 Num imgs: 1201 Num label: 1201\n"
     ]
    }
   ],
   "source": [
    "read_data()\n",
    "print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform training pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "{'00', '04', '06', '07', '02', '03', '01', '05'}\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "label_training_all = {}\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "        \n",
    "        t_aux = matrix[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(matrix)\n",
    "        label_aux.append(np.concatenate((rpy, t),1))\n",
    "        \n",
    "    label_training_all[name] = label_aux[1:]\n",
    "\n",
    "print(len(label_training_all))\n",
    "print(set(label_training_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sequence 07: 1100\n",
      "Size of sequence 04: 270\n",
      "Size of sequence 02: 4660\n",
      "Size of sequence 03: 800\n",
      "Size of sequence 06: 1100\n",
      "Size of sequence 00: 4540\n",
      "Size of sequence 01: 1100\n",
      "Size of sequence 05: 2760\n"
     ]
    }
   ],
   "source": [
    "for element in label_training_all:\n",
    "    print(\"Size of sequence %s: %s\"%(element, len(label_training_all[element])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read and normalize training images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:  00\n",
      "List length:  4541\n",
      "Right list length:  4540\n",
      "Left list length:  4540\n",
      "\n",
      "Sequence:  01\n",
      "List length:  1101\n",
      "Right list length:  1100\n",
      "Left list length:  1100\n",
      "\n",
      "Sequence:  02\n",
      "List length:  4661\n",
      "Right list length:  4660\n",
      "Left list length:  4660\n",
      "\n",
      "Sequence:  03\n",
      "List length:  801\n",
      "Right list length:  800\n",
      "Left list length:  800\n",
      "\n",
      "Sequence:  04\n",
      "List length:  271\n",
      "Right list length:  270\n",
      "Left list length:  270\n",
      "\n",
      "Sequence:  05\n",
      "List length:  2761\n",
      "Right list length:  2760\n",
      "Left list length:  2760\n",
      "\n",
      "Sequence:  06\n",
      "List length:  1101\n",
      "Right list length:  1100\n",
      "Left list length:  1100\n",
      "\n",
      "Sequence:  07\n",
      "List length:  1101\n",
      "Right list length:  1100\n",
      "Left list length:  1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_training_all_l = {}\n",
    "dataset_training_all_r = {}\n",
    "\n",
    "for directory in training_seqs:\n",
    "    curr_sequence = training_seqs[directory]\n",
    "    paths = curr_sequence.get_image_paths()\n",
    "    name = curr_sequence.get_dir()\n",
    "    num_images = curr_sequence.get_num_imgs()\n",
    "    img_aux = []\n",
    "    cont = 0\n",
    "    print(\"Sequence: \", name)    \n",
    "    for path in paths:\n",
    "        img = Image.open(path)        \n",
    "        img = img.resize((input_width, input_height))\n",
    "        \n",
    "        img_new = np.array(img.getdata()).reshape(img.size[1], img.size[0])\n",
    "        img_new = img_new / 255.0        \n",
    "        img_aux.append(img_new)\n",
    "        \n",
    "        del(img_new)\n",
    "        del(img)\n",
    "\n",
    "        print(\"%s \\r\"%cont, end=\"\", flush=True)    \n",
    "        cont += 1\n",
    "        \n",
    "    print(\"List length: \", len(img_aux))\n",
    "    print(\"Right list length: \", len(img_aux[1:]))\n",
    "    print(\"Left list length: \", len(img_aux[:-1]))\n",
    "    print(\"\")\n",
    "    \n",
    "    dataset_training_all_r[name] = img_aux[1:]\n",
    "    dataset_training_all_l[name] = img_aux[:-1]\n",
    "    \n",
    "    del(img_aux)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training right: \n",
      "8\n",
      "{'00', '04', '06', '07', '02', '03', '01', '05'}\n",
      "Sequence 07: Size = 1100 and dim = (47, 155).\n",
      "Sequence 04: Size = 270 and dim = (47, 155).\n",
      "Sequence 02: Size = 4660 and dim = (47, 155).\n",
      "Sequence 03: Size = 800 and dim = (47, 155).\n",
      "Sequence 06: Size = 1100 and dim = (47, 155).\n",
      "Sequence 00: Size = 4540 and dim = (47, 155).\n",
      "Sequence 01: Size = 1100 and dim = (47, 155).\n",
      "Sequence 05: Size = 2760 and dim = (47, 155).\n",
      " \n",
      "Training left: \n",
      "8\n",
      "{'00', '04', '06', '07', '02', '03', '01', '05'}\n",
      "Sequence 07: Size = 1100 and dim = (47, 155).\n",
      "Sequence 04: Size = 270 and dim = (47, 155).\n",
      "Sequence 02: Size = 4660 and dim = (47, 155).\n",
      "Sequence 03: Size = 800 and dim = (47, 155).\n",
      "Sequence 06: Size = 1100 and dim = (47, 155).\n",
      "Sequence 00: Size = 4540 and dim = (47, 155).\n",
      "Sequence 01: Size = 1100 and dim = (47, 155).\n",
      "Sequence 05: Size = 2760 and dim = (47, 155).\n"
     ]
    }
   ],
   "source": [
    "print(\"Training right: \")\n",
    "print(len(dataset_training_all_r))\n",
    "print(set(dataset_training_all_r))\n",
    "\n",
    "for element in dataset_training_all_r:\n",
    "    img = dataset_training_all_r[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_training_all_r[element]), \n",
    "                                                  np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))\n",
    "    \n",
    "print(\" \")\n",
    "print(\"Training left: \")\n",
    "\n",
    "print(len(dataset_training_all_l))\n",
    "print(set(dataset_training_all_l))\n",
    "\n",
    "for element in dataset_training_all_l:\n",
    "    img = dataset_training_all_l[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_training_all_l[element]), \n",
    "                                                  np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and test pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'10', '09', '08'}\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "label_test_all = {}\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "        \n",
    "        t_aux = matrix[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(matrix)\n",
    "        label_aux.append(np.concatenate((rpy, t),1))\n",
    "        \n",
    "    label_test_all[name] = label_aux[1:]\n",
    "\n",
    "print(len(label_test_all))\n",
    "print(set(label_test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sequence 10: 1200\n",
      "Size of sequence 09: 1590\n",
      "Size of sequence 08: 4070\n"
     ]
    }
   ],
   "source": [
    "for element in label_test_all:\n",
    "    print(\"Size of sequence %s: %s\"%(element, len(label_test_all[element])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read and normalize test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:  08\n",
      "List length:  4071\n",
      "Right list length:  4070\n",
      "Left list length:  4070\n",
      "\n",
      "Sequence:  09\n",
      "List length:  1591\n",
      "Right list length:  1590\n",
      "Left list length:  1590\n",
      "\n",
      "Sequence:  10\n",
      "List length:  1201\n",
      "Right list length:  1200\n",
      "Left list length:  1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_test_all_r = {}\n",
    "dataset_test_all_l = {}\n",
    "\n",
    "for directory in test_seqs:\n",
    "    curr_sequence = test_seqs[directory]\n",
    "    paths = curr_sequence.get_image_paths()\n",
    "    name = curr_sequence.get_dir()\n",
    "    num_images = curr_sequence.get_num_imgs()\n",
    "    img_aux = []\n",
    "    cont = 0\n",
    "    print(\"Sequence: \", name)\n",
    "    \n",
    "    for path in paths:\n",
    "        img = Image.open(path)        \n",
    "        img = img.resize((input_width, input_height))\n",
    "        \n",
    "        img_new = np.array(img.getdata()).reshape(img.size[1], img.size[0])\n",
    "        img_new = img_new / 255.0        \n",
    "        img_aux.append(img_new)\n",
    "        \n",
    "        del(img_new)\n",
    "        del(img)\n",
    "        percentage = round((cont/num_images)*100,2)\n",
    "        \n",
    "        print(\"%s \\r\"%cont, end=\"\", flush=True)    \n",
    "        cont += 1\n",
    "        \n",
    "    print(\"List length: \", len(img_aux))\n",
    "    print(\"Right list length: \", len(img_aux[1:]))\n",
    "    print(\"Left list length: \", len(img_aux[:-1]))\n",
    "    print(\"\")\n",
    "    \n",
    "    dataset_test_all_r[name] = img_aux[1:]\n",
    "    dataset_test_all_l[name] = img_aux[:-1]\n",
    "    \n",
    "    del(img_aux)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test right: \n",
      "3\n",
      "{'10', '09', '08'}\n",
      "Sequence 10: Size = 1200 and dim = (47, 155).\n",
      "Sequence 09: Size = 1590 and dim = (47, 155).\n",
      "Sequence 08: Size = 4070 and dim = (47, 155).\n",
      " \n",
      "Test left: \n",
      "3\n",
      "{'10', '09', '08'}\n",
      "Sequence 10: Size = 1200 and dim = (47, 155).\n",
      "Sequence 09: Size = 1590 and dim = (47, 155).\n",
      "Sequence 08: Size = 4070 and dim = (47, 155).\n"
     ]
    }
   ],
   "source": [
    "print(\"Test right: \")\n",
    "print(len(dataset_test_all_r))\n",
    "print(set(dataset_test_all_r))\n",
    "\n",
    "for element in dataset_test_all_r:\n",
    "    img = dataset_test_all_r[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_test_all_r[element]), np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))\n",
    "          \n",
    "print(\" \")\n",
    "print(\"Test left: \")\n",
    "\n",
    "print(len(dataset_test_all_l))\n",
    "print(set(dataset_test_all_l))\n",
    "\n",
    "for element in dataset_test_all_l:\n",
    "    img = dataset_test_all_l[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_test_all_l[element]), np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training > size right: 16330, size left: 16330, size label: 16330\n",
      " \n",
      "Test > Size right: 6860, size left: 6860, size label: 6860\n",
      " \n"
     ]
    }
   ],
   "source": [
    "training_r = []\n",
    "training_l = []\n",
    "training_poses = []\n",
    "\n",
    "test_r = []\n",
    "test_l = []\n",
    "test_poses = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    for img in dataset_training_all_r[sequence]:\n",
    "        training_r.append(img)        \n",
    "    for img in dataset_training_all_l[sequence]:\n",
    "        training_l.append(img)   \n",
    "    for pose in label_training_all[sequence]:\n",
    "        training_poses.append(pose)\n",
    "\n",
    "print(\"Training > size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(training_r), len(training_l), len(training_poses)))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for img in dataset_test_all_r[sequence]:\n",
    "            test_r.append(img)        \n",
    "        for img in dataset_test_all_l[sequence]:\n",
    "            test_l.append(img)   \n",
    "        for pose in label_test_all[sequence]:\n",
    "            test_poses.append(pose)\n",
    "            \n",
    "print(\"Test > Size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(test_r), len(test_l), len(test_poses)))\n",
    "\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 47, 155, 1)\n",
      "(6860, 47, 155, 1)\n"
     ]
    }
   ],
   "source": [
    "training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "print(np.shape(training_r))\n",
    "\n",
    "test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "print(np.shape(test_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6DOF Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_training_0 = {}\n",
    "label_training_1 = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "    label_training_0[name] = label_aux[:-1]\n",
    "    label_training_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_train = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_training_0[name], label_training_1[name]):\n",
    "        transformation = pose_0.dot(np.linalg.inv(pose_1))\n",
    "        t_aux = transformation[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(transformation)\n",
    "        \n",
    "        T_aux.append(np.concatenate((rpy, t),1))\n",
    "    \n",
    "        T_train[name] = T_aux    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training > size right: 16330, size left: 16330, size label: 16330\n"
     ]
    }
   ],
   "source": [
    "training_poses_transformed = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "  \n",
    "    for pose in T_train[sequence]:\n",
    "        training_poses_transformed.append(pose)\n",
    "\n",
    "print(\"Training > size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(training_r), len(training_l), len(training_poses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_test_0 = {}\n",
    "label_test_1 = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_test_0[name] = label_aux[:-1]\n",
    "    label_test_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_test = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_test_0[name], label_test_1[name]):\n",
    "        transformation = pose_0.dot(np.linalg.inv(pose_1))\n",
    "        t_aux = transformation[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(transformation)\n",
    "        \n",
    "        T_aux.append(np.concatenate((rpy, t),1))\n",
    "    \n",
    "    T_test[name] = T_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test > Size right: 6860, size left: 6860, size label: 6860\n"
     ]
    }
   ],
   "source": [
    "test_poses_transformed = []\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for pose in T_test[sequence]:\n",
    "            test_poses_transformed.append(pose)\n",
    "    \n",
    "print(\"Test > Size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(test_r), len(test_l), len(test_poses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 6)\n"
     ]
    }
   ],
   "source": [
    "y_training = np.reshape(training_poses_transformed, (len(training_poses), 6))\n",
    "y_test = np.reshape(test_poses_transformed, (len(test_poses), 6))\n",
    "print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform training pose (of thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_training_thesis_0 = {}\n",
    "label_training_thesis_1 = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_training_thesis_0[name] = label_aux[:-1]\n",
    "    label_training_thesis_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540\n",
      "1100\n",
      "4660\n",
      "800\n",
      "270\n",
      "2760\n",
      "1100\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "from math import asin, atan2, sqrt\n",
    "\n",
    "T_train_thesis = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_training_thesis_0[name], label_training_thesis_1[name]):\n",
    "        \n",
    "        Tx = pose_1[0][3]\n",
    "        Tz = pose_1[2][3]\n",
    "        Tx_ant = pose_0[0][3]\n",
    "        Tz_ant = pose_0[2][3]\n",
    "\n",
    "        Ri_1 = pose_1[0][0]\n",
    "        Ri_3 = pose_1[0][2]    \n",
    "        Ri_1_ant = pose_0[0][0]\n",
    "        Ri_3_ant = pose_0[0][2]\n",
    "        \n",
    "        Ti = [Tx, Tz]\n",
    "        Ti_ant = [Tx_ant, Tz_ant]\n",
    "\n",
    "        displacement = sqrt(sum([(a - b) ** 2 for a, b in zip(Ti, Ti_ant)]))\n",
    "        delta_Theta = atan2(Ri_3, Ri_1) - atan2(Ri_3_ant, Ri_1_ant)\n",
    "    \n",
    "        T_aux.append([delta_Theta, displacement])\n",
    "    \n",
    "    T_train_thesis[name] = T_aux\n",
    "    print(len(T_train_thesis[name]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform test pose (of thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_test_thesis_0 = {}\n",
    "label_test_thesis_1 = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_test_thesis_0[name] = label_aux[:-1]\n",
    "    label_test_thesis_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_test_thesis = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_test_thesis_0[name], label_test_thesis_1[name]):\n",
    "        \n",
    "        Tx = pose_1[0][3]\n",
    "        Tz = pose_1[2][3]\n",
    "        Tx_last = pose_0[0][3]\n",
    "        Tz_last = pose_0[2][3]\n",
    "\n",
    "        Ri_1 = pose_1[0][0]\n",
    "        Ri_3 = pose_1[0][2]    \n",
    "        Ri_1_last = pose_0[0][0]\n",
    "        Ri_3_last = pose_0[0][2]\n",
    "        \n",
    "        Ti = [Tx, Tz]\n",
    "        Ti_last = [Tx_last, Tz_last]\n",
    "\n",
    "        displacement = sqrt(sum([(a - b) ** 2 for a, b in zip(Ti, Ti_last)]))\n",
    "        delta_Theta = atan2(Ri_3, Ri_1) - atan2(Ri_3_last, Ri_1_last)\n",
    "    \n",
    "        T_aux.append([delta_Theta, displacement])\n",
    "    \n",
    "    T_test_thesis[name] = T_aux\n",
    "    # print(T_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_poses_transformed_thesis = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "  \n",
    "    for pose in T_train_thesis[sequence]:\n",
    "        training_poses_transformed_thesis.append(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_poses_transformed_thesis = []\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for pose in T_test_thesis[sequence]:\n",
    "            test_poses_transformed_thesis.append(pose)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 2)\n"
     ]
    }
   ],
   "source": [
    "y_training = np.reshape(training_poses_transformed_thesis, (len(training_poses_transformed_thesis), 2))\n",
    "y_test = np.reshape(test_poses_transformed_thesis, (len(test_poses_transformed_thesis), 2))\n",
    "print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16330.000000</td>\n",
       "      <td>16330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.020984</td>\n",
       "      <td>0.000355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.719510</td>\n",
       "      <td>0.017553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-18.706326</td>\n",
       "      <td>-0.074321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.369062</td>\n",
       "      <td>-0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.016105</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.346503</td>\n",
       "      <td>0.002380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.200720</td>\n",
       "      <td>0.083055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1\n",
       "count  16330.000000  16330.000000\n",
       "mean      -0.020984      0.000355\n",
       "std        2.719510      0.017553\n",
       "min      -18.706326     -0.074321\n",
       "25%       -1.369062     -0.002612\n",
       "50%       -0.016105      0.000084\n",
       "75%        1.346503      0.002380\n",
       "max       18.200720      0.083055"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_training_hacked = np.zeros((len(y_training), 2))\n",
    "y_training_hacked[:,0] = y_training[:,0]*950\n",
    "y_training_hacked[:,1] = y_training[:,1]\n",
    "\n",
    "y_test_hacked = np.zeros((len(y_test), 2))\n",
    "y_test_hacked[:,0] = y_test[:,0]*950\n",
    "y_test_hacked[:,1] = y_test[:,1]\n",
    "\n",
    "train_df = pd.DataFrame(y_training_hacked)\n",
    "test_df = pd.DataFrame(y_test_hacked)\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6860.000000</td>\n",
       "      <td>6860.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.015727</td>\n",
       "      <td>-0.002335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.688253</td>\n",
       "      <td>0.016444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-14.007403</td>\n",
       "      <td>-0.068335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.403611</td>\n",
       "      <td>-0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.056893</td>\n",
       "      <td>-0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.384160</td>\n",
       "      <td>0.002578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.702216</td>\n",
       "      <td>0.058259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1\n",
       "count  6860.000000  6860.000000\n",
       "mean     -0.015727    -0.002335\n",
       "std       2.688253     0.016444\n",
       "min     -14.007403    -0.068335\n",
       "25%      -1.403611    -0.004597\n",
       "50%      -0.056893    -0.000072\n",
       "75%       1.384160     0.002578\n",
       "max      24.702216     0.058259"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding network size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Definindo os valores de beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[950]\n"
     ]
    }
   ],
   "source": [
    "beta_list = []\n",
    "\n",
    "beta_list.append(950)\n",
    "#beta_aux = 150\n",
    "\n",
    "#while(beta_aux <= 2000):    \n",
    "#    beta_list.append(beta_aux)\n",
    "    \n",
    "#    beta_aux += 200\n",
    "    \n",
    "print(beta_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer)\n",
    "dense_layer1 = Dense(32)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer1)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 950.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            198         leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,222\n",
      "Trainable params: 5,165,222\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "#mean_squared_error\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "# model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 950.\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 13.7241 - rmse: 3.1445 - acc: 0.2453 - val_loss: 6.6910 - val_rmse: 1.7196 - val_acc: 0.2840\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.69098, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.24532, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 9.3922 - rmse: 2.7566 - acc: 0.3287 - val_loss: 6.2116 - val_rmse: 1.6799 - val_acc: 0.3239\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.69098 to 6.21159, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.24532 to 0.32866, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 7.1849 - rmse: 2.4255 - acc: 0.3729 - val_loss: 6.2688 - val_rmse: 1.7113 - val_acc: 0.3286\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00003: acc improved from 0.32866 to 0.37293, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 6.3402 - rmse: 2.2777 - acc: 0.3824 - val_loss: 6.3493 - val_rmse: 1.7169 - val_acc: 0.3251\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00004: acc improved from 0.37293 to 0.38242, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 5.5885 - rmse: 2.1449 - acc: 0.4013 - val_loss: 6.6472 - val_rmse: 1.7797 - val_acc: 0.3316\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00005: acc improved from 0.38242 to 0.40135, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 4.6940 - rmse: 1.9813 - acc: 0.4225 - val_loss: 8.0335 - val_rmse: 1.9341 - val_acc: 0.3462\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00006: acc improved from 0.40135 to 0.42247, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 3.9908 - rmse: 1.8341 - acc: 0.4355 - val_loss: 7.4568 - val_rmse: 1.8644 - val_acc: 0.3023\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00007: acc improved from 0.42247 to 0.43546, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 3.4684 - rmse: 1.7187 - acc: 0.4536 - val_loss: 7.5259 - val_rmse: 1.8885 - val_acc: 0.3450\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00008: acc improved from 0.43546 to 0.45358, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 2.9141 - rmse: 1.5975 - acc: 0.4641 - val_loss: 7.7079 - val_rmse: 1.8822 - val_acc: 0.3388\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00009: acc improved from 0.45358 to 0.46405, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 2.4102 - rmse: 1.4635 - acc: 0.4776 - val_loss: 7.4033 - val_rmse: 1.8809 - val_acc: 0.3439\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00010: acc improved from 0.46405 to 0.47759, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 2.0459 - rmse: 1.3508 - acc: 0.4980 - val_loss: 8.1855 - val_rmse: 1.9634 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00011: acc improved from 0.47759 to 0.49804, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 1.6555 - rmse: 1.2313 - acc: 0.5092 - val_loss: 7.7582 - val_rmse: 1.9070 - val_acc: 0.3357\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00012: acc improved from 0.49804 to 0.50925, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.5495 - rmse: 1.1844 - acc: 0.5166 - val_loss: 6.7135 - val_rmse: 1.7546 - val_acc: 0.3284\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00013: acc improved from 0.50925 to 0.51660, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.4187 - rmse: 1.1307 - acc: 0.5374 - val_loss: 8.3670 - val_rmse: 1.9648 - val_acc: 0.3187\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00014: acc improved from 0.51660 to 0.53735, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 1.1371 - rmse: 1.0223 - acc: 0.5489 - val_loss: 7.0799 - val_rmse: 1.8042 - val_acc: 0.3350\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00015: acc improved from 0.53735 to 0.54887, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 1.1378 - rmse: 1.0202 - acc: 0.5547 - val_loss: 7.4354 - val_rmse: 1.8404 - val_acc: 0.3187\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00016: acc improved from 0.54887 to 0.55475, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.9511 - rmse: 0.9372 - acc: 0.5694 - val_loss: 7.3692 - val_rmse: 1.8229 - val_acc: 0.3357\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00017: acc improved from 0.55475 to 0.56938, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.8727 - rmse: 0.8998 - acc: 0.5760 - val_loss: 6.9069 - val_rmse: 1.7979 - val_acc: 0.3321\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00018: acc improved from 0.56938 to 0.57600, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.8016 - rmse: 0.8578 - acc: 0.5933 - val_loss: 7.3415 - val_rmse: 1.8476 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00019: acc improved from 0.57600 to 0.59333, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.7385 - rmse: 0.8285 - acc: 0.5928 - val_loss: 7.3354 - val_rmse: 1.8312 - val_acc: 0.3313\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.59333\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.7186 - rmse: 0.8151 - acc: 0.6019 - val_loss: 7.1353 - val_rmse: 1.8068 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00021: acc improved from 0.59333 to 0.60190, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6444 - rmse: 0.7715 - acc: 0.6131 - val_loss: 7.8888 - val_rmse: 1.9381 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00022: acc improved from 0.60190 to 0.61310, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6252 - rmse: 0.7584 - acc: 0.6257 - val_loss: 6.8932 - val_rmse: 1.7844 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00023: acc improved from 0.61310 to 0.62566, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5747 - rmse: 0.7275 - acc: 0.6287 - val_loss: 7.2087 - val_rmse: 1.8397 - val_acc: 0.3424\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00024: acc improved from 0.62566 to 0.62866, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.5412 - rmse: 0.7037 - acc: 0.6412 - val_loss: 7.3224 - val_rmse: 1.8546 - val_acc: 0.3455\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 6.21159\n",
      "\n",
      "Epoch 00025: acc improved from 0.62866 to 0.64115, saving model to D:/KITTI/Graph/DepthVO-6DOF/model/950/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e00e138ba8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#beta =  beta_list[cont]\n",
    "#cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "#opt = optm.Adam(lr=learning_rate)\n",
    "#model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "#model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVO-6DOF/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVO-6DOF/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 350.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.4263 - rmse: 0.0632 - acc: 0.9994 - val_loss: 0.8106 - val_rmse: 0.1523 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81057, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.4209 - rmse: 0.0609 - acc: 0.9992 - val_loss: 0.8550 - val_rmse: 0.1710 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.81057\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.99939\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.4225 - rmse: 0.0638 - acc: 0.9993 - val_loss: 0.8107 - val_rmse: 0.1523 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.81057\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99939\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.4168 - rmse: 0.0613 - acc: 0.9993 - val_loss: 0.8109 - val_rmse: 0.1511 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.81057\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99939\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.4122 - rmse: 0.0611 - acc: 0.9992 - val_loss: 0.8080 - val_rmse: 0.1489 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.81057 to 0.80797, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99939\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.4135 - rmse: 0.0629 - acc: 0.9995 - val_loss: 0.8090 - val_rmse: 0.1512 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00006: acc improved from 0.99939 to 0.99951, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.4070 - rmse: 0.0605 - acc: 0.9994 - val_loss: 0.8099 - val_rmse: 0.1519 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99951\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4071 - rmse: 0.0648 - acc: 0.9996 - val_loss: 0.8080 - val_rmse: 0.1492 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00008: acc improved from 0.99951 to 0.99957, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3992 - rmse: 0.0618 - acc: 0.9993 - val_loss: 0.8230 - val_rmse: 0.1540 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99957\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3941 - rmse: 0.0634 - acc: 0.9996 - val_loss: 0.8239 - val_rmse: 0.1542 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99957\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3952 - rmse: 0.0653 - acc: 0.9993 - val_loss: 0.8334 - val_rmse: 0.1543 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99957\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3788 - rmse: 0.0608 - acc: 0.9991 - val_loss: 0.8252 - val_rmse: 0.1532 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99957\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3834 - rmse: 0.0672 - acc: 0.9993 - val_loss: 0.8303 - val_rmse: 0.1570 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99957\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3702 - rmse: 0.0654 - acc: 0.9989 - val_loss: 0.8261 - val_rmse: 0.1557 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99957\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3593 - rmse: 0.0599 - acc: 0.9987 - val_loss: 0.8366 - val_rmse: 0.1556 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99957\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3683 - rmse: 0.0677 - acc: 0.9989 - val_loss: 0.8290 - val_rmse: 0.1555 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99957\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3488 - rmse: 0.0644 - acc: 0.9985 - val_loss: 0.8670 - val_rmse: 0.1695 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99957\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3634 - rmse: 0.0751 - acc: 0.9987 - val_loss: 0.8324 - val_rmse: 0.1571 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99957\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3533 - rmse: 0.0682 - acc: 0.9993 - val_loss: 0.8792 - val_rmse: 0.1726 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99957\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3485 - rmse: 0.0679 - acc: 0.9991 - val_loss: 0.8506 - val_rmse: 0.1586 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99957\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3312 - rmse: 0.0668 - acc: 0.9985 - val_loss: 0.8427 - val_rmse: 0.1567 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99957\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3244 - rmse: 0.0631 - acc: 0.9992 - val_loss: 0.8358 - val_rmse: 0.1552 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99957\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3195 - rmse: 0.0627 - acc: 0.9990 - val_loss: 0.8420 - val_rmse: 0.1593 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99957\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3143 - rmse: 0.0617 - acc: 0.9981 - val_loss: 0.8572 - val_rmse: 0.1601 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99957\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3251 - rmse: 0.0679 - acc: 0.9985 - val_loss: 0.8444 - val_rmse: 0.1554 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.80797\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155a131b908>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 550.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3806 - rmse: 0.0626 - acc: 0.9988 - val_loss: 1.0385 - val_rmse: 0.1559 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03851, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/550/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99878, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/550/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3780 - rmse: 0.0656 - acc: 0.9993 - val_loss: 1.0851 - val_rmse: 0.1621 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00002: acc improved from 0.99878 to 0.99927, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/550/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3735 - rmse: 0.0679 - acc: 0.9989 - val_loss: 1.0740 - val_rmse: 0.1729 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99927\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3908 - rmse: 0.0717 - acc: 0.9992 - val_loss: 1.0962 - val_rmse: 0.1784 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99927\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3826 - rmse: 0.0758 - acc: 0.9991 - val_loss: 1.0394 - val_rmse: 0.1594 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99927\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3724 - rmse: 0.0673 - acc: 0.9988 - val_loss: 1.0713 - val_rmse: 0.1646 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99927\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3647 - rmse: 0.0705 - acc: 0.9993 - val_loss: 1.1941 - val_rmse: 0.1742 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99927\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3542 - rmse: 0.0652 - acc: 0.9991 - val_loss: 1.0465 - val_rmse: 0.1837 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99927\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3777 - rmse: 0.0699 - acc: 0.9988 - val_loss: 1.0925 - val_rmse: 0.1664 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99927\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3568 - rmse: 0.0707 - acc: 0.9989 - val_loss: 1.0533 - val_rmse: 0.1572 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99927\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3432 - rmse: 0.0668 - acc: 0.9990 - val_loss: 1.0969 - val_rmse: 0.1668 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99927\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3824 - rmse: 0.0849 - acc: 0.9995 - val_loss: 1.0434 - val_rmse: 0.1563 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.03851\n",
      "\n",
      "Epoch 00012: acc improved from 0.99927 to 0.99951, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/550/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3273 - rmse: 0.0624 - acc: 0.9991 - val_loss: 1.0284 - val_rmse: 0.1595 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.03851 to 1.02836, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/550/weights.best.hdf5\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99951\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3202 - rmse: 0.0645 - acc: 0.9984 - val_loss: 1.1637 - val_rmse: 0.1771 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99951\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3578 - rmse: 0.0770 - acc: 0.9991 - val_loss: 1.0706 - val_rmse: 0.1640 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99951\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3492 - rmse: 0.0815 - acc: 0.9992 - val_loss: 1.0876 - val_rmse: 0.1668 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99951\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3137 - rmse: 0.0678 - acc: 0.9996 - val_loss: 1.0587 - val_rmse: 0.1613 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00017: acc improved from 0.99951 to 0.99957, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/550/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3102 - rmse: 0.0648 - acc: 0.9993 - val_loss: 1.0609 - val_rmse: 0.1617 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99957\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2837 - rmse: 0.0660 - acc: 0.9986 - val_loss: 1.1647 - val_rmse: 0.1784 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99957\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2896 - rmse: 0.0660 - acc: 0.9991 - val_loss: 1.0588 - val_rmse: 0.1688 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99957\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3033 - rmse: 0.0739 - acc: 0.9990 - val_loss: 1.0710 - val_rmse: 0.1709 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99957\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2850 - rmse: 0.0658 - acc: 0.9996 - val_loss: 1.0534 - val_rmse: 0.1729 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99957\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2802 - rmse: 0.0673 - acc: 0.9993 - val_loss: 1.1134 - val_rmse: 0.1664 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99957\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2863 - rmse: 0.0705 - acc: 0.9992 - val_loss: 1.0859 - val_rmse: 0.1681 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99957\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2808 - rmse: 0.0652 - acc: 0.9996 - val_loss: 1.0823 - val_rmse: 0.1667 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.02836\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15709d16a90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 750.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2923 - rmse: 0.0611 - acc: 0.9987 - val_loss: 1.2577 - val_rmse: 0.1660 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.25768, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/750/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99871, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/750/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3178 - rmse: 0.0723 - acc: 0.9994 - val_loss: 1.1838 - val_rmse: 0.1600 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.25768 to 1.18377, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/750/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99871 to 0.99945, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/750/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3070 - rmse: 0.0803 - acc: 0.9994 - val_loss: 1.1980 - val_rmse: 0.1607 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99945\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2887 - rmse: 0.0636 - acc: 0.9996 - val_loss: 1.2563 - val_rmse: 0.1668 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00004: acc improved from 0.99945 to 0.99963, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/750/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2862 - rmse: 0.0687 - acc: 0.9994 - val_loss: 1.2359 - val_rmse: 0.1600 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99963\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3039 - rmse: 0.0661 - acc: 0.9996 - val_loss: 1.2370 - val_rmse: 0.1713 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99963\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2553 - rmse: 0.0608 - acc: 0.9992 - val_loss: 1.2112 - val_rmse: 0.1585 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99963\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2752 - rmse: 0.0657 - acc: 0.9995 - val_loss: 1.3112 - val_rmse: 0.1770 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99963\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2949 - rmse: 0.0703 - acc: 0.9996 - val_loss: 1.2582 - val_rmse: 0.1669 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99963\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2507 - rmse: 0.0655 - acc: 0.9996 - val_loss: 1.2441 - val_rmse: 0.1688 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99963\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2729 - rmse: 0.0707 - acc: 0.9994 - val_loss: 1.2944 - val_rmse: 0.1700 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99963\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2693 - rmse: 0.0663 - acc: 0.9994 - val_loss: 1.2018 - val_rmse: 0.1578 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99963\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2403 - rmse: 0.0619 - acc: 0.9993 - val_loss: 1.2125 - val_rmse: 0.1662 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99963\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2695 - rmse: 0.0707 - acc: 0.9993 - val_loss: 1.2155 - val_rmse: 0.1697 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99963\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2586 - rmse: 0.0717 - acc: 0.9989 - val_loss: 1.2117 - val_rmse: 0.1634 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99963\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2288 - rmse: 0.0561 - acc: 0.9994 - val_loss: 1.2000 - val_rmse: 0.1584 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99963\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2485 - rmse: 0.0650 - acc: 0.9993 - val_loss: 1.2240 - val_rmse: 0.1627 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99963\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2270 - rmse: 0.0589 - acc: 0.9998 - val_loss: 1.2420 - val_rmse: 0.1600 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00018: acc improved from 0.99963 to 0.99976, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/750/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2430 - rmse: 0.0594 - acc: 0.9995 - val_loss: 1.2003 - val_rmse: 0.1585 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.18377\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99976\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2411 - rmse: 0.0662 - acc: 0.9996 - val_loss: 1.1771 - val_rmse: 0.1560 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.18377 to 1.17714, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/750/weights.best.hdf5\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99976\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2328 - rmse: 0.0652 - acc: 0.9995 - val_loss: 1.3278 - val_rmse: 0.1664 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.17714\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99976\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2258 - rmse: 0.0625 - acc: 0.9992 - val_loss: 1.1853 - val_rmse: 0.1583 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.17714\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99976\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2461 - rmse: 0.0664 - acc: 0.9991 - val_loss: 1.2416 - val_rmse: 0.1616 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.17714\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99976\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2266 - rmse: 0.0604 - acc: 0.9989 - val_loss: 1.1951 - val_rmse: 0.1603 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.17714\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99976\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.2332 - rmse: 0.0661 - acc: 0.9996 - val_loss: 1.1985 - val_rmse: 0.1580 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.17714\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155b7df6b00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 950.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.7424 - rmse: 0.1172 - acc: 0.9994 - val_loss: 1.2428 - val_rmse: 0.1511 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24282, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.7424 - rmse: 0.1167 - acc: 0.9993 - val_loss: 1.2456 - val_rmse: 0.1477 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24282\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.99939\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.7178 - rmse: 0.1134 - acc: 0.9994 - val_loss: 1.2375 - val_rmse: 0.1443 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.24282 to 1.23753, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.99939 to 0.99945, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.7355 - rmse: 0.1133 - acc: 0.9994 - val_loss: 1.2462 - val_rmse: 0.1503 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99945\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.7109 - rmse: 0.1098 - acc: 0.9993 - val_loss: 1.2484 - val_rmse: 0.1500 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99945\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.7298 - rmse: 0.1113 - acc: 0.9994 - val_loss: 1.2471 - val_rmse: 0.1515 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99945\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.7255 - rmse: 0.1085 - acc: 0.9995 - val_loss: 1.2412 - val_rmse: 0.1445 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00007: acc improved from 0.99945 to 0.99951, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.7227 - rmse: 0.1079 - acc: 0.9993 - val_loss: 1.2631 - val_rmse: 0.1509 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99951\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.7215 - rmse: 0.1059 - acc: 0.9994 - val_loss: 1.2472 - val_rmse: 0.1470 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99951\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.7173 - rmse: 0.1046 - acc: 0.9994 - val_loss: 1.2465 - val_rmse: 0.1446 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99951\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.7141 - rmse: 0.1035 - acc: 0.9994 - val_loss: 1.2484 - val_rmse: 0.1449 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99951\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.7114 - rmse: 0.1019 - acc: 0.9993 - val_loss: 1.2607 - val_rmse: 0.1436 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99951\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.7090 - rmse: 0.1017 - acc: 0.9994 - val_loss: 1.2588 - val_rmse: 0.1453 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99951\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6844 - rmse: 0.0999 - acc: 0.9994 - val_loss: 1.2555 - val_rmse: 0.1459 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99951\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.7086 - rmse: 0.1031 - acc: 0.9993 - val_loss: 1.2734 - val_rmse: 0.1540 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99951\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6973 - rmse: 0.0978 - acc: 0.9993 - val_loss: 1.2525 - val_rmse: 0.1438 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99951\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6943 - rmse: 0.0972 - acc: 0.9993 - val_loss: 1.2591 - val_rmse: 0.1465 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99951\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6873 - rmse: 0.0965 - acc: 0.9993 - val_loss: 1.2605 - val_rmse: 0.1445 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99951\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6870 - rmse: 0.0974 - acc: 0.9992 - val_loss: 1.2713 - val_rmse: 0.1452 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99951\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6810 - rmse: 0.0943 - acc: 0.9993 - val_loss: 1.2647 - val_rmse: 0.1451 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99951\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6751 - rmse: 0.0943 - acc: 0.9993 - val_loss: 1.3124 - val_rmse: 0.1968 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99951\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6697 - rmse: 0.0948 - acc: 0.9993 - val_loss: 1.2801 - val_rmse: 0.1521 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99951\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6710 - rmse: 0.0977 - acc: 0.9994 - val_loss: 1.2648 - val_rmse: 0.1466 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99951\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6583 - rmse: 0.0943 - acc: 0.9994 - val_loss: 1.2788 - val_rmse: 0.1474 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99951\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6645 - rmse: 0.0987 - acc: 0.9993 - val_loss: 1.2750 - val_rmse: 0.1466 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.23753\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d8ddd1438>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 1150.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.7195 - rmse: 0.1004 - acc: 0.9993 - val_loss: 1.4061 - val_rmse: 0.1497 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.40606, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1150/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99927, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1150/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.7009 - rmse: 0.0991 - acc: 0.9993 - val_loss: 1.3978 - val_rmse: 0.1478 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.40606 to 1.39783, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1150/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.99927\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.7028 - rmse: 0.0984 - acc: 0.9992 - val_loss: 1.4162 - val_rmse: 0.1520 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.39783\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99927\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6905 - rmse: 0.0941 - acc: 0.9992 - val_loss: 1.4033 - val_rmse: 0.1489 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.39783\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99927\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6814 - rmse: 0.0950 - acc: 0.9993 - val_loss: 1.4452 - val_rmse: 0.1571 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.39783\n",
      "\n",
      "Epoch 00005: acc improved from 0.99927 to 0.99933, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1150/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6907 - rmse: 0.1089 - acc: 0.9991 - val_loss: 1.3887 - val_rmse: 0.1475 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.39783 to 1.38868, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1150/weights.best.hdf5\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99933\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6523 - rmse: 0.0966 - acc: 0.9990 - val_loss: 1.4242 - val_rmse: 0.1495 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99933\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6747 - rmse: 0.1028 - acc: 0.9993 - val_loss: 1.4088 - val_rmse: 0.1504 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99933\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6464 - rmse: 0.1045 - acc: 0.9993 - val_loss: 1.4062 - val_rmse: 0.1525 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99933\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6178 - rmse: 0.0976 - acc: 0.9990 - val_loss: 1.4584 - val_rmse: 0.1556 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99933\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6417 - rmse: 0.1059 - acc: 0.9991 - val_loss: 1.4364 - val_rmse: 0.1515 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99933\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5963 - rmse: 0.0968 - acc: 0.9994 - val_loss: 1.4257 - val_rmse: 0.1610 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00012: acc improved from 0.99933 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1150/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6442 - rmse: 0.1076 - acc: 0.9990 - val_loss: 1.4190 - val_rmse: 0.1498 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99939\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6101 - rmse: 0.0943 - acc: 0.9993 - val_loss: 1.3974 - val_rmse: 0.1479 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99939\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6096 - rmse: 0.0980 - acc: 0.9992 - val_loss: 1.4070 - val_rmse: 0.1485 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99939\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5835 - rmse: 0.0980 - acc: 0.9992 - val_loss: 1.5154 - val_rmse: 0.2414 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99939\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.6113 - rmse: 0.1019 - acc: 0.9993 - val_loss: 1.4034 - val_rmse: 0.1469 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99939\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5749 - rmse: 0.0918 - acc: 0.9992 - val_loss: 1.4198 - val_rmse: 0.1489 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99939\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5788 - rmse: 0.0941 - acc: 0.9993 - val_loss: 1.4413 - val_rmse: 0.1510 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99939\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5721 - rmse: 0.0945 - acc: 0.9991 - val_loss: 1.5042 - val_rmse: 0.1651 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99939\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5601 - rmse: 0.1003 - acc: 0.9993 - val_loss: 1.4294 - val_rmse: 0.1505 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99939\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5586 - rmse: 0.0921 - acc: 0.9994 - val_loss: 1.4614 - val_rmse: 0.1733 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99939\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5474 - rmse: 0.0961 - acc: 0.9991 - val_loss: 1.4030 - val_rmse: 0.1590 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99939\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5379 - rmse: 0.0961 - acc: 0.9991 - val_loss: 1.4253 - val_rmse: 0.1545 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99939\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5372 - rmse: 0.0924 - acc: 0.9991 - val_loss: 1.4511 - val_rmse: 0.1536 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.38868\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d91b855f8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 1350.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5329 - rmse: 0.0931 - acc: 0.9990 - val_loss: 1.5451 - val_rmse: 0.1534 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54514, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99896, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5445 - rmse: 0.1006 - acc: 0.9991 - val_loss: 1.5545 - val_rmse: 0.1527 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.54514\n",
      "\n",
      "Epoch 00002: acc improved from 0.99896 to 0.99914, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5682 - rmse: 0.1021 - acc: 0.9994 - val_loss: 1.5571 - val_rmse: 0.1584 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54514\n",
      "\n",
      "Epoch 00003: acc improved from 0.99914 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5138 - rmse: 0.0937 - acc: 0.9994 - val_loss: 1.5324 - val_rmse: 0.1514 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.54514 to 1.53242, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99939\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5013 - rmse: 0.0937 - acc: 0.9991 - val_loss: 1.5181 - val_rmse: 0.1517 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.53242 to 1.51807, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99939\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5214 - rmse: 0.1009 - acc: 0.9991 - val_loss: 1.5976 - val_rmse: 0.1747 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99939\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4765 - rmse: 0.0973 - acc: 0.9991 - val_loss: 1.5992 - val_rmse: 0.1612 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99939\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.5329 - rmse: 0.1247 - acc: 0.9989 - val_loss: 1.5348 - val_rmse: 0.1567 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99939\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4557 - rmse: 0.0957 - acc: 0.9991 - val_loss: 1.6438 - val_rmse: 0.2167 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99939\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4594 - rmse: 0.1026 - acc: 0.9993 - val_loss: 1.5288 - val_rmse: 0.1543 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99939\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4438 - rmse: 0.0968 - acc: 0.9993 - val_loss: 1.6019 - val_rmse: 0.1751 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99939\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4143 - rmse: 0.0965 - acc: 0.9993 - val_loss: 1.5385 - val_rmse: 0.1540 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99939\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4152 - rmse: 0.0945 - acc: 0.9993 - val_loss: 1.5391 - val_rmse: 0.1542 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99939\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4319 - rmse: 0.1000 - acc: 0.9995 - val_loss: 1.5459 - val_rmse: 0.1567 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00014: acc improved from 0.99939 to 0.99951, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4294 - rmse: 0.1011 - acc: 0.9993 - val_loss: 1.5533 - val_rmse: 0.1689 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99951\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3962 - rmse: 0.0932 - acc: 0.9990 - val_loss: 1.5473 - val_rmse: 0.1574 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99951\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4287 - rmse: 0.0970 - acc: 0.9990 - val_loss: 1.5800 - val_rmse: 0.1598 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99951\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3700 - rmse: 0.1037 - acc: 0.9994 - val_loss: 1.5955 - val_rmse: 0.1772 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99951\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4031 - rmse: 0.1039 - acc: 0.9991 - val_loss: 1.5699 - val_rmse: 0.1824 - val_acc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99951\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4179 - rmse: 0.0941 - acc: 0.9993 - val_loss: 1.5483 - val_rmse: 0.1589 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99951\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3662 - rmse: 0.0948 - acc: 0.9992 - val_loss: 1.5449 - val_rmse: 0.1560 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99951\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3694 - rmse: 0.1002 - acc: 0.9996 - val_loss: 1.5403 - val_rmse: 0.1665 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00022: acc improved from 0.99951 to 0.99957, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1350/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3517 - rmse: 0.0959 - acc: 0.9992 - val_loss: 1.5578 - val_rmse: 0.1579 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99957\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3849 - rmse: 0.1002 - acc: 0.9991 - val_loss: 1.5228 - val_rmse: 0.1611 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99957\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3461 - rmse: 0.0945 - acc: 0.9993 - val_loss: 1.5603 - val_rmse: 0.1650 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.51807\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d941562b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 1550.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.4057 - rmse: 0.0954 - acc: 0.9990 - val_loss: 1.6586 - val_rmse: 0.1760 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.65861, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99902, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3539 - rmse: 0.0863 - acc: 0.9991 - val_loss: 1.6335 - val_rmse: 0.1533 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.65861 to 1.63350, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99902 to 0.99908, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3333 - rmse: 0.0924 - acc: 0.9990 - val_loss: 1.7044 - val_rmse: 0.1622 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.63350\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99908\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3897 - rmse: 0.0951 - acc: 0.9991 - val_loss: 1.6296 - val_rmse: 0.1559 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.63350 to 1.62964, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99908\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3651 - rmse: 0.0945 - acc: 0.9993 - val_loss: 1.6177 - val_rmse: 0.1555 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.62964 to 1.61768, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc improved from 0.99908 to 0.99933, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3654 - rmse: 0.0898 - acc: 0.9993 - val_loss: 1.6554 - val_rmse: 0.1610 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.61768\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99933\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3383 - rmse: 0.0903 - acc: 0.9993 - val_loss: 1.6110 - val_rmse: 0.1547 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.61768 to 1.61099, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99933\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3802 - rmse: 0.0957 - acc: 0.9993 - val_loss: 1.6371 - val_rmse: 0.1663 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.61099\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99933\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3760 - rmse: 0.0949 - acc: 0.9997 - val_loss: 1.6508 - val_rmse: 0.1612 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61099\n",
      "\n",
      "Epoch 00009: acc improved from 0.99933 to 0.99969, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3134 - rmse: 0.0888 - acc: 0.9994 - val_loss: 1.6205 - val_rmse: 0.1539 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.61099\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99969\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3346 - rmse: 0.0880 - acc: 0.9994 - val_loss: 1.6307 - val_rmse: 0.1617 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.61099\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99969\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3269 - rmse: 0.0817 - acc: 0.9995 - val_loss: 1.6871 - val_rmse: 0.1644 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.61099\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99969\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3142 - rmse: 0.0921 - acc: 0.9993 - val_loss: 1.6393 - val_rmse: 0.1615 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.61099\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99969\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3508 - rmse: 0.0880 - acc: 0.9994 - val_loss: 1.6025 - val_rmse: 0.1512 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.61099 to 1.60249, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.hdf5\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99969\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2992 - rmse: 0.0835 - acc: 0.9994 - val_loss: 1.6514 - val_rmse: 0.1592 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99969\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3811 - rmse: 0.1011 - acc: 0.9994 - val_loss: 1.6245 - val_rmse: 0.1567 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99969\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3338 - rmse: 0.0928 - acc: 0.9992 - val_loss: 1.6581 - val_rmse: 0.1598 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99969\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3098 - rmse: 0.0836 - acc: 0.9992 - val_loss: 1.6304 - val_rmse: 0.1524 - val_acc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99969\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2954 - rmse: 0.0812 - acc: 0.9991 - val_loss: 1.6296 - val_rmse: 0.1574 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99969\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3281 - rmse: 0.0853 - acc: 0.9993 - val_loss: 1.6251 - val_rmse: 0.1534 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99969\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3163 - rmse: 0.0814 - acc: 0.9994 - val_loss: 1.6064 - val_rmse: 0.1519 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99969\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2983 - rmse: 0.0845 - acc: 0.9994 - val_loss: 1.6122 - val_rmse: 0.1535 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.60249\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99969\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2902 - rmse: 0.0749 - acc: 0.9993 - val_loss: 1.5921 - val_rmse: 0.1604 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.60249 to 1.59211, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1550/weights.best.hdf5\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99969\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2969 - rmse: 0.0776 - acc: 0.9995 - val_loss: 1.6576 - val_rmse: 0.1786 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.59211\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99969\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3057 - rmse: 0.0850 - acc: 0.9994 - val_loss: 1.6064 - val_rmse: 0.1549 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.59211\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d96f3a0f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 1750.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3091 - rmse: 0.0811 - acc: 0.9993 - val_loss: 1.7500 - val_rmse: 0.1600 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.75005, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99927, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3432 - rmse: 0.0934 - acc: 0.9994 - val_loss: 1.7062 - val_rmse: 0.1541 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.75005 to 1.70616, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99927 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3068 - rmse: 0.0803 - acc: 0.9994 - val_loss: 1.6908 - val_rmse: 0.1514 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.70616 to 1.69075, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.99939 to 0.99945, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3022 - rmse: 0.0815 - acc: 0.9992 - val_loss: 1.7393 - val_rmse: 0.1741 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99945\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3377 - rmse: 0.0838 - acc: 0.9994 - val_loss: 1.7438 - val_rmse: 0.1549 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99945\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2997 - rmse: 0.0783 - acc: 0.9994 - val_loss: 1.7061 - val_rmse: 0.1570 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99945\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2656 - rmse: 0.0748 - acc: 0.9995 - val_loss: 1.7100 - val_rmse: 0.1536 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00007: acc improved from 0.99945 to 0.99951, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3221 - rmse: 0.0803 - acc: 0.9994 - val_loss: 1.7027 - val_rmse: 0.1538 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99951\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2640 - rmse: 0.0740 - acc: 0.9996 - val_loss: 1.7026 - val_rmse: 0.1536 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00009: acc improved from 0.99951 to 0.99957, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2920 - rmse: 0.0784 - acc: 0.9994 - val_loss: 1.6949 - val_rmse: 0.1509 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99957\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2979 - rmse: 0.0753 - acc: 0.9994 - val_loss: 1.7289 - val_rmse: 0.1558 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99957\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2668 - rmse: 0.0746 - acc: 0.9992 - val_loss: 1.6951 - val_rmse: 0.1520 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99957\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2750 - rmse: 0.0768 - acc: 0.9993 - val_loss: 1.7151 - val_rmse: 0.1645 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99957\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2678 - rmse: 0.0781 - acc: 0.9993 - val_loss: 1.6955 - val_rmse: 0.1527 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99957\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2802 - rmse: 0.0756 - acc: 0.9994 - val_loss: 1.7456 - val_rmse: 0.1628 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99957\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2367 - rmse: 0.0757 - acc: 0.9993 - val_loss: 1.6959 - val_rmse: 0.1582 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99957\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2481 - rmse: 0.0744 - acc: 0.9993 - val_loss: 1.7177 - val_rmse: 0.1523 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99957\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2317 - rmse: 0.0702 - acc: 0.9995 - val_loss: 1.7348 - val_rmse: 0.1538 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99957\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2680 - rmse: 0.0727 - acc: 0.9995 - val_loss: 1.7060 - val_rmse: 0.1566 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99957\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2758 - rmse: 0.0780 - acc: 0.9993 - val_loss: 1.7111 - val_rmse: 0.1513 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99957\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2238 - rmse: 0.0715 - acc: 0.9995 - val_loss: 1.6945 - val_rmse: 0.1563 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99957\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2543 - rmse: 0.0741 - acc: 0.9990 - val_loss: 1.7089 - val_rmse: 0.1576 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.69075\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99957\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2287 - rmse: 0.0721 - acc: 0.9994 - val_loss: 1.6780 - val_rmse: 0.1493 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.69075 to 1.67801, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1750/weights.best.hdf5\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99957\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2264 - rmse: 0.0765 - acc: 0.9994 - val_loss: 1.7045 - val_rmse: 0.1566 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.67801\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99957\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2383 - rmse: 0.0774 - acc: 0.9994 - val_loss: 1.7183 - val_rmse: 0.1555 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.67801\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d95c56f98>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 1950.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2056 - rmse: 0.0697 - acc: 0.9994 - val_loss: 1.7831 - val_rmse: 0.1674 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.78313, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99945, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2283 - rmse: 0.0737 - acc: 0.9994 - val_loss: 1.8268 - val_rmse: 0.1582 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.78313\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.99945\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2631 - rmse: 0.0762 - acc: 0.9996 - val_loss: 1.7713 - val_rmse: 0.1504 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.78313 to 1.77131, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.99945 to 0.99957, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2224 - rmse: 0.0709 - acc: 0.9994 - val_loss: 1.8021 - val_rmse: 0.1535 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.77131\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99957\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1937 - rmse: 0.0665 - acc: 0.9992 - val_loss: 1.7768 - val_rmse: 0.1528 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.77131\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99957\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2300 - rmse: 0.0733 - acc: 0.9994 - val_loss: 1.8115 - val_rmse: 0.1825 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.77131\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99957\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.2560 - rmse: 0.0798 - acc: 0.9994 - val_loss: 1.7815 - val_rmse: 0.1528 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.77131\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99957\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.2185 - rmse: 0.0703 - acc: 0.9994 - val_loss: 1.7702 - val_rmse: 0.1551 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.77131 to 1.77023, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.hdf5\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99957\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.2215 - rmse: 0.0686 - acc: 0.9994 - val_loss: 1.8153 - val_rmse: 0.1709 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.77023\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99957\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.2223 - rmse: 0.0716 - acc: 0.9994 - val_loss: 1.7633 - val_rmse: 0.1525 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.77023 to 1.76331, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.hdf5\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99957\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2126 - rmse: 0.0671 - acc: 0.9995 - val_loss: 1.7715 - val_rmse: 0.1524 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99957\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1950 - rmse: 0.0681 - acc: 0.9992 - val_loss: 1.8020 - val_rmse: 0.1555 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99957\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2300 - rmse: 0.0731 - acc: 0.9995 - val_loss: 1.7825 - val_rmse: 0.1638 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99957\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2040 - rmse: 0.0684 - acc: 0.9993 - val_loss: 1.7814 - val_rmse: 0.1531 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99957\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2126 - rmse: 0.0689 - acc: 0.9994 - val_loss: 1.7750 - val_rmse: 0.1501 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99957\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2327 - rmse: 0.0702 - acc: 0.9994 - val_loss: 1.7767 - val_rmse: 0.1504 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99957\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.1848 - rmse: 0.0674 - acc: 0.9994 - val_loss: 1.7916 - val_rmse: 0.1534 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99957\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2063 - rmse: 0.0689 - acc: 0.9994 - val_loss: 1.7694 - val_rmse: 0.1512 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.76331\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99957\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2128 - rmse: 0.0680 - acc: 0.9994 - val_loss: 1.7587 - val_rmse: 0.1512 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.76331 to 1.75866, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.hdf5\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99957\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2489 - rmse: 0.0795 - acc: 0.9994 - val_loss: 1.7824 - val_rmse: 0.1539 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.75866\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99957\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2188 - rmse: 0.0727 - acc: 0.9994 - val_loss: 1.7812 - val_rmse: 0.1516 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.75866\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99957\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.1856 - rmse: 0.0672 - acc: 0.9994 - val_loss: 1.7786 - val_rmse: 0.1520 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.75866\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99957\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2126 - rmse: 0.0698 - acc: 0.9996 - val_loss: 1.7594 - val_rmse: 0.1503 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.75866\n",
      "\n",
      "Epoch 00023: acc improved from 0.99957 to 0.99963, saving model to D:/KITTI/Graph/DepthVOExpanded_Beta/model/1950/weights.best.by.accuracy.hdf5\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1925 - rmse: 0.0638 - acc: 0.9994 - val_loss: 1.7587 - val_rmse: 0.1483 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.75866\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99963\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.2191 - rmse: 0.0667 - acc: 0.9992 - val_loss: 1.7790 - val_rmse: 0.1532 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.75866\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d9c1f49e8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import degrees, sin, cos, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beta igual a 150.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 350.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 550.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 750.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 950.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 1150.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 1350.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 1550.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 1750.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "\n",
      "Beta igual a 1950.\n",
      "\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for beta in beta_list:\n",
    "    print(\"\")\n",
    "    print(\"Beta igual a %s.\"%beta)\n",
    "    print(\"\")\n",
    "    for sequence in kitti_train_dirs:\n",
    "        \n",
    "        print(\"Sequence %s:\"%(sequence))\n",
    "        cont = 1\n",
    "        data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "        data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "\n",
    "        model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "        filepath_model = model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "        \n",
    "        model.load_weights(filepath=filepath_model)    \n",
    "        prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                                   data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "\n",
    "        sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "\n",
    "        init_mat = np.identity(4)\n",
    "        sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "\n",
    "        position_X = 0\n",
    "        position_Z = 0\n",
    "        angle_total = pi/2\n",
    "\n",
    "        for element in prediction:\n",
    "            angle = element[0]\n",
    "            displacement = element[1]\n",
    "\n",
    "            angle_total = angle_total - angle\n",
    "\n",
    "            position_X = position_X + displacement*cos(angle_total)\n",
    "            position_Z = position_Z + displacement*sin(angle_total)\n",
    "\n",
    "            sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "\n",
    "            sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 3] = position_X\n",
    "            sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 11] = position_Z\n",
    "\n",
    "            cont += 1\n",
    "        \n",
    "        output_path = \"D:/KITTI/output_to_draw/DepthVOExpanded_Beta/val_loss/\"+str(beta)+\"/\"\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            # print (model_path)\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        np.savetxt(output_path+\"%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "\n",
    "    for sequence in kitti_test_dirs:\n",
    "        cont = 1\n",
    "        print(\"Sequence %s:\"%(sequence))\n",
    "        data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "        data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "        \n",
    "        model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "        filepath_model = model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "        \n",
    "        prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                                   data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "\n",
    "        sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "\n",
    "        init_mat = np.identity(4)\n",
    "        sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "\n",
    "        position_X = 0\n",
    "        position_Z = 0\n",
    "        angle_total = pi/2\n",
    "\n",
    "        for element in prediction:\n",
    "            angle = element[0]\n",
    "            displacement = element[1]\n",
    "\n",
    "            angle_total = angle_total - angle\n",
    "\n",
    "            position_X = position_X + displacement*cos(angle_total)\n",
    "            position_Z = position_Z + displacement*sin(angle_total)\n",
    "\n",
    "            sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "\n",
    "            sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 3] = position_X\n",
    "            sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 11] = position_Z\n",
    "\n",
    "            cont += 1\n",
    "\n",
    "        output_path = \"D:/KITTI/output_to_draw/DepthVOExpanded_Beta/val_loss/\"+str(beta)+\"/\"\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            # print (model_path)\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        np.savetxt(output_path+\"%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta igual a 150.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 350.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 550.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 750.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 950.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 1150.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 1350.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 1550.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 1750.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Beta igual a 1950.\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for beta in beta_list:\n",
    "    print(\"Beta igual a %s.\"%beta)\n",
    "    for sequence in kitti_train_dirs:\n",
    "\n",
    "        print(\"Sequence %s:\"%(sequence))\n",
    "        cont = 1\n",
    "        data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "        data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "\n",
    "        model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "        filepath_model = model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "        \n",
    "        model.load_weights(filepath=filepath_model)    \n",
    "        prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                                   data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "\n",
    "        sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "\n",
    "        init_mat = np.identity(4)\n",
    "        sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "\n",
    "        position_X = 0\n",
    "        position_Z = 0\n",
    "        angle_total = pi/2\n",
    "\n",
    "        for element in prediction:\n",
    "            angle = element[0]\n",
    "            displacement = element[1]\n",
    "\n",
    "            angle_total = angle_total - angle\n",
    "\n",
    "            position_X = position_X + displacement*cos(angle_total)\n",
    "            position_Z = position_Z + displacement*sin(angle_total)\n",
    "\n",
    "            sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "\n",
    "            sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 3] = position_X\n",
    "            sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 11] = position_Z\n",
    "\n",
    "            cont += 1\n",
    "        \n",
    "        output_path = \"D:/KITTI/output_to_draw/DepthVOExpanded_Beta/acc/\"+str(beta)+\"/\"\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            # print (model_path)\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        np.savetxt(output_path+\"%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "\n",
    "    for sequence in kitti_test_dirs:\n",
    "        cont = 1\n",
    "        print(\"Sequence %s:\"%(sequence))\n",
    "        data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "        data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "        \n",
    "        model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "        filepath_model = model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "        \n",
    "        prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                                   data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "\n",
    "        sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "\n",
    "        init_mat = np.identity(4)\n",
    "        sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "\n",
    "        position_X = 0\n",
    "        position_Z = 0\n",
    "        angle_total = pi/2\n",
    "\n",
    "        for element in prediction:\n",
    "            angle = element[0]\n",
    "            displacement = element[1]\n",
    "\n",
    "            angle_total = angle_total - angle\n",
    "\n",
    "            position_X = position_X + displacement*cos(angle_total)\n",
    "            position_Z = position_Z + displacement*sin(angle_total)\n",
    "\n",
    "            sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "\n",
    "            sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 3] = position_X\n",
    "            sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 11] = position_Z\n",
    "\n",
    "            cont += 1\n",
    "\n",
    "        output_path = \"D:/KITTI/output_to_draw/DepthVOExpanded_Beta/acc/\"+str(beta)+\"/\"\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            # print (model_path)\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        np.savetxt(output_path+\"%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "a = [x for x in range(-10, 10)]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    output = []    \n",
    "    for i in range(0, len(x)):        \n",
    "        value = x[i]\n",
    "        if value < 0:\n",
    "            value = 0\n",
    "        output.append(value)\n",
    "    return np.array(output)\n",
    "\n",
    "def leaky_relu(x, alpha):\n",
    "    output = []    \n",
    "    for i in range(0, len(x)):        \n",
    "        value = x[i]\n",
    "        if value < 0:\n",
    "            value = x[i]*alpha\n",
    "        output.append(value)\n",
    "    return np.array(output)\n",
    "\n",
    "relu_values = relu(a)\n",
    "Leaky_relu_values_1 = leaky_relu(a,0.1)\n",
    "Leaky_relu_values_2 = leaky_relu(a,0.5)\n",
    "Leaky_relu_values_3 = leaky_relu(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "[-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   1.   2.   3.   4.\n",
      "  5.   6.   7.   8.   9. ]\n",
      "\n",
      "[-5.  -4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   1.   2.   3.   4.\n",
      "  5.   6.   7.   8.   9. ]\n",
      "\n",
      "[-10  -9  -8  -7  -6  -5  -4  -3  -2  -1   0   1   2   3   4   5   6   7\n",
      "   8   9]\n"
     ]
    }
   ],
   "source": [
    "print(relu_values)\n",
    "print(\"\")\n",
    "print(Leaky_relu_values_1)\n",
    "print(\"\")\n",
    "print(Leaky_relu_values_2)\n",
    "print(\"\")\n",
    "print(Leaky_relu_values_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269cdceeac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(a, relu_values, color='C1', linewidth=1.5, linestyle=\"-\", label=\"Relu\")\n",
    "plt.plot(a, Leaky_relu_values_1, color='C2', linewidth=1.5, linestyle=\"-\", label=\"LeakyReLU com  α = 0,1\")\n",
    "plt.plot(a, Leaky_relu_values_2, color='C3', linewidth=1.5, linestyle=\"-\", label=\"LeakyReLU com  α = 0,5\")\n",
    "plt.plot(a, Leaky_relu_values_3, color='C4', linewidth=1.5, linestyle=\"-\", label=\"LeakyReLU com  α = 1\")\n",
    "\n",
    "plt.ylabel('Output')\n",
    "plt.xlabel('Input')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.savefig('leaky-relu-new.png', dpi = 300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('leaky-relu-new.png', dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VOXZ//HPRQgJEAKyBQQkiLggypJAYltbqFqt2qLW\nDRQBIdhWW/vYX1trF33sYx+fLnZfNIIgW2qtW11q0YJrCQRlFRBEkH1fEjAhy/X7YwYbEcgQMnOS\nOd/36zWvnDkz55zrJuF859znnnPM3RERkfBqFnQBIiISLAWBiEjIKQhEREJOQSAiEnIKAhGRkFMQ\niIiEnIJARCTkFAQiIiGnIBARCbnm8VqxmaUDrwJp0e087u53m1l74C9ANrAWuNbddx9rXR07dvTs\n7Ox61bF//35at25dr2WbMrU7fMLadrX76BYsWLDD3TvVuTJ3j8sDMCAjOp0KFAP5wM+AO6Pz7wT+\nr6515eTkeH3Nnj273ss2ZWp3+IS17Wr30QElHsP+Om5dQ9E6yqJPU6MPB4YDU6LzpwBXxKsGERGp\nW1zPEZhZipktBLYBs9y9GMhy983Rt2wBsuJZg4iIHJt5Aq4+ambtgCeBbwCvu3u7Wq/tdveTjrDM\nBGACQFZWVk5RUVG9tl1WVkZGRka9lm3K1O7wCWvb1e6jGzZs2AJ3z61rXXE7WVybu+8xs9nAJcBW\nM+vq7pvNrCuRo4UjLfMQ8BBAbm6uDx06tF7bnjNnDvVdtilTu8MnrG1Xu09c3LqGzKxT9EgAM2sJ\nXASsAJ4BRkffNhp4Ol41iIhI3eJ5RNAVmGJmKUQC5zF3f9bM/g08ZmbjgHXAtXGsQURE6hC3IHD3\nxcDAI8zfCVwQr+2KiMjx0TeLRUQaoQMHq7jnmWXs/bAy7ttSEIiINDLlldUUPFrCo/9ey4J1u+K+\nvYSMGhIRkdhUVFVzy9QFvPneTn5xdX8+f2b8v2qlIwIRkUbiYFUNt05/i1fe3c79V53DV3K6J2S7\nCgIRkUagsrqGb858m5eWb+Mnw8/musGnJGzbCgIRkYBVVddwx2OL+MeyLfzo8r6MOi87odtXEIiI\nBKi6xvnu44v5+6JN3PnFMxn3mV4Jr0FBICISkJoa564nlvDE2xu546LT+ernegdSh4JARCQA7s6P\nn1nKX0rWc9uw0/jmBX0Cq0VBICKSYO7Ovc++w7S5H3DL507l2184PdB6FAQiIgnk7tz/wgoeeWMt\nYz+dzZ2XnImZBVqTgkBEJIEemPUuD766hhvzT+HHl/cNPARAQSAikjC/fXkVv/vXaq4f3IN7v9yv\nUYQAKAhERBLiz6+8xwOz3uWqQd346ZXn0KxZ4wgBUBCIiMTdxNff5/4XVvCl/ifz86v7N6oQAAWB\niEhcTZ27jp88+w5f7NeFB67tT0ojCwFQEIiIxM1f5n/Aj55ayoVndeY31w8kNaVx7nIbZ1UiIk3c\n3xZs4M4nlvC50zvxhxsG0aJ5493dNt7KRESaqL8v2sR3Hl/Ep3p34MFROaQ1Twm6pGNSEIiINKB/\nLN3Mt/6ykNzs9hTelEt6auMOAVAQiIg0mJfe2cptM96mf/e2TBozmFYtmsZNIBUEIiINYM7KbXx9\n+lucfXImk28eQkZa0wgBUBCIiJywN1bv4JapCzitcwaP3pxHZnpq0CUdl7gFgZn1MLPZZvaOmS0z\ns9uj8+8xs41mtjD6uDReNYiIxFvxmp2MmzKfXh1bM218Hm1bNa0QAIjnsUsV8G13f8vM2gALzGxW\n9LVfufsv4rhtEZG4W7BuF2Mnz6dbu5ZMG59H+9Ytgi6pXuIWBO6+GdgcnS41s+VAt3htT0QkkRat\n38OYSfPJykxnZkE+HTPSgi6p3hJyjsDMsoGBQHF01jfMbLGZTTKzkxJRg4hIQ1m6cS+jJhbTrnUq\nMwry6JyZHnRJJ8TcPb4bMMsAXgHuc/cnzCwL2AE48BOgq7vffITlJgATALKysnKKiorqtf2ysjIy\nMjLqW36TpXaHT1jbnuh2ry+t4f/mfUhainHnkHQ6tQpmzE0s7R42bNgCd8+tc2XuHrcHkAq8CNxx\nlNezgaV1rScnJ8fra/bs2fVetilTu8MnrG1PZLtXbd3ng+79p+fd95Kv3VGWsO0eSSztBko8hn11\nPEcNGTARWO7uD9Sa37XW264ElsarBhGRhrJmexkjCotp1syYXpBHzw6tgy6pwcRz1NCngVHAEjNb\nGJ13FzDCzAYQ6RpaC9wSxxpERE7YBzsPMLKwmJoap2hCPr07JVcXXDxHDb0OHOnC28/Ha5siIg1t\nw+4DjCicS3lVNTML8umT1SbokhqcvlksInIUW/aWM7KwmNLySqaNy+OsrplBlxQXTediGCIiCbRt\nXzkjC+eya/9Bpo4bQr9ubYMuKW50RCAicpidZRXc8HAxW/aVM3nsYAaektxfd1IQiIjUsnv/QW54\nuJj1uw8wcfRgcrPbB11S3KlrSEQkau+HlYyaVMyaHfuZNHow5/XuEHRJCaEjAhERoLS8kpsmzWPl\nllIevDGHz/TpGHRJCaMgEJHQ219RxdhH5rNs417+MHIQw87sHHRJCaWuIREJtQ8PVjNuynzeXr+H\n340YyBfO7hJ0SQmnIwIRCa3yymomTC2h+P1dPHBtfy49p2vdCyUhBYGIhFJFVTVfm7aA11fv4OdX\n92f4gPDeLkVBICKhU1ldw20z3mb2yu389MpzuDqne9AlBUpBICKhUlVdw+1FbzPrna3cO/xsRgw5\nJeiSAqcgEJHQqK5xvv3XRTy/ZAs/vOwsbjovO+iSGgUFgYiEQk2N872/LebphZv47iVnMP78U4Mu\nqdFQEIhI0qupcX7w1BIeX7CBb13Yh68PPS3okhoVBYGIJDV3556/L2PmvPXcOqw3t1/QJ+iSGh0F\ngYgkLXfnf55bzqP/XkfB+b34f184g8hddKU2BYGIJCV352cvrmTi6+8z5lPZ3HXpWQqBo1AQiEhS\n+vVLq/jTnPcYmXcKd3+pr0LgGBQEIpJ0/jB7Nb95eRXX5HTnf4b3UwjUQUEgIkml8NU1/PzFlVwx\n4GTu/8q5NGumEKiLgkBEksbkN97nvueXc9k5XfnFNf1JUQjEREEgIklhevE67vn7O3yhbxa/vn4A\nzVO0e4tV3P6lzKyHmc02s3fMbJmZ3R6d397MZpnZqujP5L4rtIjE3WMl6/nBk0v5/Jmd+f3IQaQq\nBI5LPP+1qoBvu3tfIB+41cz6AncCL7t7H+Dl6HMRkXp5c1MV3/vbYs7v05E/3jCIFs0VAscrbv9i\n7r7Z3d+KTpcCy4FuwHBgSvRtU4Ar4lWDiCS3ZxdvonBxBfm9OlB4Uy7pqSlBl9QkJSQ6zSwbGAgU\nA1nuvjn60hYgKxE1iEhy+cfSLXyraCF9TmrGxDEKgRNh7h7fDZhlAK8A97n7E2a2x93b1Xp9t7t/\n4jyBmU0AJgBkZWXlFBUV1Wv7ZWVlZGRk1K/4JkztDp8wtX3htip+93YF2ZnN+NpZ1XRsF4521xbL\n73vYsGEL3D23zpW5e9weQCrwInBHrXkrga7R6a7AyrrWk5OT4/U1e/bsei/blKnd4ROWtr+ycpv3\nuet5v/y3r/meAwdD0+7DxdJuoMRj2FfHc9SQAROB5e7+QK2XngFGR6dHA0/HqwYRSS5vrt5BwaMl\n9O6cwdRxQ2jbMjXokpJC8ziu+9PAKGCJmS2MzrsLuB94zMzGAeuAa+NYg4gkiXnv72LclBJ6dmjF\n9PF5tGvVIuiSkkbcgsDdXweO9rW+C+K1XRFJPgvW7WbsI/M4uV0608fn0761QqAhacCtiDRqizfs\nYcykeXRqk8aMgnw6tUkLuqSkU2cQmNk1ZtYmOv1DM3vCzAbFvzQRCbtlm/YyauI82rZKZUZBPlmZ\n6UGXlJRiOSL4kbuXmtlngAuJnAD+U3zLEpGwW7mllFET59G6RQozC/I5uV3LoEtKWrEEQXX052XA\nQ+7+HKAOOhGJm9Xbyrjh4bmkphgzCvLp0b5V0CUltViCYKOZPQhcBzxvZmkxLicictzW7tjPyMK5\ngDF9fD7ZHVsHXVLSi2WHfi2RL4Vd7O57gPbAd+JalYiE0vpdBxhZOJfK6hqmj8/jtM7h+8ZwEI45\nfNTMUoC33P3MQ/M8cp2gzUdfSkTk+G3a8yEjCuey/2A1MwryOKNLm6BLCo1jHhG4ezWw0sxOSVA9\nIhJCW/eVM6JwLnsPVDJ13BDOPrlt0CWFSixfKDsJWGZm84D9h2a6+5fjVpWIhMb20gpGFs5lR2kF\nU8fncW73dnUvJA0qliD4UdyrEJFQ2llWwQ0Pz2XTnnKm3DyEQafohoVBqDMI3P0VM+sJ9HH3l8ys\nFaALf4vICdlz4CA3TpzHup0HeGTMYIb0ah90SaEVyzeLC4DHgQejs7oBT8WzKBFJbns/rGTUxHm8\nt62Mwpty+dRpHYMuKdRiGT56K5Erie4DcPdVQOd4FiUiyausoooxj8xjxZZ9/HnUID57eqegSwq9\nWIKgwt0PHnpiZs2B+N7WTESS0oGDVdz8yHwWb9jL70YM4vNn6k61jUEsQfCKmd0FtDSzi4C/An+P\nb1kikmw+PFjNuMkllKzbxW+uH8Al/boEXZJExRIEdwLbgSXALcDzwA/jWZSIJJfyymomTC1h7vs7\neeDaAVx+7slBlyS1xDJqqMbMpgDFRLqEVkbvhSkiUqeDVTV8ffpbvLZqBz+7+lyuGNgt6JLkMHUG\ngZldBvwZeI/IHcd6mdkt7v5CvIsTkaatsrqGb8x8i3+t2MZ9V/bj2tweQZckRxDLF8p+CQxz99UA\nZtYbeA5QEIjIUVVV1/Bff1nIi8u2cs+X+nJDXs+gS5KjiOUcQemhEIhaA5TGqR4RSQLVNc53Hl/M\ns4s384NLz2LMp3sFXZIcw1GPCMzsquhkiZk9DzxG5BzBNcD8BNQmIk1QTY3z/ScW8+TbG/nOxWdQ\n8NlTgy5J6nCsrqEv1ZreCnwuOr0d0D3jROQT3J0fPb2Ux0o28M0L+nDrsNOCLklicNQgcPexiSxE\nRJo2d+e///4O04s/4GtDe/NfF/YJuiSJUSyjhnoB3wCya7+/rstQm9kk4HJgm7v3i867ByggclQB\ncJe7P1+fwkWk8XB3/veFFUx+cy3jPtOL7158BmYWdFkSo1hGDT0FTCTybeKa41j3ZOD3wKOHzf+V\nu//iONYjIo3cL//5Lg+9uoabzuvJDy87SyHQxMQSBOXu/tvjXbG7v2pm2cddkYg0Kb99eRW/n72a\nEUN6cM+XzlYINEGxDB/9jZndbWbnmdmgQ48T2OY3zGyxmU0yM92FQqQJ+9Oc93hg1rt8ZVB37rvi\nHJo1Uwg0RVbX1SLM7H+BUUS+WXyoa8jd/fN1rjxyRPBsrXMEWcAOIsNQfwJ0dfebj7LsBGACQFZW\nVk5RUVEMzfmksrIyMjIy6rVsU6Z2h0+i2/7i2kpmrjhIftcUJpybRrOAjgTC+juPpd3Dhg1b4O65\nda7M3Y/5AFYDLep631GWzQaWHu9rhz9ycnK8vmbPnl3vZZsytTt8Etn2KW++7z2/96x/dWqJV1ZV\nJ2y7RxLW33ks7QZKPIZ9bCxdQ0uBBrmbtJl1rfX0yui6RaQJmTnvA3789DIuPCuL344YSPOUWHYj\n0pjFcrK4HbDCzOYDFYdmet3DR2cCQ4GOZrYBuBsYamYDiHQNrSVyWWsRaSIeX7CBu55cwtAzOvGH\nGwaSqhBICrEEwd31WbG7jzjC7In1WZeIBO/phRv5zuOL+HTvjvz5xhzSmqcEXZI0kFjuR/BKIgoR\nkcbr+SWbueOxRQzJbk/hTbmkpyoEkkks3ywu5T/3KG4BpAL73T0znoWJSOPwz2Vb+ObMtxnQox2T\nxgymZQuFQLKJ5YigzaFpi3xTZDiQH8+iRKRxmL1iG7fOeIuzu7Vl8tjBtE6LpTdZmprjOtMTHZH0\nFHBxnOoRkUbitVXbuWXaAk7PasOjY4fQJj016JIkTmLpGrqq1tNmQC5QHreKRCRwc9fspODREk7t\n2Jpp4/Jo20ohkMxiOc6rfV+CKiLDPofHpRoRCVzJ2l3cPHk+PU5qxbTxeZzUukXQJUmcxXKOQPcl\nEAmJhev3MOaR+XTJTGf6+Dw6ZqQFXZIkQCxdQ52I3EMgm4/fj+CI1wgSkaZp6ca9jJpYTPvWLZhR\nkE/nzPSgS5IEiaVr6GngNeAloDq+5YhIEJZv3seNE4vJTE9lRkEeXdoqBMIkliBo5e7fi3slIhKI\nVVtLueHhYlqmpjCzIJ/uJ7UKuiRJsFiGjz5rZpfGvRIRSbg128sY+XAxKc2MGQX5nNJBIRBGsQTB\n7UTC4EMz22dmpWa2L96FiUh8rdu5n5GFxdTUODML8ujVsXXQJUlAjuubxSKSHDbsPsDIwmIqqqqZ\nOSGf0zrrv3mY6RqyIiGzee+HjCicS2l5JVPH5XFmF102LOwUBCIhsm1fOSMLi9mzPxIC/bq1Dbok\naQR0BSmRkNheWsGIwrls3VfO1HFD6N+jQW48KEkgpiMCM/uMmY2NTncys17xLUtEGtKu/Qe58eFi\nNu75kEfGDCanZ/ugS5JGpM4gMLO7ge8B34/OSgWmxbMoEWk4ew9UcuPDxazduZ+JoweTd2qHoEuS\nRiaWI4IrgS8D+wHcfROgIQYiTcC+8kpumlTM6m1lPDgqh0+f1jHokqQRiiUIDrq7E71LmZlpsLFI\nE1BWUcWYSfNYtmkff7xhEEPP6Bx0SdJIxRIEj5nZg0A7Mysgcs2hwviWJSIn4sDBKm6ePJ9FG/by\n+5EDubBvVtAlSSMWyxfKfmFmFwH7gDOAH7v7rLhXJiL1Ul5ZTcGjJZSs3cWvrx/IJf26Bl2SNHIx\nDR9191lmVnzo/WbW3t13xbUyETluFVXV3DJ1AW++t5NfXtOfL/c/OeiSpAmIZdTQLWa2BVgMlAAL\noj/rWm6SmW0zs6W15rU3s1lmtir686QTKV5E/qOqxrl1+lu88u527r/qHK4a1D3okqSJiOUcwf8D\n+rl7truf6u693P3UGJabDFxy2Lw7gZfdvQ/wcvS5iJygquoa/ryogpeWb+Mnw8/musGnBF2SNCGx\nBMF7wIHjXbG7vwoc3n00HJgSnZ4CXHG86xWRj6uucf7rsUWUbK3mR5f3ZdR52UGXJE2MRUaGHuMN\nZgOBR4BioOLQfHf/Zp0rN8sGnnX3ftHne9y9XXTagN2Hnh9h2QnABICsrKycoqKiGJrzSWVlZWRk\nZNRr2aZM7Q6HGncmLjnIG5uqGJ7tXHlmeNp+SNh+54fE0u5hw4YtcPfcutYVy8niB4F/AUuAmpgq\njIG7u5kdNYXc/SHgIYDc3FwfOnRovbYzZ84c6rtsU6Z2J7+aGueuJ5fwxqb13HHR6ZybsjE0ba8t\nTL/z2hqy3bEEQaq739EgW4OtZtbV3TebWVdgWwOtVyRU3J27n1lG0fz1fOPzp/HNC/owZ87GoMuS\nJiqWcwQvmNkEM+saHfXT3szqe8WqZ4DR0enRwNP1XI9IaLk7P3l2OVPnruOWz57KHRedHnRJ0sTF\nckQwIvrz+7XmOXDMkUNmNhMYCnQ0sw3A3cD9RL6pPA5YB1x7vAWLhJm7c/8/VjDpjfcZ++ls7vzi\nmUROt4nUXyzfLK7XJafdfcRRXrqgPusTEfjVrHd58JU13Jh/Cj++vK9CQBpEnUFgZqnA14DPRmfN\nAR5098o41iUih/n9v1bx23+t5rrcHtz75X4KAWkwsXQN/YnIPQj+GH0+KjpvfLyKEpGPe/CV9/jF\nP9/lqoHd+OlV59CsmUJAGk4sQTDY3fvXev4vM1sUr4JE5OMmvf4+//vCCi4/tys/u/pcUhQC0sBi\nGTVUbWa9Dz0xs1OB6viVJCKHTJu7jnuffYeLz87iV9cNoHlKTHeXFTkusRwRfAeYbWZrAAN6AmPj\nWpWI8Nj89fzwqaVccGZnfjdiEKkKAYmTWEYNvWxmfYjciwBgpbtXHGsZETkxT769ge89sZjPnt6J\nP944iBbNFQISP7FchvoaoIW7LyZy7+KZZjYo7pWJhNSzizfx7ccWcd6pHXhoVA5pzVOCLkmSXCwf\nM37k7qVm9hki3wGYSGTUkIg0sH8s3cLtRQvJ7dmeh0fnkp6qEJD4i+lkcfTnZUChuz8HtIhfSSLh\n9PLyrXxj5lv0796WSWMH06pFTDcQFDlhsQTBxujN668DnjeztBiXE5EYvfLudr427S3O6prJ5JuH\nkJGmEJDEiWWHfi3wInCxu+8B2hMZSSQiDeCN1TuY8GgJp3XOYOrNeWSmpwZdkoRMLKOGDgBP1Hq+\nGdgcz6JEwqJ4zU7GTykhu0Nrpo3Po20rhYAknrp4RAKyYN0uxk6ez8nt0plekEf71jr1JsFQEIgE\nYNH6PYyZNJ+szHRmFuTTMSMt6JIkxBQEIgm2dONeRk0spl3rVKaPz6NzZnrQJUnIKQhEEmjFln2M\nmlhMm/RUZozP5+R2LYMuSURBIJIoq7eVckNhMWnNU5hRkEeP9q2CLkkEUBCIJMSa7WWMKCzGzJhe\nkEfPDq2DLknkIwoCkTj7YOcBRhYWU1PjzCzIo3enjKBLEvkYfX1RJI427D7AiMK5lFdVM7Mgnz5Z\nbYIuSeQTdEQgEidb9pYzsrCYfeWVTL05j7O6ZgZdksgRKQhE4mDbvnJGFs5l1/6DTB2Xxznd2wZd\nkshRKQhEGtjOsgpueLiYLfvKmTx2MAN6tAu6JJFjCuQcgZmtBUqJXOK6yt1zg6hDpKHt3n+QGx4u\nZv3uAzwyZgi52e2DLkmkTkGeLB7m7jsC3L5Ig9r7YSWjJhWzZsd+Jo7O5bzeHYIuSSQm6hoSaQCl\n5ZWMnjSPlVtKefDGHM7v0ynokkRiZu6e+I2avQ/sJdI19KC7P3SE90wAJgBkZWXlFBUV1WtbZWVl\nZGSEb9y22p045VXOL0vKWbO3hlsHpDEoK5gDbf3OwyWWdg8bNmxBTF3v7p7wB9At+rMzsAj47LHe\nn5OT4/U1e/bsei/blKndiXGgosqve/BNP/X7z/lzizcldNuH0+88XGJpN1DiMeyTA+kacveN0Z/b\ngCeBIUHUIXIiyiurmTC1hOL3d/HAtf259JyuQZckUi8JDwIza21mbQ5NA18Alia6DpETUVFVzdem\nLeC1VTv42VfOZfiAbkGXJFJvQXRmZgFPmtmh7c9w938EUIdIvVRW13DbjLeZvXI7P73yHK7J7RF0\nSSInJOFB4O5rgP6J3q5IQ6iqruH2oreZ9c5W7h1+NiPzTgm6JJETpuGjIjGqrnG+/ddFPL9kCz+8\n7CxuOi876JJEGoSCQCQGNTXO9/62mKcXbuK7l5zB+PNPDbokkQajIBCpg7vzg6eW8viCDXzrwj58\nfehpQZck0qAUBCLH4O7c88wyZs77gK8P7c3tF/QJuiSRBqcgEDkKd+e+55Yz5d/rKDi/F9+5+Ayi\no91EkoqCQOQI3J2fv7iSh19/nzGfyuauS89SCEjSUhCIHMFvXl7FH+e8x4ghp3D3l/oqBCSpKQhE\nDvOH2av59UuruDqnO/dd0U8hIElPQSBSy8OvreHnL67kigEn839fOZdmzRQCkvwUBCJRU95cy/88\nt5zLzunKL67pT4pCQEJCQSACzCj+gLufWcZFfbP49fUDaJ6i/xoSHvprl9D7a8l67npyCcPO6MTv\nRw4kVSEgIaO/eAm1pxdu5Lt/W8z5fTrypxtzSGueEnRJIgmnIJDQem7xZv7rLwvJ69Weh0blkp6q\nEJBwUhBIKL24bAu3F73NoFNOYuLowbRsoRCQ8FIQSOj8a8VWbpvxFv26teWRsYNpnRbMzeZFGgsF\ngYTKq+9u56vT3uLMLplMuXkIbdJTgy5JJHAKAgmNN9/bQcGjJfTulMHUcUNo21IhIAIKAgmJ+Wt3\nMW5yCT07tGLauCG0a9Ui6JJEGg0FgSS9tz7YzdhH5tO1XTrTxufRISMt6JJEGhUFgSS1JRv2MnrS\nPDpktGDG+Hw6t0kPuiSRRkdBIEnrnU37uHFiMW1bpjKjIJ8ubRUCIkeiIJCk9O7WUm6cWEyrFinM\nLMinW7uWQZck0mgFEgRmdomZrTSz1WZ2ZxA1SPJ6b3sZIwuLad7MmFmQT4/2rYIuSaRRS3gQmFkK\n8Afgi0BfYISZ9U10HZKctu6vYWThXMCZUZBPdsfWQZck0ugF8ZXKIcBqd18DYGZFwHDgnQBqkSaq\npsbZuf8gW/eVRx8VbN1XztT55Xiz5hRNOI/TOmcEXaZIk2DuntgNml0NXOLu46PPRwF57n7bYe+b\nAEwAyMrKyikqKqrX9srKysjICN8Ooam22905UAV7yp3dFc6eihp2lzt7KiKPQ9N7K5zqw/50DeiY\n7tw2qCU9M8N37aCm+js/UWr30Q0bNmyBu+fWta5Ge5EVd38IeAggNzfXhw4dWq/1zJkzh/ou25Q1\nxnZ/eLCabaXlbNlbztbSCrZFP81viX6aP/Qor6z5xLJtW6aSlZlOt87pDGyTTlZmGl3aptO51nTH\njDTeeO3VRtfuRGmMv/NEULtPXBBBsBHoUet59+g8aaIqq2vYXlrxiW6arYft4PeVV31i2fTUZmRl\nppOVmc653dvRJTONrMx0Omem0yUznc5tIs91dVCR+AkiCOYDfcysF5EAuB4YGUAdUofa/fDbSiM7\n9i17/zN9aAe/c/9BDu9hbN7M6Nwmjc6Z6fTulMGnenegc3SHn5WZFtnJZ6aTmd4cM90bWCRICQ8C\nd68ys9uAF4EUYJK7L0t0HWHm7pRWVLF1b60demn5R8+37Ctn275ytpVWUFXz8T28GXRonUZWZhqd\n26Rxbve2H32ij8yLTHdo3YJmuvm7SJMQyDkCd38eeD6IbSe78spqtu4rZ+WuavYt2vRRP3ztHfzW\nfRV8WFn9iWXbpDenS3SnfmrvDh9NH9rJZ2Wm06lNmu7pK5JkGu3JYvm4yuoadpRVfKx7Zkv0E3yk\nqyby/GP98PPeBiCteTO6tE0nq006/bq15cKz0qP98Gkf7ew7Z6bRqoX+HETCSP/zA1ZT4+w+cDD6\nab3WSdZFickGAAAFPElEQVRDXTXR/vgdZRVH7IfvFD2Z2qtja/JP7fDRJ/gt76/gC+fnkaV+eBGp\ng4IgTg71wx/qitkS3akf2tkf2vFvKy2n8vAB8UCH1i2iI2fSOLtrW7Lapkc/vad9tLM/Vj/8nNLV\nnJ7VJt7NFJEkoCCoh/LK6sgOvVaXzLbo8MlD01v2lh+1H75zm8i497xe7clqm05Wm1pDJtum0ykj\njRbN1Q8vIomhIKilqrqGHWUHa31i/8+omo+6bkrL2XOg8hPLtmje7KNP7GefnMnnz+z8sU/vh064\nqh9eRBqbUOyV3J3dByprdc98chTNln3lR+yHT2lmdMqIDJfs2aEVQ3q1jwyTzEyvNaomjbYtU9UP\nLyJNUlIHwW9eWsWjrx+gdNY/OFj9ycsWHOqHz8pMo2/XTLLaRr7J+tEOvm0aHVqnkaLx8CKSxJI6\nCLq0TeOM9imc26fnYd00aXRqk0Zac122QEQkqYPgusGnkLV/DUOHnhl0KSIijZaGpoiIhJyCQEQk\n5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQMz/84jqNkJltB9bVc/GOwI4GLKepULvD\nJ6xtV7uPrqe7d6prRU0iCE6EmZW4e27QdSSa2h0+YW272n3i1DUkIhJyCgIRkZALQxA8FHQBAVG7\nwyesbVe7T1DSnyMQEZFjC8MRgYiIHEPSBoGZ/dzMVpjZYjN70sza1Xrt+2a22sxWmtnFQdbZ0Mzs\nGjNbZmY1ZpZ72GtJ224AM7sk2rbVZnZn0PXEi5lNMrNtZra01rz2ZjbLzFZFf54UZI3xYGY9zGy2\nmb0T/Ru/PTo/qdtuZulmNs/MFkXb/d/R+Q3W7qQNAmAW0M/dzwXeBb4PYGZ9geuBs4FLgD+aWTLd\nqmwpcBXwau2Zyd7uaFv+AHwR6AuMiLY5GU0m8jus7U7gZXfvA7wcfZ5sqoBvu3tfIB+4Nfo7Tva2\nVwCfd/f+wADgEjPLpwHbnbRB4O7/dPeq6NO5QPfo9HCgyN0r3P19YDUwJIga48Hdl7v7yiO8lNTt\nJtKW1e6+xt0PAkVE2px03P1VYNdhs4cDU6LTU4ArElpUArj7Znd/KzpdCiwHupHkbfeIsujT1OjD\nacB2J20QHOZm4IXodDdgfa3XNkTnJbtkb3eyt68uWe6+OTq9BcgKsph4M7NsYCBQTAjabmYpZrYQ\n2AbMcvcGbXeTvmexmb0EdDnCSz9w96ej7/kBkUPK6YmsLZ5iabeEl7u7mSXtcEAzywD+BnzL3feZ\n2UevJWvb3b0aGBA91/mkmfU77PUTaneTDgJ3v/BYr5vZGOBy4AL/zzjZjUCPWm/rHp3XZNTV7qNo\n8u2uQ7K3ry5bzayru282s65EPjkmHTNLJRIC0939iejsULQdwN33mNlsIueIGqzdSds1ZGaXAN8F\nvuzuB2q99AxwvZmlmVkvoA8wL4gaEyzZ2z0f6GNmvcysBZET488EXFMiPQOMjk6PBpLuyNAiH/0n\nAsvd/YFaLyV1282s06FRj2bWErgIWEEDtjtpv1BmZquBNGBndNZcd/9q9LUfEDlvUEXk8PKFI6+l\n6TGzK4HfAZ2APcBCd784+lrSthvAzC4Ffg2kAJPc/b6AS4oLM5sJDCVy9cmtwN3AU8BjwClErtR7\nrbsffkK5STOzzwCvAUuAmujsu4icJ0jatpvZuUROBqcQ+fD+mLvfa2YdaKB2J20QiIhIbJK2a0hE\nRGKjIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5P4/UXcC1lgnHc4AAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x299840c3d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, Leaky_relu_values_1)\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2998413b278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, Leaky_relu_values_2)\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFBQiIlIuBYWIiJRLQSEiIuX6/6j37aG95s6iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x299841bbd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, Leaky_relu_values_3)\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269d0c85a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_training\n",
    "#y_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_training, color='C2', linewidth=1.5, linestyle=\"-\", label=\"y_training\")\n",
    "#plt.plot(y_test, color='C1', linewidth=1.5, linestyle=\"-\", label=\"y_test\")\n",
    "\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269d0e9f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_training[:,0], color='C3', linewidth=1.5, linestyle=\"-\", label=\"y_training\")\n",
    "\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOI6T4UHBcRzHyfCg4DiO42T8H0cWl3UPlCWaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269d0ef9630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_training[:,1], color='C4', linewidth=1.5, linestyle=\"-\", label=\"y_training\")\n",
    "\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269d0f76b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test[:,0], color='C5', linewidth=1.5, linestyle=\"-\", label=\"y_training\")\n",
    "\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvWmUHNd1JvjdiMysHYUqFFDYCBT2hdhIFElxT1iWRHnT\nWLLalvu4bbdlWmN5uk+73cd0H9sajzxj2bLcbR0vMiXL8tIj2Or2SLIkkxQlgjtBACSIhWsBxF4r\nCrVX5RLx5kfEe/HixZpbVaYQ3zk4yMqM5UbEi3ffvfe79xJjDAkSJEiQIAEAaEstQIIECRIkqB8k\nSiFBggQJEggkSiFBggQJEggkSiFBggQJEggkSiFBggQJEggkSiFBggQJEggkSiFBggQJEgjUTCkQ\n0ZeJaISIzoRskyWik0R0loierpUsCRIkSJAgHqhWyWtE9ACAGQB/xxjb4/P7cgAvAHiIMXaJiFYx\nxkZqIkyCBAkSJIiFVK0OzBh7hoj6Qjb5WQD/zBi7ZG8fSyH09PSwvr6wwwZjdnYWbW1tZe27VGg0\nmRtNXqDxZE7krT0aTeY48p44cWKMMbYy6lg1UwoxsB1AmoiOAOgA8KeMsb+L2qmvrw/Hjx8v64RH\njhxBNpsta9+lQqPJ3GjyAo0ncyJv7dFoMseRl4guxjlWzdxHthB9AL4V4D76MwD9AN4LoAXAiwB+\nlDH2ts+2DwN4GAB6e3sPHj58uCx5ZmZm0N7eXta+S4VGk7nR5AUaT+ZE3tqj0WSOI++hQ4dOMMb6\nIw/GGKvZPwB9AM4E/PYIgN+T/v5rAB+NOubBgwdZuXjqqafK3nep0GgyN5q8jDWezIm8tUejyRxH\nXgDHWYx5eykpqd8AcB8RpYioFcBdAN5YQnkSJEiQ4KZHzWIKRPRVAFkAPUR0BcCnAKQBgDH2BcbY\nG0T0GIBTAEwAX2KMBdJXEyRIkCBB7VFL9tHHYmzzWQCfrZUMCRIkSJCgNCQZzQkSJEiQQCBRCgkS\nJEiQQCBRCgkS3CQwpvKYPzO21GIkqHMkSiFBgpsE1//+dVz/hzdgzhWWWpQEdYxEKSRIcJMgf3ka\nAGAuGEssyc2F4kQOrGAutRixkSiFBAluMrBi40xQfjBzBkb/+jQKY/NLLUokmMEw9JmXMfJXry21\nKLGRKIUECW4yNLpSmHtlGLl3JjD8x8cx/o9vgZm1K9VTKQrXZqz/r8wssSTxkSiFBAluNhj1O4nG\nwcQ3zonPc6+OoDA4u4TShGPm+aviszHbGLGcRCkkSHATQF5NN5J/Ow6u//3rSy1CIOZOjorPU49f\nWDpBSkCiFBIkuAlgzjirVGY0hlIojM5h/PCbHnlb+3tdfxsTucUUqyS03r5KfOaB/nrHUvZTSJAg\nwSLBmMmLz40SUxj+3AkAQNOW5Wi7Y7X4fu748FKJVDIorUFrTwMmQ6Zv2VKLEwuJpZAgwc0A2X1U\nbKyYwo3/9Y74LLvBev/T7UshTklgOQOU0YGUBjTIfU8shQQJbgK4rIMGsBRYwZ1LceWRZwEAHT90\ni/gu3Vv/7TLNvAkto8FE41hoiaWQIMFNAHlCaoTJyZwv+n5fGJoDALTdabmT2u9ZC2i0aHKVClaw\nLAVKUUPcdyBRCgkS3BSQXUaNEGg25yyloPrhC1esYO3yn9gCAKAmHUD9umW4+4hSWqIUEiRIUD+Q\naaiNEFPglsKy925wfW9MWQFzSllTF+kEmKjbBDaWNxOlkCBBgjpEg7qPtJYUOn9sMygTMFXZyqFe\nr8ksGKCMZimFBskPqZlSIKIvE9EIEYW22CSiO4ioSEQ/VStZEiS42dFogWYzZwWaqTmFjvvWYdUn\nD/huR7o9hdVpljbLG9Bs9lG9Ki4VtbQUvgLgobANiEgH8IcAnqihHAkS3PRwB5qrP4EyxjD2N2ew\nMHCjOsdbsC2FJh2Am2nU++sHxWdKWUHmep1wWc5xHzUKJbVmSoEx9gyA8YjN/g8A/wvASK3kSJAg\ngRpTqP4EOvKnr2DhrRsY+1KoYyA2eHlvrdlhza/9v+7Byl/Zh/SqVvEdjy3UY/CcMWazj7SEfRQH\nRLQOwE8C+MulkiFBgpsFfEKiJr0mkxOrsvuG5YqATkDKoZtqGR1NmzrdG+r27/W4Ci+aAEPDBZqJ\nsdrdTCLqA/Atxtgen9++BuBzjLGXiOgr9nb/M+A4DwN4GAB6e3sPHj58uCx5ZmZm0N7eXta+S4VG\nk7nR5AUaT+Zy5O1+h9B1jmA0AbMrGUb3VPe9X3WasOyqtcYceMideFaOvD2vEzoGCe++N3wibb9G\nWH1Kw8X7DBSq+AirMSb0HLDpKR2ju0xkZoC2YcKFH6qNYogj76FDh04wxvqjjrWUGc39AA4TEQD0\nAPgRIioyxr6ubsgYexTAowDQ39/PstlsWSc8cuQIyt13qdBoMjeavEDjyVyOvBNz5zF7aRCptgyW\nrVyGW7M7qirT2MWzWLhqeYtV2cqRd+jEcRQL85H7zZ0axfipN3HnHXdUNcO5GmOieH0eQ08dx/Y9\nO1G4NoPZ0WFks/dUR0AF1RzDS6YUGGOb+GfJUvAohAQJElQBRQZKayC9Nr5tOQOZGczKH6gAxdF4\nXdXIzmautvuqGuAMKq2psdhHNVMKRPRVAFkAPUR0BcCnAKQBgDH2hVqdN0GCBF6wogmktJr5tlnO\ncRmZ8wXo7ZmKj9m8e0X0RrzERR0mr/F7Qk0O+4gxBts7UreomVJgjH2shG1/oVZyJEiQwGIfUQ2V\ngpkzLNqKCZizlSkFXuY7f2kqemPbIqnHjGbO+BKUVMDKp0jVt1JIMpoTJLgJwIqWUkCKapOnkDOQ\n6moGAJiz/sXs4oLXPer8QF/ktlTPlkLethTSmkOdbQAXUqIUEiS4CWApBbImpxpw+lnegM6Vwlxl\nvYh5fELvbIreuJ6VArcU0pqTZNcApS4SpZAgwU0AbimQXv0aPMxgYAUTqW5LKVTaoN6099dao73b\nItBch0rBtHtCyO6jxFJIkCBBXUDEFNJa1bN/uZtE77JW9tz9Uy74/lpLjJCnsBQqOmVNwPKWUFri\nPkqQIEG9gRVNiZJa3VV1YdRqfFMYnAVlNLHSLxfmPLcU0pHb1rOl4LiP9Lp2c6lIlEKCBD9gMPMG\njKmc+0ubkmr1Cq7uapVPzC27V4CaUzAXKrQU5osA8QY6EeCTbR3mKbCCARAsthGfaetPTA8SpRAT\nrGDWZdGtBAlUjH3xNAb/n5dd37EiqxklVbhJ2tOWgqhwNTz9/ctWzaAYbTapnimpeds6IxK5CfUo\np4pEKcTE1d95HsOff3WpxVhU5K/NYP7M2FKLkaBE5C9Pe75z5ylUuXgdD6imdcs9tZir9jp2y7CC\nYbmOgLqWU0WiFEpAcXhuqUVYVIx8/lVc/4c3llqMBFWAiCmkqPqBZilJC3rllkJJqOPJlhWsew7A\nkbP+xPQgUQoJEtwEEMlrugYYrKpuDLMgsWw0rSJLoVS56j3QLNqIcp1Qw6rU1UKiFCRceeRZXHnk\n2aUWo+4w92rSA6nRIfIURLmF6lkLInM3o1mWQgXH5vWC2t6zJt4O9Wwp5B33kah3VIdyqkiUQgQW\nBm6geD1excYfVIz/41tLLUKCCsBMBhjMyWhGdVtyytRL0qmiVTtnLmXWxetlQPYMVreWgnAf2V82\nAFdlKfsp1BUWzk14vjPzhqe9YGF0DumVrZ5tf9CgmrlmzhD9chM0GPjKPaXVpKfx7MuDAKxyDtCo\nInoob8NJzTGnpjq2FMyC6STgcfZR4j5qHBSuzIjP/MEVrs14tpt5/tqiybSkUF5sYzIXsGGCasGY\nymHm6GBlx/BJHBMrecl9VM1gc3Fk3jl+hewjZlsKWnO8BUg991Ow3EfW/a7nwn0qEqUAoDix4ASE\n4EyAfgOtMDy7aHItJbifWPxdhy/dDxqGPnscE//fQEW1g4wbC+JzccL6zF1FlLaT11Bd95ELulYV\n95FWqqVQhytwlpes64R91DjIX53B0GeOYeqpy+K76195HYB/RcO223sXTbalhKleewPUbGl08PGm\nKuSSjiE9J17Cmn9HkvuoVs+TtMoCzY77KKarso5X4Dx5DUDCPmokFMes3ANzKi++K4zY3/mUAL5Z\nVsx8Ymrtt5RgI5T8bXjw7Nxc+UrBkMYxnyhdSkGvcWG2St1H86VZCvVNSTWs3A0k7CMAABF9mYhG\niOhMwO//lohOEdFpInqBiPbXSpZQSO+G1m4V4NKXWV2j/Ko9NkKVw2pAlC5os+7JzXLdSwnu7zcr\nUQoTTuyHT5S+MYVaWQoVJq9x1xkfd5Go09pHjDE7T0HNaF46meKilpbCVwA8FPL7uwAeZIztBfBp\nAI/WUJZA5K86wWTOFOAvltyMnONmmRx56QLdrmnP/65nFMcXGtqi4a6G3ICXCRcXcoVS4Y7iloLc\n7KVGMQXSKrQUctbqOk7dI34+UB1aCkXTqt+kuI/qMfahomZKgTH2DIDxkN9fYIzdsP98CcD6WskS\nhpnnrorPqslqzuS9jT5uGqVgTyT2PVl460bY5ksOxhiG/ugYrv7O8zCm89E71CH4Kn7quxfLPoZc\noZQrA8d9RFKguVbuI62iVTvLG6CmEqcljepuBW5KvRQAyc3VAEqBaikkEfUB+BZjbE/Edr8BYCdj\n7OMBvz8M4GEA6O3tPXj48OGy5JmZmUF7uzspZvN3NWiG9cDmVjC0Xrc+D7zfQO9pQtMkITNnP1Bi\nmOhjuL5j8R6sn8yLgdYRYO0rOkZuNbHqrDWwBx6KthaWSl4qAluetEz1q/0G5nvi77tUMqvoe0pD\nKmePv5B7HSZv70lCx5D1vAYPGJhdDbSOAmtP6Lj8HgNMAza8oGPwNgOzVeJMbH1MFzKvPENoGyVc\nOOTM0qXc397XrHfu0gPxZ/nNT2iY3Fjd97LSMZGaB/qe1jG8x8T0eob0DLDxOR1D+03MrKn+/BFH\n3kOHDp1gjPVHHWvJk9eI6BCAXwJwX9A2jLFHYbuX+vv7WTabLetcR44cgbrvZP6CVaoXwIp1K5E3\np2HcyOGBe+/H+JW3YLB5FOaswLOWSeGWdauxN7u5rPNXS+bFwNypUYy/8ib2vr8fw2dfQcuBlchm\nd0but1TyFkbnMPzkCQDA/gP70by1K/a+SyWziuEzr4p8mTB5wuQde/cM8lPTMOeK2L1tF9oO9mL+\nzBiun3gDB+/sB6U0DL9wArfu3I3W/asqlpkxhquPPSdkvjExgPnxUWSzd8eS1yP/xbMwkEM2e3ts\nGa4+9ULV38tKx0RhZA7DT5/Arr270Lp/lTU+nzuB3bt2ofVA5fddRTXH8JKyj4hoH4AvAfgQY+z6\nUsigtTgBLa05hfZ711l/GKYofdvz7/dg+U9utSpM3mzuo5QGfVnGqZlTpzBnJF96BYHapYQoswyH\nAVcqzPkitA6LKOEXU+Cfp753qRJRpRO6V71y8trUkxcxf7a00uuW+6jEzPkq9HCoNlxd14Ckn0Ic\nENEGAP8M4OcYY28vlRyuwaSRi+LGa5c0b+9C+11rrFr0DRzILAWuejZNekXc+cVAYchJKuT+3IaD\nNBaH/+REeYdYMKAHKYWUJmJksgKqBDyvQEBiH009eQnX/7600utmzqFxxgVpldVbqgVcRQKBhH0E\nAET0VQAvAthBRFeI6JeI6BNE9Al7k98FsALAXxDRSSI6XitZwiAPptmXBgVXHKZCKYP1Ut0s3dcc\npVCbxizVxsQ3zonPLFdZO8ilAjNZ/KStAJjzRUkpWBOTyGhOadBtqmfL3hKCLiFgSutNXjq73Fgl\nK6fGVgNYCk47zvqS0w81iykwxj4W8fvHAfgGlhcTxoRTFqDtztWuWiosb7jKXyClATeJpcBZLNSk\nV1wOeTHQvKsbC29YZLeJr5/DxNfPYf1n7q/6eRhjmHnuGlpvWwm9PVPdg5sMqe5mFK5ZVs/cqyOY\nPTGMlR/fG1s2c7YAvTNj0TR9LIVqZwB7aNu2pVCuC89cMOKXuLBRKQ22FjDVGk5JQbzGwezRIQBA\n291rsPwntjiWgsE8pqxlKdT/Q60GWM4q5kUagfT6v24/GmruwmTVz1McmcPkt89j8PePVv3YMEzo\nnU3iz/F/fAu5gYnY1imbLwImg9aeseIHfkohIrPWmC2UVHtJdR/xRVW5uRZsoQhqKdFSWOxubzFg\nKpnZTkbzUkkUHze9UuDo+tBWUeURsGMK80Wn9C1Qk6bn9QpWcAJ++YtTFSVULQbkKrcc86er31+6\nljkQzGSglIbMxmUiWAw4NYyiwGXT29OgtO64j7h1m6LIZK/BT7+EwU+/FF/mBR9LAcqKOOYrw4om\nWMEsz1KoU6VAfP5oIPfRTa0UCqM+DA9NiSmknVtEKbp5As150xPwq7cXjyNIrlqUOTfnaxhwN5hF\ndshoMCXlM/305ZCdHCy8YyluPm7FWC2alkLgq9UYPvi4bg7VfcQXVRNfH3C+i/nK8FpjsUtccGio\nP0thOg/oJGU0J+yjhsDw57wMD27+mpw9kFbcRzeJpWDmDGgZZXjUaVyB+6+XPdRX+3OpK+NqHttk\nIJ2gtbonRS1m7ILX7Mps6PC4j2RKcdDKWnYbcYrv+OE3cePrA5h7zb8lK/ed99hxD/H+SNYNxZwH\nDXsf9fqjUI+Wwszz16xud7YyoIR91MDgGj3HlYISaK7TibHaYLkiqMkyfdvvt3I36u3F4+ArTL09\ng8yGDqfODKovs+xDr/r9sC2F1n1uZpBrDIaAFzGktB6qFIK6o5kz7krBxmwBcydHMfvSIMa/6t+S\n1ZwtABqhaUun9YXuI2vM28TrNultJfJfqP5iCh4k7qMGhh6sFCrtKtVIMHOGYE7oy+3gZ51euwjq\ntaaw6lcPYP0fOKyjsa+cre65JEvBr2BiJeCWAlfG4vuY1glfzVNGA2V0UW2VFRRLIeU/juWqwMZE\nTpSxdn73BqDNuSK01pSzItbJs03J7qMSLYV6CzT7xp246y5RCo2BtrtWi8/C/OVKQX6Z9JvHfcQW\nDFEMTwTf610pSKSAlv0rAQC5tysr5FcYnsWVR57F9DNXALgnaLOCDmm+MC1LQW1FGZcNlLNjCpTW\noHdkRFyCFZXYWNo/GVGe9G987W2XAgSAwrA3BmcqZAz4VDeN6z4SNOgGDzSP/a13IeJkNC+2NKUj\nUQoAln9oq/MHz1NQMxKBihuINBLMXNHTSrCeXjwZwqqTkp66f3qH+OxLKIiJ4f/2CgBg8jvvAgAM\nqZxGtZUCM5hFAVaSt4zJ0hhPlNKhL8vAmMpZdf2LzL24yei+hIni9QXX36ol5He95kLRxRaqxFJg\ntmtOK5WSWmfJa35MODHT1pGcQUiUAuCq3e6xFJRAczVjCsxkuPLIsxj7u9erdsxqwZwuCCVAmj1M\nJIVoLhRFMH6pweXQ5JwS6ZlOPXaheueaL4q3ptruI5gM0ElkHXOUSoMlnaB3NoHlTbCc4Q00ZzRf\nS8GwYwrt96wFfJh2ftdrLhgO7RJw8nxkxJwH589et+Vr/DIXHiTuowaGpsQUUkpMoYrlHrgrauH1\nJakFGIii3fx97vgwALhyN/j/1/7PF3Htd19YGgEViACrssJe/cgdAICmHfErpqqQ8wUAK0Es1d0C\noEYxBU1z+dRTq1pgTuZC9rJQVLbhTCRjKm9N7ilnstYyur9CLzJQWrOuucjE9a38362miL5Np+aL\nLneXWEBIiB1TsC0RQZ2Nizrrp8DrS3X+yCbxndNPYUlEKgk3t1JIaWi/d63rK1KVgsI+qmrtozqN\nT/BVZOeP2oNatDy05M1fnFoKsQLhuPrcSkG0t5wqP+FM1FGyFWP+8rTwfUcpheJEDlNHLscvbWAy\nzxvJcgaMqXyktTD0By+7/uZ+eZYzAI+loAtF6jr9fBFae1q4b+RkOFCQpeB2H8mWAleocWIKZt5A\ncWw+ekM/1JmloHc3o2lzJzoeUPqGERL3Ub2DCF5zl7uPeNBLYR+hgmJfKuo1PsFZKOnVbQC8gebJ\nJy4siVxBEEpBoW6KTmZPllcmmhVNa/K0KZx84uEc/iilMPRHL2PqsQuYPxOdWc1MZrVvVCid6bVW\n45RizLiI3t0MAE7bzYIZ231kzhWgNacE+4lfJ6U1gAHTT3mT6MyFost9JMcUOLU0jqXgd+y4oDqL\nKbAFQ/R7d0GjhjAVbmqlwBhzfH02+KCee8Wi98kVG0m3Xg6Y1oRRSYN1oIYtESsED6aKzFKliFrL\nrhXW1x0lUgdrBFY0rexRhfni1wNi/vXrrjLbYeCTvm5fJ/+784ObQM26h7LpPYB9zjjlNvikplxD\nx4PWajP3bjzrjG/PY2GsaMZmHxXHF6x6V7qyMAropcEKJlBkbraUJH9hyFZkMeZBP2ZTbATkXSwV\nzHxA+W+ihmAfLXnntaUCYwwoMhgTir9WpdTJL4St5ZlhCn96JZU4ZaVg+ZNL9KXWCOa8WymoloII\nQJbq+60RVB4+h/odYwzX7aB+nOcmqK4dGRiTeZHcRS06tJZUpKWgtaZgzhWRWRfd1pHfWz4Gev/z\nQRTHF5BZ32H9XghfgKRWNKN4fQFt/VaPTX7tQZaCX88JZjDoHU5DJdmF2rS502MhO5VAI9hHMebr\nzC0dWHj9Otb89l3RG6vH1+vLfcTyhov0wEF1WI7DDzetpcCVwfxro+4flIlZl4J+009bXPWi1BXL\nL6EnLlxB65ixivk3x3HlkWdRHF+I3rhM8HsjXnbdzT4Sq8w6WZ0xgwl3iYqO924Q28jd2eJAZErb\nypGXbtCaU9Ba05HPPs2VgV+Wr+dk9r20J9X0yla07Oi2GuN0ZFxUWD8wk6H1tlXC/cQtA1b0so+0\nTECewnwRmtRlT+QppDSr0ZJSEVUoBZf7qLxAM8sZgFZG3SMgkpJqzBYw8c1zi1K3jDFect/fUviB\ncB8R0UeJqMP+/NtE9M9EFL+Bap2CD962u9e4v1ddEJLZvex9G63vpAdevBHNDAmEbCnEnGCv2xm6\nQ390TCRUVRu8ZzXP0XAsBbtsAmch1YtSKJq+kxFgB0lhTfBqMlYUeGyF1x4SGbfNKWht6cikMp5M\nFodSyu+tn7WY6mqCEbEI8LiIhKXAwArePAUYzPX8RFXg5pRQTOaCIQrpaU26x13KlQQFBJpFLao4\ngWY7YF0y8wjRlNTppy5j5oVrmD0xXPKxS4bBABOgJp/xqFFseu5SIo6l8DuMsWkiug/ADwP4awB/\nWVuxag8+iDJrFdM+5I6kVlhBPNntE7RCjSWDbB3ENCubd3aLz5Pfebf6XHkJ4gVVKKlC1jqpA8WK\nJhBQH4jTO825gi/jJgx8EtTsgKnBlUJLCnp7OtTymDvlWKAzT8dQ3lw0H/eL1paOfs523SQO1VKQ\n7w9X9rJLSmQ/G44CYQtFUMruMdyc8nS0c3oGSHE3acHEFbJsKTDGMPXUJeQvT7uPtVAsOZNZIMJS\n4FRlY6qCBVxMMJ9CmkKOkJLl9YQ4SoGPnB8F8Chj7NsAIss2EtGXiWiEiM4E/E5E9HkiGiCiU4tu\nfQQE9sL8+rKflqPUiUYGK8NSUBk2ZdP4QtC8o8txfUByCRSdPAWgfiwFhFgKmnD9FCL98ip4SQuh\nWGZ5GQbdmqhnC4FMtPH/983SziUSBX188gEZyK79Deby54uxmjd9KanWb5JSsK81s77dCTTPF0Fp\n67PWnII5b7iu1y+mIFfW5W4lYo5cuYEJTD1+ESN/ftKVK8EWDE95j9iImGwFUWC6AlcvsxJNrzzy\nLIrXg985kUjp11JUYh/x8ik8J6ieEEcpXCWivwLw0wC+Q0RNMff7CoCHQn7/IIBt9r+HscjWR6C5\nHhbs5S+aNJlXktUrxxTiriDUFWPcEg58UE9+92L0tuoEIywF+7oli6EeVj7MTrryA1cKxmzplgIv\nL8GTkXhyFXcfsYLpe8yCj6IOm0isk9nH8VMKaS1SoTGDuWIX/H74MYi4UpCDzXKnMDnQzD9rLSnr\nefsoEhclVbIUhFKQbpFM7JCTHz35DiUgkpJq39NyGiTNnR7D5BMXXCVAhj4b3E5eJFKqZecBy1Sw\n78X41962/v9H/+qzS4k4k/u/AfA4gA8wxiYAdAP4L1E7McaeATAessmHAPwds/ASgOVEtCZk++pC\nCexxhFoKfFtpAFYUvJIpqTFX3eZ8Een1zio+ytfMwZkk09+L5uz7llqWZZRFrQelYJi+rBfAHST2\nC66GYfblQQBO+QzRTatJd2IVPnEFue83R5T7R1gKfuwduWFOEEzTayloJOIi7kAztyKc+8EpoVqL\nE1OQm0wJxShdB7MbDrnYR3JZmBY7aCwNEZWGzeMyrFL3UdgwtBdf5bhax//HG5j+/mUYUUrdRqj7\nSHOec/N2K8u+eevykmWqNSgsEYuIdABnGWM7yzo4UR+AbzHG9vj89i0An2GMPWf//T0Av8kY86hh\nInoYljWB3t7eg4cPHy5HHMzMzKC93ZpQM9PAhud1DB4wMOsUSQUVgS1POg904CHnxWm+Aaw/quPa\nQQNrXtFAjDC038TMmvImxvZBwurXrJfu4v0GCm0+Mk/PYPV0B2ZWW9muG5/WsLCcYXg/w+YnNExu\nYLi+M/r8eg7Y9JTuuSY/rH9Rg5EGBvutFzg1B/Q9o2N4r4npdQyrThOWXbXkPvfDBpj0Lsv3eLGw\n7qgGRsC1O30mThPY+oSO69tMFFqA1acsueV7ECTzmhMa2kYJgwcMrDmpY6aXoW0YOPcBE62jwNpX\ndFx+j4Gc8l6vfkVD+4h7cvfbTkbQeASAFW8ROi8Szr/f9JeXAVsf1zG+xcT4NmcsbHpSw1wPQ8eQ\nhpHdJqY22HkmY8C64zrGtptgGjDZx7D1MWtsXLnLQLEZ6Hva+nthGcOVe0y0DQFrTuq4dI+B/DLr\n+N1vE7reJZx7vwm5hwU/1oUHDfQ9rePylnnktlke565zhBXvOArqyp0GFrqBjUc0zHczjOwr/V3q\neZ3QMUh4973+inP5u4SetzTk2hku3xdvEcfvMb+W4b0mek9rYMSQb0PgcfgccbXfwLy7LYbrGrsG\nCCsGNM80QRC7AAAgAElEQVQzKxdx3rtDhw6dYIz1Rx0rVDUzxgwieouINjDGyksLrQIYY48CeBQA\n+vv7WTabLes4R44cAd83f2UaI8+fxJ59e9Gye4XYxswbuPakZda237sW2ewW8Vv+8jRGjp7E3r37\nMH7mTbCcgV3bdqCtX3mLg67DZJh68iLa71kLvT2D2RPDuPGaZUbe2X8H0r1erfDy145g9SkNzYVu\n9Pz8rbj69ItY3rcSu7Jbce25l7C+dwX2ZrdFnrs4voChp44BAKLu3/Brr0Bf3oQd2VutfScWMPTM\nMezcvgNtd6zG+PBbmLtqJffdd/e9rgJu8j2uFYzZArQmXax+h8+ehNaSwvasZ+0BALjyxLO4pX01\nMn3LMHHKahMpyxgk8+j5MzCbCtiz5xZcP/kGVnR0IX9jCtlDDyB3cQqjr7yGfWt3ou1O9/O/8tiz\nAID0LR1o2dWNqScuYvPlTvT+b7cFXlP+2gxGnn8Ve/bsQcse92wyVbyIqXcv4cEHHgRp5JGXFU1c\nffx59G3ZhH3ZDeL7a8+/hJ6ONuSGJrBjl/XsAFiyH38NPW9b92/vh+7A0GPW2Ljrxx6AOV/E4NNH\nAQDLujqRze7HwrkJjJ08jdtvPYDmLZZ2uzE5gPmhUWQP3e2S17zbCm6vYQyDTx9Fc6YJd2cfBABM\nzJzH7MVBdH10O8b/x5vYe8tOtN2x2hrXG1did3YrSsXE1DnMjgwjm73H9/cpXMbUWxfQqjchm42X\nB8HvMX+W29ZuwtTpi2jduxL6hanA4ywM3MDY0TM4cPttaNrc6fpt8OVj6Oxdht3ZHZgsXMT0wCVs\nvGUD9mU3+R6rFFTzvYvjPuoCcJaIvkdE3+T/qnDuqwBukf5eb3+3KGBx3Edq8FJyo4gyAiX4qXPn\nJjD9/cuif20pgeaFt29YtMEFp349+dAEg+A6VwRXmhlq+0bNJaNr/yVgIA1++iVc/6oUyFXdXT6Y\ne3XExXiJU6qE8V4BUukT7hZI2eUkwmph9X7ygHDpFK76lFOWETAeASk7OcCFJBLflPFKGd1xecns\nI8VFOvSHx5w/UuSSgY9zPubkLG6554YMrUmH3pZ25JFutTlXgNaSRstuS/FNfd9eayqU2pIQVRDP\nHvvGZL7sGNjU41YsTu/IePI1ZIg4oQ8rUWYf8RiR3/t75ZFnMf5PSxdriOPE+50anfubAH6NiA4D\nuAvAJGNssEbn8iKI7eFTRtv5wv6fMTHgSwk085dXBPhk/2rAYDV153dWMAHmMBu0jC5iBZHnlicU\nE0AI0YMV3YFmMUnwCVCOqVSxamwc8ODmwlmnsqwVA4mmBvOqr9ZOcLk8gs6V7mpyAu0LhtfHHtVT\nwSdGxQwTxmReKBYgin0kUUj9WC38uSgKRUtrTjc1SWHIMSnPuYjcCwJbIXGlIPvlzYWiP8uGw5bH\nRUnNG6AmXdxTw87zseJC5SoFhCaFyQuu4tg80qtayzsP7PhO2ELIfqd9FykS+4gvJtX3l88nc6+M\noPvf7MBSIPIpMMaeBnABQNr+fAzAK1H7EdFXAbwIYAcRXSGiXyKiTxDRJ+xNvgPgPIABAF8E8Kvl\nXUJ5EAMlhJI6/bS7SJerhLTSjKcsGWT2UYClIF4oBunlt5PKmkpQCi4FFLG6L5qu8h5q6WyXUlhk\nS8FvZeUJjMc6ULQyM/0sBTvoTLoGrS0VzWjxOc3kv17A0B8dc+9rhFkKEr3U7xTcUlDuAaV1J9As\nWwpEQqn5gUIsBVeg2Z7gA49j3ze5zIUcvBbfmXbCV6nPUJyIQi2/qlKndc1VHNFzrjClQBDjgc8b\n6vxRatZ9LRBpKRDRL8MK8nYD2AJgHYAvAHhv2H6MsY9F/M4AfDK2pNVGCNuDo+09ChmKJ3NJVEy/\nF5UVTVz91Avo+cU9bnYBp8GSs53zG8Pk4xegt6fRfu8655TyKqvofvm1Jj2y/IHYV6I0MpOFLpJV\nSqpQgNx9JF/yIucq+ClBy7IpcUKJcqExq5+A1iwrBcPpVw1AX9YU2BWNK4+W3StE1zaOhbctUp45\nV4Bul5cOtRSE+8h/AcCtQI9SyGgi10K1pOR+zBwiMVJWCva5qUkHNMVSyBnh/ZT9LAVJKTTv6IIx\nU5Am0vISQUmievpCWriUuohr2tyJ3PlJAEDbnaude6wkC4rjhyoFyVKwn5lag6oc2my1EedN+iSA\newFMAQBj7B0Aq2op1KIgIHlNRtMmd6DI1ShDFIfzDrLC4CxgMIx96bT7lGqZAHmwmgzTT13GxL+c\nd5/TpRTcL0+UpZC7MClWUO46S9bnqSOXMfplb26hp4CacB/5WAqLTEmVX2rHcjF9fbihx4mQm+VN\nK3bUknKuv2i6qIZBmcaU0UTwOdXT4vm9OGLRG+fl5krCUggu7BfkqhPjIq2WaFG6Bkpo2atQYwD0\n/IJFLJBLTfAJnIjsBDbJUsgZoe4jIrJdO25ZhaVgr7qFG3UR3EexKtbKkO5bYWjWiSUGWMjqwk2G\nFVOwt+OWgvL+zh4bco61RHTvOE8hxxgT6ouIUghnBTcE1KqUfvAMeCnQLOoA+VkK9sOUV5XWtvYA\n8HnJg1aBZDryiYQ7e3/KBAeac5emMPqFU7j6W895js/lm3rsAnJv3/AEMJnhdh+pPZpdg3WRB65c\nCJC/UFGWQs/HfVhJEV6vuVet+EPunRuuhYOcsUtNum89JbUnstae9nWz8OAlEG4pIHIiCrYUxGfl\nN7Xe/7If3gA/yJaAWhnWzIW7jwDLzeaxFPj41QnMMAPdX7FBVp5CkAuJFU2QnS0dVa/KA2l8dzyw\nXoyzoLL3oVaPZClwCyHMcql2D/C4iPMUniai/wqghYjeB+BrAP6ltmItAmJYCh5mBd+WMbGy8ws0\ni5LDimuKfy+CpHJmtLwCk1Y2rgqTit9ZC7EUVGXlDjS7Xx451Z6XFHf5lYncNevl/Rd5eSBfL79n\nVjZv8HNs3trlVdBRloJ9rU1bl7t7eMsZu80pDxPF8o+7q7Y2bV0OymiYef6q67yu8RUyHklTLDVV\n1iCloAcrhaY+txWcWuG2aDJ9VjKCS7GoSmG2EO4+AgCNgmMKdslrx/1VpvtIvJcBGxhMyOkiG8SB\n/LxaUpKCDn8WCAw029tx9pEyf2iuYptLUwIjjlJ4BMAogNMAfgVWgPi3aynUYiAsg5RDtRSIM+xM\np8KkbwnigGqcYe4j98vm+BV93UdyoDlv+E5wquURRn9lPiwoD71RJ2+ZCyyB+0i+Dn6NIRnNHJ6+\nGRFy80mkZU+Pm5EmKwU/S8HwTgrmXBHmdAET/3Ie81KhPDmw49BKfZQCX50GWQoF/4nI5QJUfmvd\nvxKrf/MOdP+slZeqMpLyF6ymPnJHNK0lJSiprGi510LZR/x6PErBCdajyDwWcMngtywo+KuMj1LG\nLI8ndH14G5o2d0p1wAJMzchAsxKLVKz0mReueY612IjDPjIB/C2ATwP4PQB/y6rVj3IpEcdSUAe8\nFGjm+/v2uuU9fHMGJv71XTF5qat6l/tIUgrGlL9S4ErFCTTb3HEf15NHLlkRKC9F7p0bHpk8g1qy\nFFwvVYmB5uL4Agb/8GWXGyh/bQYLb4VVRHHgdrmZgW0sVXjaI0YMYXPK6SkhTyiu3gEtKbCcWyn7\nBX1zb7vvb2aD3ThHjkeEjcdUTEtB5fnLCsYnByDV1YzWfSux7vfvRXqlP01TtjBl91FQX2wPdFIW\nNoYTE7MXGuKZlh1TkCx4H3DiBB8DJfciSZEVZCaSYgpBz8IKQPu6AYmEiCKmIE38qlyLTffmiHwK\nRPSjAM4B+DyAPwMwQEQfrLVgtUYlMQV3lVTr4ebOT4pic7wmjDlTwMzTV0TwWPVDsgD30cJbziSi\ncrwBOKwOWz5fRk5etUqC6a8LrkmLrzqVoKVOzn6m464p1VKYOzUK40YOM885eYojn38VY39zNtb+\nruB8wQylcspQuelRbREXBqxeCDL7CHArBT6Ry+09Hf+4s09GIixMP3PZ37ILYx8JSyHgXgexj/zI\nAj4IW6Gnb+kQn2WlwFfQPPYSeGxN83Ef2e+V3fMc1WAfIeSZ2sUCeXHE0b88Geu4vH9G89Yu51wx\nYgpB10GypWA/MzctPcTlu4iIo5o/B+AQYyzLGHsQwCEA/622Yi0CwjJIORe9yR1TID+lYD/I0UdP\niWJzajArd27C3lZxu0hMDFkpTH33ojNJ+CgFmZIKBHD35XMVTXfmMT+2vX/zLqfMBwJMeavzlr1K\nZNLvJRqNKdu3n7/mzfCN1bO66FYKwvUQoRSad3W7v4jpPqK05pqoZaXA2UNTTzoVYFQXHwB03O9Q\njIsj8441Ia/eA/JmrGOVGWh2UUtLW4WvfHgvAGDVr+xzjtGUgsl7KtgTcev+leEHkiwFxpgrpkC6\nBlYN9xHfLdBSsNxHnR/oA2AVRzRmoqmfnAm08KZkxfpUSvacK+g6SIop+FgKXEHwZl5L1cM9zlOY\nZowNSH+fBzAdtHGjIGxl1vsfbkPXR7Z5JxquFHweJEfu0pSHNdDCXxxlomZFU0zMKrXx6n+1WENh\n7qMwSwHKitq3TLfpXrXI16Neu9aScpSPKTViKdFS4Mcv+pT8LgzOer4L2p+fO6jEg4r296wFAGQ2\n2dXcYsgt6KTSsWWl0LzDUjR6p9NexG+C5s2ZOHg7V9d9N0OUm0oJVhDoPnJZCqVNuE2bl2P9Z+5X\nspvtGIDJMHXEijVkNi4LPY4rpmDYrj6ZfWSavoq0JMhuXR+womUp8OcFAIO/fzTOgb3fcCsgiB5c\nMP2DzPxwJhPKkcssFnD8PvD3ut6UAhF9mIg+DOA4EX2HiH6BiH4eFvPoWNB+DYMQH26qp0UUD5Mh\nAs0yV155cJPf9nZD4wwVl+85b1i+zoy/UgBsU1u2FHLePAUgwFJQso5dq0wlNuAOQges2uSa9XJP\n5BJjCoJ1Meu93jjtMj1B8YASDyoorWH9Z+5H+11WQqIcFkvNAfNKTIPlDKcdqRxolpQCz0XIbJAm\nRn4/ZKXQo/jr/W5ZGPsown0Ux1KIuj9xIDKrcwYKvI5UVPtMjUSTHY/yst1H4rrKdh9Z/wcarYbl\n0iGd0LyjK2AjH9j3rGmbk4AaFfSHwUItBcacxQDPKhf0dvt/Xoq87pQCgB+3/zUDGAbwIIAsLCaS\nNyOnwRAnpuCBaimkSGh3/oDzF6c8E7z427N6N721+iWa4tzJkYCYgtt95BtTUAPLaj9e6Ttfy0dl\nH0l9cBljzqRXovtIXh17lKckR/7ajG9XObWFaVxLQcBnVbnxGQ3XlZgGkxPV5JQNSSlo9uQ28Y1z\nzn4+9Mow15ZILgxlH0W4jwr2vqqlIB2qnN7HHjn49X7bSbDMSDEH3300yX2kuM1I1wAGpzFNpYHm\nQPaRk8fS84t7kFplTV9RfBn+DLs+sl36LlpBR8UU+HssxlLRHV/gHeiWKqYQWOaCMfaLiynIoiMk\nphAIHtDimr7JaZMolw3IvzvpPhVnbMjP2GS+7iO9LYUiL03QpAfEFKIDzW5XlbtJOwzmHnBF72fP\nwFbyFMp2H8lWVsF0LS9kpTDy+VcBAOs/c7/7AKpyC5lMfSES8ZyvyJ49Z168huYd3Uh1N7vq+gTF\nFMTKeUHOMfFftXd9dDsKQ7OYedZdCHjh7Rto2dEdzj6K6z5SzulXyqISaLaSNCYdem/kokonwPam\nemIpXNnxcV2uNRPBPoJhut7z9Oo2FEfmYUzmkFre7L8PgMI1y52ptUiEEym73Q8spDUsf4fE82pN\nA9cXxN9i7NSxpQAAIKJNRPQnRPTPVS6dvaQIzSANAGkEkPQSNqVcgTIZulQB09dSMJmVJMYrYNrb\nyG3/AHiyQQFnRRUaaDbVydN9bleGs4uZ5L9qky0FWSmUmtHs50cXf8eg4JXrPuLgLkA/uSe+cQ4j\nf3FSyCl830ppC3Esn7LRQf7xtoO9aL93rWd70651Ey9PIVwpqPeAU1+rBT6Zc+ZRrH2k5DU+5hxL\ngVzfl+viEuwjBkw9eRHDf+qu16nW8mqy+0FEFZ/j412TCCfxLIWQmIIUT/BYBEX390uVpxCndPbX\nAfw1rFjC0khZCwi2R4kmK5HzUDM6DJP5rtRbdnWj49AtmPj6AAp2rRuV388Mx30kAlSyKyfvjimY\nCvuIwpgQLsvAhJqnoBbjE+cUeQo+lgJf0ZgMmmhN6j11GFwWivpi+VyHmTdcWZ6saIr4BjOZFBgv\n0X0kyg14q1QWxiyGkGChSW4Zl6XgWxAtwJUDuFalrf29mDs+7FWuoZZCCPsopXlcRH4tISuBuKZS\n4kgy40a41twWWMXuIyl5TWaCAUBhZA7F0Xlk1jsKMt1rxXiiLCljKo/0OndSXywmWNyYAn/3+f2R\nx45OS2YpxFEKC4yxz9dckkWGmKBLHYcaSZaCvVK3A8nLfniDGJRaSwp6ewbUnHICqEquACua7uQf\nD0/ZEEE6AN48hXSwUpBX4cxwu4/k0gLq/mKw+wSa/SyFUt1H8iQcmlnNt5/OQ5NKMDDbumILhiuJ\nMPYqU8mvkF0hHMN/fBxaW8q94rMVdqRlGbBqVyEmJonRBSCckqpYUgvnJiwZC/6r07IpngFQFV1G\nKRjpC9lSUAPNfAwpbtGSERJTGP6TE9YHOQHRphvzPIQgyA2tBPQIxVhkoGb/+06cfaTMH4IFKLkB\nKRWjL3eNEEcp/CkRfQrAEwDEG8QYi+ypUNcwGaCVHoAjTVrxZNw5BnqnU19HmJ6tUmkAz2pdYSow\noGXPCsyfsfjvqqUgVlR8n7CUezWGoLCP/HIt5GP5uY/Eis+EozRKLXMRklnt9xIYMwV3XR7DCgCz\nBcPlFovrjyY10BwgvjlbdNX9Wf1f+mFOebntqd5Wd92qsDIHsOirxmRejBXBTDNCxqNSkJBj7ItW\nFd62O1d7KqQCgFHl2jmy5ZFa0SxyGUL30X0sBe4+4iXJFQJFyZCrF9sQFiWXQy5QyEkhl6bReiC4\n4LO5UER6Wcb1XRxLQUsF1IOym+zwkitiQciVgrQgo5RWvzEFAHsB/DKAz8BKZPscgD+upVCLAatR\nThmDULIUBHOIB4allRSfKLSWlGAaqX5+GKbFYJIGbNvdjt+ZFVWlYFgTB29eolGgmemJE7gsBVOx\nDpjnc80CzYb/eQFnQpWPqfp9LevKUUglu49ETME+XshqTH6eqc4mX6ZNuqfFtZoMK50MQPRf0JpT\nAEk03JDxSEQ2fTOIfeRvKbTeVt0K9/L9KF5fiLegIkgxhSBLoTTF7jmF5D7iYHnDVS5GdvFyS8FV\nZ8gHxZF5bwJrgNUmzhMaU7AU5Phhq9Umz4R38hScuJKlFEpccFUJcd6kjwLYzBh7kDF2yP73Q3EO\nTkQPEdFbRDRARI/4/N5JRP9CRK8R0Vkiqhnjycwb6H6HnEnJYKXRUW2Q5FsX7B+pD27vf7odANCR\ntdpP8yCVmTPsVa5jfnKmAi/H3HqwF81blmPdH9xnHddQYgoFL7OBZ4V6L1hxVRnMvbr3YRwBwYFS\n0iVKqlwFtAJLgRmKouRKIcC1xa+Fs2BgQipAF/NZiqCkl47r2TSOT16NA8XMzqVm3XrxBUc9fDwG\nPmcET0RVdx9lSj+ey8IMsBQqZh/5JCqYeROmlLUsu4r4eYPakhaGZrH1MevZz72ilPGQm+z4gIXm\nKdgyigC2v6VAKc1q+1nHlsIZAMsjt1JARDqAPwfwQQC7AXyMiHYrm30SwOuMsf2wciA+R0QZ1ABT\n372I7nMa5l4Zsb4wWWgxvEBo5KwG1RyDlIZ0bxvWf+Z+pLgrSaITMoM5cQB7tU4pTTTzab/HshLE\nytBkINN5GVnO8OYPpKMtBc7S4cqHye4jUrYVjcdDktcqsRRMr1ziN/vcLmaUT70ocT9kSmrMZykm\nHp9sbs+2MUpDqGZ+3C5imXXt1jMuOvc0NA6hU6jLIkjW3v98EKsfuSNUlriQJ7um7fGSwHLvTqF5\nyk3lljOaAXjyb0oG3012H+UNV1dCdZym17RBX+Yupw5YweXh/y55xpXhHZ0zEmwp8CY7rf29AKxF\noCybbPVSqr4DzcsBvElEx+COKfxExH53AhhgjJ0HACI6DOBDAF6XtmEAOsiyQ9sBjAOoLrman4g3\nZJFXu+WsTCT2kRNo9rqPxOaaNIhMSSkUGay+tITOD26C3tOC9Oo2Zz/dUj6WUtDB8qYVePYUqgtY\nUShuGlkhuYNdKcWl42/KV42SqgbbXQrJayl4GUoM1J5yrqPUBi1KTIHfhxX/bjfmTo5g/pTTmUtQ\nA8MOlyL3Cj6snj6Aro9sw8wL16wXX7W+Qi0FCrzXYS6LoOqn5UAmRciVX0P3SRN4iy5W5JRUqSAe\nrFU9KL5i95xDFMRT3UcSiUC5d4XBWd+yKjPPu/NIeGlxAaU1rQfcJewHO6bAezqIXhT8WDK9WrFA\nFxNxlMKnyjz2OgCXpb+vALhL2ebPAHwTwDUAHQB+2i7VXXXwvAHh/y3TUiA5pqAUs/N1N8iWgsmc\nfrtSF7ZUTwuWf3CTez9NcyyFJh1AwQo8q4onwMx0019NV4YuZz4B9sQn1xMKK50tZzSXSUmFYil4\nCvcBwUFw+28+OTHZ0oidp+AOSnKrJNXdjO6f2Qn2EQPXPvUiAHiZJ37H81gK4TGOtjtWOyVUNM3d\nuCiskmmY+yhkdVpNlFpUDwBa9q7E1AnLd++b0Qz7XSjXSgB82Ucsb4pqxdbJ1BgZPGN34Z0bmH76\nivi7+2M70LrPXfCPW/HT37uE4sgcVvzbXa7fQ5+FHVNIrWxBcXTeGYvSwoArx6VkH1GtWiMQ0U8B\neIgx9nH7758DcBdj7NeUbe4F8OsAtgD4LoD9jLEp5VgPA3gYAHp7ew8ePny4ZHlargPrjum4cqeB\nhW5g1WlCy3XCxWxpN37j0xr0PKAZhLEdJnre0jCxwcTySxou3megoLgp2wcJq1+zflt7XIOZBpqm\nCcN7TPSe0TC608Rkn/cZ9H1fw2wvQ/MIgDShaYZgagzFZuDSA47MtzynodAGDN3mvo7Vr2poGwYI\nhKH9JpZfsMoNNE0TRnabYBrQe0ZDroOBEXDlHmv/5ecJPW9rOPc+A0zScSvPENpGCRcOmdjyuIaJ\njQxdFzRc32bixhZH/pmZGbS3+/tqAWDdUQ1Nk4BmEq4dNJDrADYdsU40tdbEyD6Gpknglhet78Z2\nmJjY5Bx/49MaFpYzdAxa5y42A72nNVx4wEAxxqKYH/va7QbmVgHt1wirT2m4eL+Bgm2obf6uBs0g\nDB4wMOstgeXCircIyy8Qzn3Aun/dbxO63nX+DsPGIxrmuxlG9rHI8bjhGQ25Tobh/UzcY+73Xuhk\nMNLAYH+NJxET2PqEdc6JjSbGdkXPHT1vEDquEN59n4muc4QV72gYeL9FmODv5MIyhswscP595cnf\nOgKsfUXH5bsNMW6uHTTQNGWdb6aXYWyH6Rof8njm4PcTAGbbixi8z19J8/EBWONzcgMT78qWxzXc\n2MQwvt17b3pfIzRNEnKdDE2ThJG9JtYf1XG138B8j3ssrX3ZKjl+9a549yTqvQOAQ4cOnWCM9Ucd\nK3IpRETTcDxrGQBpALOMsfDyiMBVALdIf6+3v5PxiwA+YzftGSCidwHsBPCyvBFj7FEAjwJAf38/\ny2azUWJ7kDs/gdFjp3Fg3wE0b12O8eG3kJufQjZbmr916NgxFPM5AAxbd2/HxFsDWNPdi/lLo7jr\nnvcg1e1Om58/M4brr72BOw7egbHXziDV1YT89DR2bNqKiTPnsW3nNlHBU8bgC0exrLcLUyNDaO1a\nhvzMNDST0NrRimz2oNhu+PSr0Dsy2Jm91bX/2IWzyN2YBMsb2L1zF6bHroJ0Qn56Gtu3bAV0wsSZ\nc+hY0QlzviiOOVW8iKm3L+GBQw+6zPkbN97B/MR1PPjgXbj62HPYsGkDpi9cxqa+Tdif3SC2O3Lk\nCMKez8jrJ1HMzcOcK2Lv7r1Ir2vD0BGrvmLvql7szu5E7sIkRl88BQDY3LcZy7LOMLr2/FF0ruvC\n3OAw+jb0Qe/MYOL0AN5z791OHCcE+WszGHnxVezdvQcte3ow8/IgJk4N4D333S1oouNDb2Lu5CgO\n/NCdnj4MKiYLFzH97iU8+IB1v25MDmDu2iiy2bsjZRk8dgzLVnVgd3anNR4Xgsfj0Inj6Oxpw67s\nLnGPrzz2LACgo6UN+ooW7MiqIbvq48oT1jlXt63Enhjnm5g5j6krV5DNZjGZu4Dpgct48NCDICLr\nOR87hfZMK8xiIdY988P8W+O4/spZ3H7b7Rh98TUAwJ6dt6I4PIepdy5hx3+8HzsVr8DE3HnMDg8i\nm33AuTb7fgLA8F0UOI6vPfOiSHzreUvDptXr0fnBTWAmw9XHnkPf5o3Yl93o2W98+C3kclPo7GlH\nwZjF7f07MHL0JPbt2YeWnd2YmD2P2SuWTKMDp8EKJrZl98e6B1HvXSmIVAqMMcHDs33/HwLwnhjH\nPgZgGxFtgqUMfgbAzyrbXALwXgDPElEvgB2wSnNXH0p9lCgfbuhxuB87o7CP/NgZor+uCZhS/wSl\nZIUHvAEJc5vtfpUwg9xHlNFENVZWNKE1Wz5MxiAas2hNuov2Kfjy6r3h7iPmnJefpxQwOR5h94MW\n4AX6QthH4PXqNbgK/cXOU1BNdp9Wll0/vQOdP74FeltE/2FIRQkLhhWfKZjQmuK5QkjuZmeEJ8aR\nroV2+1oM95EMv5IdvpDzFHJWPSkeA6iW+8iTewKA5UyXO0aFZj8rtQQGYOeepEO6AyjbO2Vs7PMH\nXYuUvEa65nV7yb3G5RjeIqOkJ8EsfB3AB2JsWwTwawAeB/AGgH9ijJ0lok8Q0SfszT4N4B4iOg3g\newB+kzE25n/ECiFoa/bfhllWTMHVhUtJXvOlBQq2Ag/2uovYBTIVdM2aQBncdfF9umsFBZplphOk\nc0CxXMEAACAASURBVEPKaKbmlIc946eoSLM7r5nSwOcTcylwMbBYJCXVk+XNJ0A7aFdylVS1eJpP\nLwIiiqUQ5P2cTlrx/fuuiT4qxpUKy1MwFk0p8NLhUdVRxfZSRrNasoRfr5k3yqejAmIWcy0mCkbo\nPeUUVbmvR3p1K/TOjKuxkB9IySfhTXgiEyntmIKghytKQSa/kMz2W2TEcR99WPpTA9APIFaqJGPs\nOwC+o3z3BenzNQDvjyVphfAGdcrjRcsJO4KSuhAywcsVLg2pAJ4INAfIoNv5EB5LQdk+pYH5pOvL\nCohnNMuTsblgACnNqvRqKCvzoOuQJnHS4KapxoSaL+GXOBdUrM/6266Nz1dSJQaa1Sqpfj2VS4Gn\nWF1YkxUVUkIaM8PZN+GWQjAltdpY+9t3WdZQVG9mG6xgghghd37Cutc+Y5nlTVB7BfJz9pGUoGba\nvbOD7uncqxY1ffq5q+j+Kas0tjFTQPPObocVFAj3c+BJcuL5BCoFAIxZConB6c8iWwpc4cjJoouM\nOOyjH5c+FwFcgOVCaiyoWY/l5inoXqXAeItCvwqXmpSXIPP7I9xHfNIj5p6wfPvw+lkKpqSAuELi\nLyRjVh2flGZnRLtdOH4cezEJSzV6iMowcU0GavZhDwHOBClbCp4scGZbKWQnAJboPlLGASuYYFSm\nKxFwlHpRshRiTtAyJTUyT4FbajZcFlZh8dxHFpU2/rl4L+7RR097f5RXyuXefzgLNblaMMsb9iTr\nf9zOH9mMG//zbcwdH0bXR7Zh7IunYc4UkOoKLqUtjh0U+42wWkkjMMZQuGK3olUtBbttqHWMpXMf\nxYkp/OJiCFJzKO6jKB9uIGT3kVwQL0X+af8ydVPKU1ArnnqQsleGUUoh7U9dk7u6qYlzIpvaXnG7\nJt6gevB8O74tUZmWglQbJtBSCCiFIeUkcCXFJCUVC0r2KyuaMCsoJqpaCqW4j+TVIDNZaNkISpG7\nGq/6zBY5plANyOOsOu4jWSmYoblIqR5n8jdu5EQ5cNGDOgxBbrywlqqAbSnYIndkpBwmn4VqnbuP\nVsKqfdQnb88Y+/e1E6sGUH3JUSuzAMjvrVjx5gzx2bO93K1NmuB5vZcgGawgpGlZCvLK00cpmH58\nZoM5Gcym6Woozpg0kahKISBNn5crkOv+l7WacSXRwe3+UZQCZTRFNilbmMttN1CJXdhQjAOIc7GK\nlIL0fGHHPEqxFIo+E4LvthpMw9vMh++7WO6jUtG0dTlyAxO+v7kmz0qUGn/HctJigrtnA+6p6L8N\nwJDKYaTXhNM6AQTnD0S6j6w4WGpFM9LrO6QFo39MoZ4Dzd8A0AngSQDflv41FHhgadbOJqyIfcQ/\nNnubb3igTBpOYDK83gvplruAGIVaClpG97cUTGn1aMhuFzgMCL7iZu5Vp++gljOz+d9UhqWglMgQ\nSibtxDZELZymlG9ym2BumKU/R2EoSBnNrJL5VOlpUdKqXXdqH0W6UNSCeIq/ueyy0zVGamVI517Z\nFVuBpSDcR1JZ9tmXh5C7OBV4XL09g7Y7V0PrSIv3p2nrcrTFKCKovm+8h3NkF0DbUuCMJ0+c02gQ\nSwFAK2PsN2suSY3BWybmLth5cQYDyi3wxT9LGcyBfkTRXcod0IxsLKKTL0PJN6NZMpsFeECXYDOf\nbH8lb1Ajs3jkwRc0qWnKdXD3kTJuOy8Qxr/2Nro/ul09ggV5VSu5f7SM5nLBQCdrO7VWkn1vRMwl\nxG/sCz9LoZIYp308Y3wB2LDMCqyWYCm43EehGc3k62oTqCQjuIYIU5DVcx95A80AUByeg94Vkrui\nE8zpghjTnR/oK+/8PNAdFVMgKS6nkS8ltVEshW8R0Y/UXJIaI7PByrXrfJ+VaFV27SOhye2BbN/B\nwIlAdh9J26kNc1TINY1cTeBVSyGtAUXmGUCCf80nE5ttxQemxTIiZ8UtNZD3bQkp8i2kQLMS/ASA\nlW9qmDsxHOibld1TvCUpYAft+QRpl/Owju+NL5AmKbdSnyPflF9vobKYQv6qFTTk5ZBLoqQq9aSi\n3EdBgWagfPZUraG3h9S3lJ9bJUqN63mfxVFYUHz2xUEAEDWQynXBCctBtqKD5GQQk78aU2Amc+6D\nhiVjH8W5C/8RlmKYJ6IpIpomoqnIveoN/DlVyngQSkHyiwPhsQFIA0e3V+9RVEiNUBy12njK9Vj8\nAs2Ao3Q4mH19pGmuOkvCMpDcR9YOEMeJYylAQ2ieglxYziWXVLvImtSd+IFwH3EGj2rF+FgKJT9H\ntSBe3qgopqDWRwp0v/lBtRRKcR8pz7te3Uft9wUnucnKPH8hft9nz3F4voNiKVBGD53hln1go7Xf\nrOVaLjsuI5U/B8LfaZ5bQ7rmiSlAHgP2tkuByLvAGOtgjGmMsRbG2DL776gSF/UHpZIiK9XtwA+j\nket/8X3cmILtwomqIS9XxZR9mJ4qqWqBPQ7uLtKVc2mOpSDcR4BEi2O+QT+1ZDBpFGrihgXjXJaC\nlB0uVkx5A5TWvS4TkSMhWQolPke19L6ZM2DGcaIGoGVvDwBg2fs22geMb7nwBEW+X7ilEExJBerX\nUiBdw8BDPu5NwHW9gnhRDgLcR5aiDb4v3HtgTFuB5tpbClaFZbZQRO7dSZ+YgpNQ62eFLxbqcyTV\nAGIS52OvXPeRanHwrwMGlMhTEP0LrMk0NOFNOX7rAalSY1xLwV6NkKwU7IlcBLtSmjeBpmj63xeP\npUCe1YwcsJ745jlceeRZTD/rWDnMtCm2Ur4Ek5SCnKfAm5e7LAXVdWVbCiURBhQWmjlfhJEu/+Xj\nz0+4y0zmpqhFyRIz0OxJXvPEFOrTUghDqa1wA4+jKIWOB9dbP5jhVhu38njyWaymSrDKrLfduRrN\nu7qhtacdkkFEoJm4+wi2y0p1ycqu25BS6bXGTaMUnEYc8VZmQRCWgj1+OLUtylIQ5RQ0ZfXeFE5l\nBYDmnd3iM+/vKrYTMQq1RpDtPtKd/g+QagZZJX69wS6Zuuonj5iYeKBZXr36WAeT335XrMT4OTys\nKNiBZju+YBakmIKavAYplsPdRyXFFKxt506OilVbJZYCf4lnnrlqy+i1IsP2ZWW6jzyWQp0GmlWs\n+uSB6h9UcR9lNtqOjIhnIZTChFWgIW5nuZbdK9D14W3o+flb0byty3mGcSipfn/L9dgaJND8gwH1\nARgVUlLt/3kT8MAaRj4rbBeDKWgAybJJg2n+9evu43P3UcEbU7DcR5qTKCcHmg3Tv/5KQKBZbCeU\nm3fgyg3sZQz+30fFsQEolFQeU5DcRwUppiCviOVENTnQXIr7yH5MhaszGP3iKZjzRZjxyhz5Q71X\npSw2ZJeQidIshQZxH3Gs/NX96PrIttg1k0qB2sHNdS/iKIUbOVBzqizF6koejarDJX3d+cE+j/vI\nlYG9hJTUWHeBiO7j/ZOJaKVd+bSh4HRnsr+oNNAsAszWLQz0RyoxBdh+fud44VRWaxvn4/If2+ze\nTsl7AGw3jl1xkTSSEuWk4G3BHWiW3Ud+TBBXEh7gWArSuOW03473bvC9JleimuTGAmz3kcndRwEx\nBemlqzjQDCB/aRpgqMxSUFZ/rAR5SNdKDDQzhyXmUQr17T5q2rDMaS5UbSjuI1etsDCab0YX7mC9\nrbxBIBekjFUQj3/kOU4aHJKHNAaEm3cJFEOkUiCiTwH4TQC/ZX+VBvAPtRSqJuDPw8dUK+kw3FTl\njAX7ZYxrKfAVtkDQE5ATe3yK8Dl/KzELQCgsznBQA82wV+hqoHn+zXEYk3n/CUZVCro30MxlyKxr\nx7o/uA89v7zXdQi3+4cXtJOVgm09iJhCQJ6CBmFFlGzx+fixjUosBRWsBHl0EuyrOIFmsR3gjSnU\nuaVQS/B7Y+YM6z13LahC7qlG4n3SYlbF9RwjbZenZ8zFjvPdVvpa9IqX3yGldDaAJWEgxRlJPwng\nJwDMAuCVTatvA9YaipukYkvBBjcVowLGYjLVyFmJh5RncE0s0jbFsXn3dn7uI1OZuCWzWtQMKqhZ\nlcD1r5x1XZP/ddiTuE/tIyevQgMRoWlzp/WDHEOwj0U2D5tPirwkBwxLKWhhMQWtAkqqz6WZqeq8\neGJiiDk/u/opmMxZuPhtq9ZYatCYQk3Ax2beW0I8auHH+3CXrRRaUtYzLJqRrVjl97hwbcb+ynmH\nrIUqz1NQ5qtFRJyRlLc7ozEAIKK2iO3rE4riLTumYO/CA8RiVR1gvpNGcOUlkBRTCKOcBbiPPL5k\nP/eRnOSlE8yclBNhm6uilLbf4AsLNAvlZv3zLUNh709E0DrSTgVRmZ3BmUuypQBLLlYwbI65O7jq\namKiO+Z1KRafnxKuJE9Bxszz16BmeIfKIl1DJBtOV8ZMg7mPotB295rydxarah83bsQ7zt040eWy\nA04tFcVk0mLMf2MfueSFlUJJBerUfQTgn4jorwAsJ6JfhlUD6Yu1Fav6ICIwMFRcEM/eJ73WLpwV\nFVMALBNRthRiKCO3i8n5rK5o1CYvgJsFQbrmyp4W/Ge5BDXcg893chKTkpta66Kk8pWSdC/Sq501\nhMhOlmICotObyIPgzCgtNE+hbEvBD1V672ZftjJkp79/Od4OumRBRbmPeO8B0X+hsQLNUYjbn8EP\nYYX1ohZ+fFLX2sv0IcqLqsjaRz7WvxSXc5E84iwca4Q4pbP/mIjeB2AKVrvM32WMfbfmktUCBOFv\nL7sgnmglyE0G+7/QGi/k9sXHUUaSbLlzTpVJvdNdNsBPKQjqp0zd5DISOcX40k6egrzyDKWkFp2J\nGRqJtp6WDN5AX3pNO3LvTrnlktlDBrOC7ZKLiRVMUEazgnhB7CPb7C77OUqYi66BFgvFkfnojSQ4\nLU3N6NLZPN9F4rS70OBKoSJWkszmU+9DxLuWv2S13TQnc6HbBUHtrAgEKyKXTtCc//0SGMttd1sN\nxAq5M8a+S0RH+fZE1M0YG4/aj4geAvCnAHQAX2KMfcZnmyyA/w4rgD3GGHswvvilgRGqlqfAJ6j5\nk6PW92E+XclSoDIsBZa36aNFE81bu9zbiYxmvxpB7oYoToazUm1Uuh4AAVVS7WNLFg9pBNMVU7A/\nSy+m1qJb/taC6azI7XvADAayM6+dwoGGk/UsK1NJRuF+4hZPGYUN6wLyajAqM1vJd/G4jxoweU1G\n09blZe9rxbdg5SXY8SzxW8x3vHijPKXgZykEKejZEyPOH3wbOabgZylUkOhdLuL0U/gVAL8HqwWn\nCYiyTpsj9tMB/DmA9wG4AuAYEX2TMfa6tM1yAH8B4CHG2CUiqtKaLRiMMSeztoKYAm/KEWsXnWDy\nBC6KaSnIk7lGWP3rB0XhLtexfWIKHuon39Z+YUTgOe0tysW385xHiSnIq30Bn3pOvLy4uVCUlBXc\nmdW2m8vazpYto1vXVvRxi2lSL4e84ak/1CjwuMwCEhkByX0kBSXdvzemYmy+dQUWzl6vPFBuj8VS\nYwocHYduKeu08opeLgHjh+KI0w9a9ACXyRSSS3spYwpx3qbfALCHMeZf4SwYdwIYYIydBwAiOgyr\njefr0jY/C+CfGWOXAIAxNuI5SjXB3UcR1LEwzDx/rfTzSg9ethTCTGY1ppDqbkaq29sqUGRIy24c\naUXt8bfKbCRdEzatrFRCy1yIPAUEs4/S/kpBWGmyQjGZEzjm29nHkCvFWj9692cMoZNpGHp/ox9g\nDANnXy5r/yB0/fSOeBsK6yh8MgHg5LMEBpobUyms+JkdKE7kKm4SRJoGBj/2Ufhx9a4mGDdyaN5W\npqUiWQqRGc0Slv+4taaWOx9a5JfGYB+dAzAXuZUX6wDIEbcr9ncytgPoIqIjRHSCiP5dGeeJDe4+\nck3QFaIja9dZCeETk6aBFexzNuvuSohBkPMUIgYZpd2NdgpD1uPKX5nxZk9rgJmXVvTKxCS+V6EG\nvjSfPIWi11IQrCyD+QaKWVFxH8lKIe2UvgD8A83lxBSad68AAKR7WpBe2VrSvnGgt8azXEScQCYh\nBG2bcj8nbz+FxnQfUVqvzjPgvniVhRUxw618eB9W/Nyusi0VV6yHl5aJUdPJSV6zLWaFzryUlgKx\niOQIIroNwN8AOApAON4YY/8hYr+fguUW+rj9988BuIsx9mvSNn8GoB/AewG0AHgRwI8yxt5WjvUw\ngIcBoLe39+Dhw4fjXp8LfU8SZtYC49sYNn9Px+hOE5N9pd30rY85q9KBhwx0v0PoPqdhfIuJ8W3+\nx9r4tAY9B2gm4dK9Bnre1NB6nTDfxXD1Ln+nYedFwso3rBEyvtnE+PZgOfue0jC7kmF0j7VN2xCw\n5qSO0V0mmm8AHUPWcd49ZKD3NQ1NU4BeJAwesCqErjuuY/A2A2teta5t8ICBWSX5tGkSuOVFHVNr\nTSy7puHSvQa6zhGapgiXHrCuoWuAsGJAw8D7DTG424aBNa/quHy3ATKB9Ud1XO03sPINDbkOBhDQ\nNEkY22Vi7Qkdw3tM9J7RMLTfRHoW1vE+YCUlLbtMWHVWw7tZAyveIbRct16c+W6GkX0lPEcT0AyI\n8hYzMzNob49uwxgEeUwAwNU7DMyviN6v/Rph9SkNl+4xsOEFHWPbTUxs9r+O5nFg/cs6rt5hYLRp\nBmsmOtB7xp6QiOHcB5bA+RwTld7fOOj7voZUnjDbwzC+1cQtL1nPZGKDibHdpU+scWVuHQHWvqLj\n8nsMtA8ROi8Rzr/f/1nI4+TSvQbyHcCGZzTkOhmG9zFsfVzH9a0mbmxlaB8krH5Nw8X7DBRi3Lo4\n8h46dOgEY6w/6lhxljR/BeD7AE6jtLDHVQCyo269/Z2MKwCuM8ZmAcwS0TMA9gNwKQXG2KMAHgWA\n/v5+ls1mSxDDwcXvPYN1a9di1z0bMfi9l7Bt21a036saL+G48tiz4nM2m8VU8SKmzl3Cxo0bsS/b\n57vP0PHjKC5YzJQ77roTk2PnsXD9Bpa1dmBb9jbffWaODmLijQEAwPb37kfzlmDzdvDYMSzr6cCt\n2Z0AgIVzExg7eRq77tuPuWNDmBuyguH33n8vrl95E7kJi820Z/9eUEbH2PHTuHXHboy/ajWK2Xv7\nfjRvdwe089dmMPLiq+jtWYX5a2O44847MD13Bbn8FLLZOwAAk7kLmDp3Cdkfyor95t8cx/VXz+L2\n224HiiZGj57G/tsOYOLyOSxb0QLSCAVjFvvv3I7RE69h2+o+TJ25hFv370FhZA5TAxfwwL33Q8vo\nmHlpEBNnB3DPvfdgavYiFqYtrkPn2i7szgZ0eouBI0eOoNwxBQBjF85i4U2Hd3Hg9tvQtKkzcr+5\nU6MYP/UmDu6/HaMvvIYtW7eg44H1vtvmr85g5OVXsW/nXhwdPY0dK7dj4ow1PrRMCtnsPWXLX2tU\nen/jYPCFozDyefSsWYlNB9dj5KWTAID1G27Bnmxo+NMXcWVeePsGxl45g9tvux3zr41idmg48Flc\neeJZMYMe3Hsbmvo6MXTiODpXtmHn/Ttw9fHnsWnLZuzP3oK502MYf+0N3Nl/h4vWXam8cRDHZkoz\nxn6dMfY3jLG/5f9i7HcMwDYi2kREGQA/A+CbyjbfAHAfEaWIqBXAXQDeKOkKSoBgH1UQU1DB8wbU\n8hMu6A4X2UrDt257we7a5QfZJZLuDTevtbQG04+SKmdPA3Z7TnLKYEhMDVeVVZ/74jSoV/z6SpVU\ntbWlcH3J7iOe42Ay4UflhQWNGafhiXBDqYwbzXKDMdOqBVQNN2Al6PrwNgBAps+uzhm7n4Liugu5\nDp556yrRzY/T4Ilr1QB//zyxiVq71YRb1YxMpEytcPpVu1yGLtcq7P+9BJDFQhxL4V9t982/wO0+\nCqWkMsaKRPRrAB6HRUn9MmPsLBF9wv79C4yxN4joMQCnYE1VX2KMnSnzWqJhB5qZPLlUiLY7V4Pl\nDbTfE2xxuPz6Gjm5AWGQZYvyUSoxBZn6Sa7YhOaWRap9ZEqBZr3Dp4WiH/uI4OqhwIrBSoG3BLVO\nQFK9eAakSASk5YYnoppq0QnEiWPyAB0PeC8h1PpX8WsfuWMKYfvxYDov+sb59UB0MPVmgKgwoNYG\nq/HYcLGPAopJcsiNsOSsf8bgXvAA3q5si4g4SuFj9v+/JX0XSUkFAMbYdwB8R/nuC8rfnwXw2Rhy\nVAxGTkkBAFVp8kG6ho4HI+hsujLBx3iJXZN5jKxMHqAF4Mt0AkmTKT+uFBDmSqXrI9uQXuW1TIQM\nUpVUuTscP4an3zG/VtM/0MypwfylNqedhieeBkKms7pygty05JaCUJhyy9UY8CurHniKJs7isuIr\nLsZVgzKP/v/2zj7YjvI87L9nz7nf0tUnXPSFJEBAZCxAEgJsGa7cOBE0NX80yeC0dpqaYTxjGmcy\ndYrrqTvJTGfsTqeTydQxoQlNO22smRDXZRxqGgeLJgUjvjFgBAILkNAXSEi6+rr3nPP2j33f3Xf3\n7Dln9+ju3j33vL+ZO/fcPbtnn7N3d599vmcTc640Wex5nxt2AkaHpAeTbg2ED3qmuDSmFEqdkqqU\nWl+EIIWhmv8BWagsHaZ+/HymbSInSiXlTSxiKXRYdWyAc/vCqufg+0m47/Ap1tqw6oXTzvRTTMty\n/7g5m1Cn0NZSsFNLBcKKZPxjovswRdxHQQfYemTfQdHdLFp8F4XefWTkahrix6bdvV0PRFIXajBM\n4G4D5z6C8Dz3YoWMhVoK1qjZJIZ/YWlQ7Bqkl1tZdBF5EzoNFEXHRwwRGRCR3xaRh/XPfSIym82G\ni0PA7lHeTRXouC5yiYzI7IT9dJ7SOmnV+yjx4/XT0Ynv7+P0/z0QvVma7xjvvgiRyWtBrnyLp9zm\n4jUSW2fHlUIk3zpWZ6Aa6FnSfmzDG66EoxGrXlO1dqiQwn1nmV+QGxI7NpljCrpupF2bCxFk0Atj\nP7aOde6jwI3ZZCkUFlNQkYZ2SYxtngjF0i7aoH9YiSyFNGfTd4At+JXHf6xffydPofJCGR948CSd\n/YQZ2bScoQ2LGf+ldam3aTUwpy0t5ikkyqSHx5/5ySFOPvrz8AKxYgrB02S8wjke7GzZ4TH2VNui\ndXa842ikarcRk8vUGRgZh6vhZDddp+DLps1uMzjI3vcs9D66WIL/T63DMYxvZ27mKdxH4N/wzBS9\nSAND5z4KkyfmMqbQamph2w+wLGZsS6HcMYWblFLXW38/LiIv5SVQ7mg/NtDVE6Y3VOWSL36884qR\njaIxhbMvdC7cTjWIRzO4dmFgBQGRArOwwVYY2Ar2YU+NmunwlGuUwgW7mV5sjmyi+8gU9zSifV2E\nsF9MQqdZv6I56rJq+owGgAoGHs0Zpi9UUJmc8iYdKNp0xZTeYCUMVkZanTv3UfDAEa9uL8pSMBXN\n7faX9JaxmOOu0JJbCnURudL8ISJXAPU265cX4z6yevAUsttYH6NUxIPTbfCGqtjtn4NBPFZMoWmi\nE0RTUjtU1Ta5Oqpes6WQ5D6KpKQagXWgWKnIjd5+yjNtLsC6MExHVaLH8cwzhxNlLoz4MezSfdTR\nUhiw3UfOUoigj4c34EVuvrlbCnaszUwzbLly0vZEkjDi7qNSts4Gvgr8WETexv9aa4HfylWqnFDm\n6VTFtHLeZIgPGKKT17LtLgjWWnUKRq9EU1LTxxTC9SzXm35aV8pv+6xqzdlHtnktRhkLYY2D1R3U\nM5aCJ9EOrjXLUkhwg41/Zm2aw5If5mHxrG7RkUegGV9pKuc+SiTo51W0pWCljqqaah/0T3q48wRU\nw6otspbrzy2aNNlHfysiG/BnKQDsVUp12Wd2jtExndmsU0i120oXN3jbusgY+zjzE3/YS6SYxk6B\ns/cRuzG1uqGFT0ThDSxQMH5mqG8pxEdbmu9Rs4Jw+oYf98MGaYXmtzVvwN93bLC5xkvZaygv4v8f\nEyDvuJ2pEblgNShst/6gF6Y1OqUQoXYstI5t8rcUQmtW1Rt4w61zcBIvY7GGRYHl7i2x+0hEfg0Y\nVEq9jD+r+bsisjl3yXIgsBRmsSFeKlrUBrQja8Bq5R98gsH145FljbO1SJ1CRBadGhu4jzq5MGxz\n1iMM9kLY5TEpphD4RqP1E5GKZmPNDMYKkOIjKOsqzMmPxWlKQzVla3QIvkvjnLYwOkwfa2kp9Ggz\nvNlk2Rc2IkMVBi+PXgNpa0a6xnx8XfkWbbv9JZynwXXQlJI6d5ZCmiP2b5RSp0VkO37juj+jR7OP\ngGj6V0E3k+DpdrCS2i2U9enPG6yw7HPXRpZVFg01WQpGCYQDwv1f4dDxFkLZi81nxIJhaqY5+yhS\nmRk8DYHpDkmjEfaQ1xaCGZGYNKw+tBTsL58s8lyQJT00OH7BDIn227YONJfoAMwRIxuXser3P9E0\n1jPvuKEdU4i4NxNXTlhmEiZi96S5bHORKtCsf/9D4D8rpf4aSOiD0AMY91GQ7VHQfmNB3kV3rgdg\ndMtEqy26mx+tbw7GnVJZONjSUjA3oEBJGUuhlfvIsgxaPc20txQaLVpnq6ZAcyBbkH2kXVa1UIFk\nSdktgsq4zjvP8H8zStD0M0rjPnKB5mzkXsNhPl9Frd4kgrnuFiKEg78gfEAKWrwU3/02jTP2oIj8\nCf4EtW+JyBClejZLj3EfmZnH9ZPThew3/nS7YPsq8ISxbZd13CYTxh0xbfn9zUkm0Rt5cCOJD3rp\nMFY0MkfWXA/10FJoanNhu53iQ3LMskpMUbVwH0ViJF0E73MlrihTENRhGEshzdwM4z6yHiCd+6gN\nOR+b4BpoqOhDS9K6ScrbtIqJu49KrhR+HdgJ/Ael1EcisgI/I6n3EEApBlb5GntgReeWtLNC7EYm\nnrBwe4eW3V3c6CJdRSXm9ze/YpZCOHktxaAXT/zM1wRLQekbfKKlIPqGbimFaEqqCTBHO102uY/s\nmoYu5vDmSixAmAY/wyqcNtfpBiYDXmg1OUshFblbCpFroH1KqnjCpV/ZHFiV/kKJuVajrlRq/YZh\nUwAAGt1JREFUxbuP0mQfnQW+Z/19CDiUp1B5klgokjOpJq3Ft+niQjejOSND4PVXDW48RheYG3BQ\nQJWiRUMb95G5WTXFFMx68WCah7YUaL4QzA2/KdDcaGEptBa5MIw4GW9CUq2Ec6k7uY+qnvY/x3zN\nTim0Jm8rSqxroNa5onkw9iDqPxxZSRixmN9cWAp9dTYF4zhNTKeoJ8zYMO5UmyS1r05BoEz0yVVd\n7vdwj1fNSiyLp2NFs/2e2YXZVqlwTGTCGSWehOMKzT69cK60Cc6ZmQGmSV88phBJSc1Q3FcE5mLO\n3CxxwAtHkHayFExTwwYR/5FriNeavF1rtiWs6o3sClq7tCNt5SEYneuUQt4I/pNzvWhLISGNMq99\nBWanfzJV9BAgZYazSPSm2ty+uUNMwdrGjhcE7TKSNrf6HPkfoBVFTT8h631WFviK0OTtN3VmbZGS\nWg73UXebyYAXVqN3uoGZuQ22tUsBLpIeppBjYxViZlZCXosuqfiyO6VQBHNS0ez/KuLmFXc7mVbY\nQdZKQvZOWleMkd8E6CPNwLRSaQo0Y1kK2lUUNrQjIounraMg8GrWs3sfJRSvlSLQ3KW1Eun31OEp\n07YUXEVzSgoIwvsPOA1Q2ZWQqVOw290H7w04pZA7pktqfPRd3pgTJehJlJLhjcs4tTLbSREfR2jK\n/hd+2m/53VSnANGCtnY3t/gFZqekBpZCQmDMthQS4itGuRiXWcMaGCQViVY0J8UUVMI+C8Yct+Fr\nlnRYM7adrRSyuI8iMYUSKMWSUkhmVoIrNMu2LWe8VL05CTTnelsUkZ0isldE9onI/W3Wu0lEaiLy\nq3nKE7iPCg40zxw729V2y7+wkaObsp0U8adGEWH1Nz/FItPqOyhms9ZJevpO+mz9vqmDiFQrp4kp\nNJLbVBiZKwt9q2b0hkvDjSsSXhh2F0pr+zPPHGkrdyGY7531SdFuiZEm0Iy2FJRzH7XEfrApyH2U\ndeqewa/XsQLNleh1UdaU1K4QkQrwbfz6hgPAMyLyiFLqtYT1vgX8n7xkMZg6hST/XZ6ce+lYIfuB\nZkshzsAlfuC5ZgdEgxtah+NhShvMAHI788IohaTso4oXmshJmVhBRXOFlf/21khTM6l4YcV0w2qJ\nYW0/dsuK9nIXQRcpqRCzFDopZVOcWCc6ZMe5j1pShKUgngRzLjJbCkGguflBVaoy79xH24B9Sqm3\nlVLTwC7groT1/gXwV0DnIQMXi84+KtpSWPob13ZeaZbodIOoLB4CCOYiAMkZPUmfHX/Kj3SI7GAp\nBAN1op/l7zfcyBupNo0vDS4MuzjI2k+l1QjRApk5OAVkv0EHrT1SfIegfsPFFFJTjPsoZfFn4rbR\nJIxW806KRFRO/ljtCtqplLpH//154Gal1H3WOquAvwB2AA8BP1BKPZzwWfcC9wJMTExs2bVrV1cy\nLX+mwej5KqdWK5bv9XjrF+uoAhpsDp2ENU9VUKJ465ez/ZOnpqZYsKC5PL4VK571GPvAP7H27Wwe\ne+FNwxWPVzixvsGH1/j/+3WPe1SnhdqQYv+O1vKtftJj+JRwboni4M0Nxt8TLn3V44OrG8yMKVa8\nUGHvDaepXDYa2W7N33vMjEF9QDF2TNi/o8GSt4Rlb/oX0KEb65xp0fFj7RMe55Yojm5SrHvc48yE\n4tjHFMPHYfUeX8O8+4k60+PJ26ch6zFO4qof+rKcWtXg6MfTX1MTLwoLD3vMDCvemWx/bpjvvO+6\nKVa/O8bwKf///P6WOmczTIctmtk4vlkw1xvA25+u0+giuzuLzGt3e9RGYOSEcHhTg6mV6f//y/YK\ni94Rjm1UTLzisf+2OjV9+ax+yqNRhfdv6nzPSCPvjh07nlNKbe30WXPbcxj+EPhXSqlGuwCnUupB\n4EGArVu3qsnJya529trLTzCiRli+7jJO7d3Pbbff1tHdMhvMfHCOI089iyghq+y7d+/OtM0H777G\n+Q8+ZHDdOJOT1yeuU79lmlULBoIn8kNPPk19epqhkWEmJ7e1/Owjr7zAzKkpFi9ZzIbJTRz/yzc4\nyxEmjoyw6M71HH/hdYYXjPLJmLxHXnyeytJhvJEqF06fYHLyZk7Le5x8cz8A112/iZFrlybu8/Cz\nzzJ+yQI2Tl7LwSeeYtWaS/nY5JVc2H+SY3teBuCmbTcxcFn31elZj3ESB374dwCsWL2SjZMbUm93\n/NgbnD18hOGxESYnb2q77oV3T3Fsz0uMDo2wcGwBM6fOAHD9lhsYumJx98LnzGwc3yxMH5zi6FMv\nALD9tu14w9lvc1lkPvT0HrzRAWZOTLHxuo2MbkqvoU9e2M/pd97j2quv5sQrb3LLJ2+lusi35o+9\n8TJKKa5ucR13K28n8lQKB4E11t+r9TKbrcAurRCWA3eKSE0p9f1cJBKae/AUQJHFRUbJTe8/1XKd\nSJk9pPaHx+sT7C6p7QLNkf4ubbKPkoWVoJgtMhi9bCmpmswpibHZEW3XbZGS6iqaW1NUTCEY8pPV\nfST4FeoJ7iOqHupcLXm7HMlTKTwDbBCR9fjK4G7gN+wVlFLrzWsR+XN891E+CgErJdUaFFMEpiir\nCLryL8djBJ3WC5p2hZlMM4d8n3rr7KMG9TMz4ZAYSXdTDzKXiKakXsxkujzp1P66aX2jFFL830Kl\nIK73UVoKzj7K+gAYjt1svidJ1QtSvYskN6WglKqJyH3AY0AFeEgp9aqIfEm//0Be++4gmN/ywZpP\nnDdS9Vh+z8epLh3Of19duMPCAHKHlEiznj5sC25ZwZmnDjF++2pmjvhpt42keKnux3Th7Y/Cz6qk\ntxRUXfkpmGWuaNYERYIp6Uop1HFKISWFnBsXkZIaNKSsN2dEzlX2Ua4xBaXUo8CjsWWJykAp9c/y\nlAUITLVIY7WCGL6qGJ9vd5aC/t3pmMS7vQ6Fk9K8kap/A0+qaK5I87CQFtlHzdvqdFbTuyk2rSz+\nWXPNzOEzmdZvagLYbl1X0VxKIu6jrK7iWOt64nUKM/MrJbV0BA3xGl30KOkRurIUTO5/ypjCzFHf\nKghGeTYU0+9PRatsbSpek1KIWGkdmvCpWiNw+SVedCVoiBeQUZRzrx0HYPqd1jGg4KNb9T5ySmFu\nsd1HWWNKgaXQMAvC96pWq/QCmevso8IJWmeX6OlyVuniewWKpNO2pvfRh+cjf6vpBhfe/KjVVr4y\nqTcYWL0gaNCXKdBca4Stvc3Tsr1JD/8ra0czVLubeIrS57HGdUmdWyIuqqwKWq+e7D7yUDPzrM1F\n6TCWgtWCeb7RzfcKxmB2sjLin63/PPnXb7f//IrVOjspqN0u0KytjHCGtJbRuvjK8J8UnfboZUwq\n8IaSSsBb7cT6pi77qDykjY8lYc79pCFXVS8MQBdIX51Nxn1kj4Ccd1yEpSCD7W9QHdswtMq80YFm\n1Uieh9DW5DYpqSbgpp+KB9csbCtL0Vz6ZT+XvONEvRgj16fPaQ90gnIxhTIhaa3eNtuqup6WmBBo\nzqvAuBX9dTYJ/gU1jy0F45v2xtJ7BgNLodPNRZ/wozfqhnX2nOCRKmNbk2dOB/2LrIZ2abOPjJXR\n7D4qV0rqwCWjrP7mpzIrqwU3+32bKmky00yHW7upI+XKvioFRR+OWHA4EyamUFNNsbFg1karWF1O\n9JdSwH/COvfyMWofZpuQ1Sucf90PXAb1AClIW0BlnuhN/yRv1I8PVC8d9Z/mW22v4wK14+fCgLNt\nHbRVCh61Y+eYPtC6t5A30sOhseDpP8WF38p95JhT4r26MhHEFBpNVn44o7xYF1JfKQWlLQXm8fVk\n5iZkSYENlUL70+Gs6fZquYBkqMLwhsW6sCx5e38mgj9k5/yrHwbLgvfbPOle0JbPiYffiMgalT+D\nX75kGMU68vEUbqQW7iPHHGOd95kbIloxhfh1YM71otNSe/gRqwtMTGEeY3oAdYoP2ATrdspi0S6c\nC2+egM+s9ZfpDqiRWQfxz694QaA4XJYuYyM+8zjL9+oFvJEqK79xSxCobkcQj4m5jxxziz2sK3ub\nC6t4LbZpaCk491G+zPNrKYgPZLh5Tv/8JBBtp53EsG5aVz8zE+7PbhvcSqlY/YuCwKr9dNXGUli4\nY03k7yIaGBaNNzqQPi7QB9Zuz5HSFZqEHWhuOgfMue4shfxQ+phXl48wsKL7rpplZvjqJYzvXBcE\nMNMw/e5pgKBVRSvGtk5w/vXj0SZdEivcSTh/pRKuMzAxGiwLaBdTiI8Xtf6+7KtbM8VO5gUivqUA\nDH9sGeOTa9qv78gdu1Fk5qC/UQq1hJhC1XqvQObfY1c79DFvTNfnbRqfeML45JpMwdcl/9hv9dzU\nPTVGQ9/YG2ejLSaSSvQj2FaBqZ626wzaVCSffTE6e8mzLKDqshEGVxXXp78UiK5oxk/LLVtqbl9i\n3HrdFBGay6DWXFAbuI+cUsgfNV3P3M1yPuMt9JVBJ9/l6A2XMLr5Ui77vbDvv0jYtKtloNk62YOm\neCnN7HiTvvnoPsqCeBIohaIaOjraE1i9XXRktdtcxP+fQaC5YKXQl+4j6s05wf2MaeJ24Y0TbdcT\nEZb++jXRhR6omfbNwOzl5/f6+0gdkIspj/kWaM6MiSlAnz7SlZDKxVgKVp1CPNBcdZZC/uj/maol\nBHX6mIFLRvwXXZ7UHZuBJbTkTlv5ObYtVhA3XyvR0yKWpeDO4fYUdK6EVfrdzzJJCjSHSsFlH+VG\nYCko5m9DvC4YWOX7pcd3XJ55W5HOMQX7CWrh7auBdIPqAcY2R4c3973LxFIKhQyQ6WEKU5qBpdD9\nLJOkmEKQqu3cRzliH/N+f+K0qC4eYsXXb8YbS3ejtql9cC543dpSCI/18C8sbb9ujH6PIcQRD3/y\nGtn77PQdBSnNIO7Vzf/DeC/qDcSLukZd9lEBKOt/5kzvKJWFgxd/TFrFFKyLpXbiwsXto9+xso+c\ntduewpRmQj+v1FgpqU2B5vkYUxCRnSKyV0T2icj9Ce//ExF5WUR+KiJPisj1ecoTsRTcBTUrDF2x\nKHjd6qKwrQJ1ofhB5PMKO6bgLIVkzM214JhCVx2KgxnN5Qk05+Y+EpEK8G3gM8AB4BkReUQp9Zq1\n2s+B25VSJ0TkDuBB4Oa8ZIrI55TCrNA4a1U3tzLXI32OwnUmfneLSw3OigieqddzSqEtRVsKXWU0\nGkthJql4bW4CzXnGFLYB+5RSbwOIyC7gLiBQCkqpJ631fwKszlGeiPvIWQqzw8zhsAq6YbW/sIlc\nnNZxH7h0NDe55itipaTGazgcUbrKBupmPyb7qIttq0uGmj4n+HuOLAXJa4CDiPwqsFMpdY/++/PA\nzUqp+1qs/y+Ba836sffuBe4FmJiY2LJr166uZBp46wJr3/RvRB9c0+Cj9eVvIDM1NcWCBeWt2r3q\nh2Fw7P3NdY6ONss7ehRWPu+vd3hTg6mV2Y67vY99O2e/rUXZj7HN2t0eNa/ByNkK72+pczb9jJ45\no+jjO3gKLn+ywoUFive2d3dDzSLzoneES37mcX6R4sCt2fdnzu9zixUHb7G2V3DVYxWOX9ng+Ib2\n10waeXfs2PGcUmprJ3lKkX0kIjuALwLbk95XSj2I71pi69atanJysqv9PHfwieD1lVddxcJPZZuS\nNRfs3r2bbr9vERz44d8Fr2/6tdt54oknmuQ9/+YJPnj+FQBu/OytVDKOrDy4+0mU7nGUx7Eo+zG2\nOfT0Hs6f9zvHbrrheoY3LJljiTpT9PGdPjjF0SdfYMH4AiYnN3f1GVlknnr6EB/9bB/ji8aZnLwh\n876O/PQFZg5OsWjJYjZMboq8d+BHf8/aNZezaXL9rMnbiTztq4OA3a1rtV4WQUQ2AX8K3KWU+jBH\neWLZR3nuqf9Y8a+3ta4hsEcMdlGR3E39xLzFrlNwLtBEzFCawtxHF7mfhm4wmXRPkqpX+DyFPI/a\nM8AGEVkvIoPA3cAj9goicjnwPeDzSqk3cpSlGRekm1Uq40Mt30vb/K4Vw9f6T8OjWyY6rDn/ESsl\n1WUftSCY7ldQ9pFJxe7SGz14uW5qmKDkpeoVPk8hN/eRUqomIvcBjwEV4CGl1Ksi8iX9/gPAN4Bl\nwB/rm0Utjc+ra1ygedapLB6i/lH72oOaPSini8eQgYkxVn/zU9k3nI9EUlKduZuEuYkWlWF4sR2X\nq8tG2n72vJq8ppR6FHg0tuwB6/U9QFNgOTd5JNS487V1dtFM/PaNHWcaDF8ZjgZ1N7KLxHPFax1p\nFGsp1E76D0XT753uantv1L8NJw25kqrMnzqFstPLc33LhDc6EMwZbrlOyj5HjhSIIMq1uWhHEFMo\nSmle5D3b0/ei+skEi7vqud5HuWIHmt0FVRiuUHD2iIRk3DmcTGApFGOVLvjkSs6+dJTFv3JFV9tf\n2O+Pw62fnG56T6re/GpzUWrcBeXoRSyt4JRtMmFMoZj9iSdM3HcjQ+sWdV45gYVtRqrOhVLoK0vB\nNcSbO1b+wSfcMZ8N7GPo4jOJVBb7mXCDa8bnWJJ0VJcOU1k2zPiOZuXgxxTmSfZR2XHuo2Lx+n1i\n2mzhXKAdGbp8nEu/spmBid5ooyJVjxVfvSn5vcEKjbMXqH14jtNPHGDxP7oy93by/fWoEfHH9tdX\nd8wT7KCCs7xaMrhibF5Ypt5wlcaFOh898hZn9hxm+tBU/vvMfQ8lZT6cMI7+Q5yl0FfIUAV1vkb9\ntB+EVtP5xxf6Sikol7nh6HXsQLM7h+c93nCFxoV6EDxX5/OfR9JXSmFwyl1Qjh4nUpXfV5dvXyJD\nVairoLDN9EnKk746q84ts6L4zn3k6EEibs++unr7E2/YT9Aws0oazlLID9duwdGTGJ1Qka6aCzp6\nCxnWLTB0/yNnKcwyLqbg6Hm0InCJEv2BNxRN5a4ub908b9b2mfseSoq7qBw9iWUpOOY/plkewKI7\n1zO2Of/28X2lFMQuDHRKwdGDBPOAnVLoC+wphd5YMY0l+0op2LiLytGTmDiCi4n1Bd7CUBE4pZAH\nlqXgAs2OnkTrhLxbHTjKgT2+tqj/ea57EZGdIrJXRPaJyP0J74uI/JF+/2UR6W7Kdko8a4aFu6gc\nPYkJNLshUX2BnWE2uGZhIfvM7cwSkQrwbeAOYCPwORHZGFvtDmCD/rkX+E5e8gCc151t3dAXR69y\n/rUPAToONnLMP4pqKplnl9RtwD6l1NsAIrILuAt4zVrnLuC/KaUU8BMRWSwiK5RSh3KRyINV/257\ntCrU4ehFVLHtlB1zx9BVi2lMNQ/gyYs8lcIq4D3r7wPAzSnWWQXkoxRwAWbH/GB6/6m5FsFREMv/\n+XVQL27QTk/MUxCRe/HdS0xMTLB79+6uPmdqaqrrbeeKXpO51+SF3pJ5eBus3lPhwLY6+3pE5l46\nvoZek3k25c1TKRwE7FFCq/WyrOuglHoQeBBg69atanJysiuBdu/eTbfbzhW9JnOvyQu9J/PupT0m\nb48dX+g9mWdT3jxTGJ4BNojIehEZBO4GHomt8wjwBZ2FdAtwMrd4gsPhcDg6kpuloJSqich9wGNA\nBXhIKfWqiHxJv/8A8ChwJ7APOAv8Vl7yOBwOh6MzucYUlFKP4t/47WUPWK8V8OU8ZXA4HA5HelwF\njMPhcDgCnFJwOBwOR4BTCg6Hw+EIcErB4XA4HAFOKTgcDocjQFSP9VARkWPAO11uvhz4YBbFKYJe\nk7nX5IXek9nJmz+9JnMaedcqpS7p9EE9pxQuBhF5Vim1da7lyEKvydxr8kLvyezkzZ9ek3k25XXu\nI4fD4XAEOKXgcDgcjoB+UwoPzrUAXdBrMveavNB7Mjt586fXZJ41efsqpuBwOByO9vSbpeBwOByO\nNvSNUhCRnSKyV0T2icj9cyjHQyJyVEResZYtFZG/EZE39e8l1ntf0zLvFZFftpZvEZGf6vf+SOwJ\n37Mr7xoR+bGIvCYir4rIV3pA5mER2SMiL2mZf7/sMut9VUTkBRH5QdnlFZH9ej8visizZZdX72ux\niDwsIq+LyM9E5Nayyiwi1+hja35OicjvFCKvUmre/+C37n4LuAIYBF4CNs6RLLcBm4FXrGX/Hrhf\nv74f+JZ+vVHLOgSs19+hot/bA9yCP3H6fwN35CTvCmCzfr0QeEPLVWaZBVigXw8AT+v9llZmva/f\nBf4C+EEPnBf7geWxZaWVV+/rvwL36NeDwOKyy6z3VwEOA2uLkDe3L1KmH+BW4DHr768BX5tDedYR\nVQp7gRX69Qpgb5Kc+LMpbtXrvG4t/xzwJwXJ/r+Az/SKzMAo8Dz+fPDSyow/dfBvgU8TKoUyy7uf\nZqVQZnkXAT9Hx1F7QWZrH78E/L+i5O0X99Eq4D3r7wN6WVmYUOHEucPAhH7dSu5V+nV8ea6IyDrg\nRvwn71LLrF0xLwJHgb9RSpVd5j8Efg+wJ7SXWV4F/EhEnhN/hnrZ5V0PHAP+i3bR/amIjJVcZsPd\nwHf169zl7Rel0DMoX52XLiVMRBYAfwX8jlLqlP1eGWVWStWVUjfgP4FvE5HrYu+XRmYR+RXgqFLq\nuVbrlElezXZ9fO8Aviwit9lvllDeKr7b9jtKqRuBM/jul4ASyoz4o4w/C/xl/L285O0XpXAQWGP9\nvVovKwtHRGQFgP59VC9vJfdB/Tq+PBdEZABfIfwPpdT3ekFmg1LqI+DHwM4Sy/xJ4LMish/YBXxa\nRP57ieVFKXVQ/z4K/E9gW5nlxX9CPqAtRoCH8ZVEmWUGX+k+r5Q6ov/OXd5+UQrPABtEZL3WvHcD\nj8yxTDaPAL+pX/8mvt/eLL9bRIZEZD2wAdijzcdTInKLziT4grXNrKI//8+Anyml/mOPyHyJiCzW\nr0fwYyCvl1VmpdTXlFKrlVLr8M/Nx5VS/7Ss8orImIgsNK/xfd6vlFVeAKXUYeA9EblGL/oHwGtl\nllnzOULXkZErX3nzDJCU6Qe4Ez9z5i3g63Mox3eBQ8AM/tPLF4Fl+EHGN4EfAUut9b+uZd6LlTUA\nbMW/EN8C/hOxANosyrsd30R9GXhR/9xZcpk3AS9omV8BvqGXl1Zma3+ThIHmUsqLn8X3kv551VxP\nZZXX2tcNwLP6vPg+sKTMMgNjwIfAImtZ7vK6imaHw+FwBPSL+8jhcDgcKXBKweFwOBwBTik4HA6H\nI8ApBYfD4XAEOKXgcDgcjgCnFBwOh8MR4JSCw+FwOAKcUnA4HA5HwP8H5AARbAdiV0cAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269d1fc4d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test[:,1], color='C6', linewidth=1.5, linestyle=\"-\", label=\"y_training\")\n",
    "\n",
    "plt.ylabel('some numbers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decay Usage Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 350.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 50688)        1918848     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50688)        0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           3244096     lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 1.2101 - rmse: 0.7755 - acc: 0.7465 - val_loss: 1.2927 - val_rmse: 0.6096 - val_acc: 0.8246\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29269, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.74654, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 1.1982 - rmse: 0.7724 - acc: 0.8386 - val_loss: 1.2877 - val_rmse: 0.6077 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.29269 to 1.28772, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.74654 to 0.83858, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.1957 - rmse: 0.7719 - acc: 0.8667 - val_loss: 1.2850 - val_rmse: 0.6066 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.28772 to 1.28502, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.83858 to 0.86675, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 1.1950 - rmse: 0.7715 - acc: 0.8830 - val_loss: 1.2832 - val_rmse: 0.6058 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.28502 to 1.28316, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc improved from 0.86675 to 0.88304, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 1.1929 - rmse: 0.7706 - acc: 0.8940 - val_loss: 1.2817 - val_rmse: 0.6051 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.28316 to 1.28174, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc improved from 0.88304 to 0.89400, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.1917 - rmse: 0.7698 - acc: 0.9016 - val_loss: 1.2806 - val_rmse: 0.6046 - val_acc: 0.9101\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.28174 to 1.28063, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.89400 to 0.90159, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 1.1902 - rmse: 0.7696 - acc: 0.9084 - val_loss: 1.2797 - val_rmse: 0.6041 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.28063 to 1.27969, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc improved from 0.90159 to 0.90839, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 1.1905 - rmse: 0.7694 - acc: 0.9147 - val_loss: 1.2789 - val_rmse: 0.6037 - val_acc: 0.9195\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.27969 to 1.27891, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00008: acc improved from 0.90839 to 0.91470, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.1902 - rmse: 0.7697 - acc: 0.9192 - val_loss: 1.2782 - val_rmse: 0.6034 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.27891 to 1.27823, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00009: acc improved from 0.91470 to 0.91917, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.1889 - rmse: 0.7685 - acc: 0.9228 - val_loss: 1.2776 - val_rmse: 0.6031 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.27823 to 1.27763, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00010: acc improved from 0.91917 to 0.92284, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 1.1881 - rmse: 0.7684 - acc: 0.9254 - val_loss: 1.2771 - val_rmse: 0.6028 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.27763 to 1.27710, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00011: acc improved from 0.92284 to 0.92541, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 1.1877 - rmse: 0.7681 - acc: 0.9281 - val_loss: 1.2766 - val_rmse: 0.6025 - val_acc: 0.9310\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.27710 to 1.27663, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00012: acc improved from 0.92541 to 0.92811, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.1884 - rmse: 0.7687 - acc: 0.9303 - val_loss: 1.2762 - val_rmse: 0.6023 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.27663 to 1.27621, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00013: acc improved from 0.92811 to 0.93031, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.1879 - rmse: 0.7684 - acc: 0.9331 - val_loss: 1.2758 - val_rmse: 0.6021 - val_acc: 0.9345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss improved from 1.27621 to 1.27583, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00014: acc improved from 0.93031 to 0.93307, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 1.1756 - rmse: 0.7676 - acc: 0.9351 - val_loss: 1.2755 - val_rmse: 0.6019 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.27583 to 1.27548, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc improved from 0.93307 to 0.93509, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 1.1867 - rmse: 0.7672 - acc: 0.9374 - val_loss: 1.2752 - val_rmse: 0.6017 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.27548 to 1.27516, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00016: acc improved from 0.93509 to 0.93735, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 1.1866 - rmse: 0.7677 - acc: 0.9390 - val_loss: 1.2749 - val_rmse: 0.6015 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.27516 to 1.27487, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00017: acc improved from 0.93735 to 0.93901, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 1.1859 - rmse: 0.7668 - acc: 0.9404 - val_loss: 1.2746 - val_rmse: 0.6014 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.27487 to 1.27461, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc improved from 0.93901 to 0.94036, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 1.1864 - rmse: 0.7674 - acc: 0.9417 - val_loss: 1.2744 - val_rmse: 0.6012 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.27461 to 1.27436, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00019: acc improved from 0.94036 to 0.94170, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 1.1758 - rmse: 0.7676 - acc: 0.9429 - val_loss: 1.2741 - val_rmse: 0.6011 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.27436 to 1.27413, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00020: acc improved from 0.94170 to 0.94287, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 1.1865 - rmse: 0.7674 - acc: 0.9438 - val_loss: 1.2739 - val_rmse: 0.6010 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.27413 to 1.27392, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00021: acc improved from 0.94287 to 0.94385, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 1.1856 - rmse: 0.7672 - acc: 0.9448 - val_loss: 1.2737 - val_rmse: 0.6008 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.27392 to 1.27373, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00022: acc improved from 0.94385 to 0.94483, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 1.1863 - rmse: 0.7670 - acc: 0.9454 - val_loss: 1.2735 - val_rmse: 0.6007 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.27373 to 1.27355, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00023: acc improved from 0.94483 to 0.94544, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 1.1852 - rmse: 0.7667 - acc: 0.9461 - val_loss: 1.2734 - val_rmse: 0.6006 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.27355 to 1.27338, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00024: acc improved from 0.94544 to 0.94611, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 1.1851 - rmse: 0.7667 - acc: 0.9467 - val_loss: 1.2732 - val_rmse: 0.6005 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.27338 to 1.27322, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.hdf5\n",
      "\n",
      "Epoch 00025: acc improved from 0.94611 to 0.94666, saving model to D:/KITTI/Graph/Tests/model/350/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b1ada2128>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta =  beta_list[cont]\n",
    "cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate, decay=0.5)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/Tests/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/Tests/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA igual a 950.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 50688)        1918848     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50688)        0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3244096     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,165,090\n",
      "Trainable params: 5,165,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/40\n",
      "16330/16330 [==============================] - 325s 20ms/step - loss: 1.5498 - rmse: 0.7646 - acc: 0.9170 - val_loss: 1.8021 - val_rmse: 0.5936 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.80215, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.91702, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/40\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 1.5046 - rmse: 0.7589 - acc: 0.9639 - val_loss: 1.7914 - val_rmse: 0.5906 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.80215 to 1.79139, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.91702 to 0.96393, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/40\n",
      "16330/16330 [==============================] - 320s 20ms/step - loss: 1.5158 - rmse: 0.7573 - acc: 0.9732 - val_loss: 1.7854 - val_rmse: 0.5887 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.79139 to 1.78544, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.96393 to 0.97318, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.5132 - rmse: 0.7560 - acc: 0.9776 - val_loss: 1.7812 - val_rmse: 0.5875 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.78544 to 1.78124, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc improved from 0.97318 to 0.97765, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.5107 - rmse: 0.7556 - acc: 0.9810 - val_loss: 1.7780 - val_rmse: 0.5864 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.78124 to 1.77805, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc improved from 0.97765 to 0.98096, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4878 - rmse: 0.7538 - acc: 0.9836 - val_loss: 1.7755 - val_rmse: 0.5856 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.77805 to 1.77549, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.98096 to 0.98359, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.5057 - rmse: 0.7545 - acc: 0.9859 - val_loss: 1.7734 - val_rmse: 0.5849 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.77549 to 1.77339, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc improved from 0.98359 to 0.98585, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/40\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 1.5040 - rmse: 0.7534 - acc: 0.9868 - val_loss: 1.7716 - val_rmse: 0.5842 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.77339 to 1.77162, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00008: acc improved from 0.98585 to 0.98677, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.5028 - rmse: 0.7526 - acc: 0.9879 - val_loss: 1.7701 - val_rmse: 0.5837 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.77162 to 1.77008, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00009: acc improved from 0.98677 to 0.98788, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.5013 - rmse: 0.7520 - acc: 0.9889 - val_loss: 1.7688 - val_rmse: 0.5832 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.77008 to 1.76875, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00010: acc improved from 0.98788 to 0.98885, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.5008 - rmse: 0.7524 - acc: 0.9895 - val_loss: 1.7676 - val_rmse: 0.5827 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.76875 to 1.76760, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00011: acc improved from 0.98885 to 0.98947, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 12/40\n",
      "16330/16330 [==============================] - 320s 20ms/step - loss: 1.5000 - rmse: 0.7519 - acc: 0.9898 - val_loss: 1.7666 - val_rmse: 0.5823 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.76760 to 1.76655, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00012: acc improved from 0.98947 to 0.98983, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/40\n",
      "16330/16330 [==============================] - 320s 20ms/step - loss: 1.4987 - rmse: 0.7516 - acc: 0.9904 - val_loss: 1.7656 - val_rmse: 0.5819 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.76655 to 1.76560, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00013: acc improved from 0.98983 to 0.99039, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4984 - rmse: 0.7513 - acc: 0.9906 - val_loss: 1.7648 - val_rmse: 0.5816 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.76560 to 1.76475, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00014: acc improved from 0.99039 to 0.99063, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/40\n",
      "16330/16330 [==============================] - 322s 20ms/step - loss: 1.4975 - rmse: 0.7503 - acc: 0.9913 - val_loss: 1.7640 - val_rmse: 0.5812 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.76475 to 1.76397, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc improved from 0.99063 to 0.99130, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 16/40\n",
      "16330/16330 [==============================] - 320s 20ms/step - loss: 1.4972 - rmse: 0.7501 - acc: 0.9918 - val_loss: 1.7632 - val_rmse: 0.5809 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.76397 to 1.76324, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00016: acc improved from 0.99130 to 0.99179, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4956 - rmse: 0.7498 - acc: 0.9920 - val_loss: 1.7626 - val_rmse: 0.5806 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.76324 to 1.76257, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00017: acc improved from 0.99179 to 0.99204, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4970 - rmse: 0.7511 - acc: 0.9924 - val_loss: 1.7620 - val_rmse: 0.5804 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.76257 to 1.76196, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc improved from 0.99204 to 0.99241, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4953 - rmse: 0.7499 - acc: 0.9927 - val_loss: 1.7614 - val_rmse: 0.5801 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.76196 to 1.76138, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00019: acc improved from 0.99241 to 0.99265, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4946 - rmse: 0.7497 - acc: 0.9930 - val_loss: 1.7608 - val_rmse: 0.5799 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.76138 to 1.76083, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00020: acc improved from 0.99265 to 0.99296, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 21/40\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 1.4946 - rmse: 0.7496 - acc: 0.9930 - val_loss: 1.7603 - val_rmse: 0.5796 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.76083 to 1.76030, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00021: acc improved from 0.99296 to 0.99302, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 22/40\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 1.4943 - rmse: 0.7494 - acc: 0.9931 - val_loss: 1.7598 - val_rmse: 0.5794 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.76030 to 1.75983, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00022: acc improved from 0.99302 to 0.99308, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/40\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 1.4748 - rmse: 0.7488 - acc: 0.9933 - val_loss: 1.7594 - val_rmse: 0.5792 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.75983 to 1.75938, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00023: acc improved from 0.99308 to 0.99326, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 24/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4929 - rmse: 0.7488 - acc: 0.9934 - val_loss: 1.7589 - val_rmse: 0.5790 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.75938 to 1.75893, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00024: acc improved from 0.99326 to 0.99339, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 25/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4738 - rmse: 0.7485 - acc: 0.9936 - val_loss: 1.7585 - val_rmse: 0.5788 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.75893 to 1.75853, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00025: acc improved from 0.99339 to 0.99357, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 26/40\n",
      "16330/16330 [==============================] - 320s 20ms/step - loss: 1.4920 - rmse: 0.7487 - acc: 0.9938 - val_loss: 1.7581 - val_rmse: 0.5786 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.75853 to 1.75814, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00026: acc improved from 0.99357 to 0.99375, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 27/40\n",
      "16330/16330 [==============================] - 322s 20ms/step - loss: 1.4916 - rmse: 0.7482 - acc: 0.9941 - val_loss: 1.7578 - val_rmse: 0.5784 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.75814 to 1.75776, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00027: acc improved from 0.99375 to 0.99406, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 28/40\n",
      "16330/16330 [==============================] - 321s 20ms/step - loss: 1.4921 - rmse: 0.7481 - acc: 0.9942 - val_loss: 1.7574 - val_rmse: 0.5783 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.75776 to 1.75742, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00028: acc improved from 0.99406 to 0.99418, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 29/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4910 - rmse: 0.7482 - acc: 0.9943 - val_loss: 1.7571 - val_rmse: 0.5781 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.75742 to 1.75707, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00029: acc improved from 0.99418 to 0.99430, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 30/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4720 - rmse: 0.7479 - acc: 0.9944 - val_loss: 1.7568 - val_rmse: 0.5779 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.75707 to 1.75675, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00030: acc improved from 0.99430 to 0.99443, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 31/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4913 - rmse: 0.7477 - acc: 0.9945 - val_loss: 1.7564 - val_rmse: 0.5778 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.75675 to 1.75645, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00031: acc improved from 0.99443 to 0.99455, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 32/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4908 - rmse: 0.7475 - acc: 0.9947 - val_loss: 1.7562 - val_rmse: 0.5777 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.75645 to 1.75616, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00032: acc improved from 0.99455 to 0.99467, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4911 - rmse: 0.7481 - acc: 0.9947 - val_loss: 1.7559 - val_rmse: 0.5775 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.75616 to 1.75588, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00033: acc improved from 0.99467 to 0.99473, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 34/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4904 - rmse: 0.7484 - acc: 0.9949 - val_loss: 1.7556 - val_rmse: 0.5774 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.75588 to 1.75561, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00034: acc improved from 0.99473 to 0.99486, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 35/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4832 - rmse: 0.7477 - acc: 0.9949 - val_loss: 1.7554 - val_rmse: 0.5773 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.75561 to 1.75535, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00035: acc improved from 0.99486 to 0.99486, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 36/40\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 1.4899 - rmse: 0.7482 - acc: 0.9949 - val_loss: 1.7551 - val_rmse: 0.5771 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.75535 to 1.75510, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00036: acc did not improve from 0.99486\n",
      "Epoch 37/40\n",
      "16330/16330 [==============================] - 322s 20ms/step - loss: 1.4897 - rmse: 0.7472 - acc: 0.9949 - val_loss: 1.7549 - val_rmse: 0.5770 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.75510 to 1.75486, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00037: acc improved from 0.99486 to 0.99492, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 38/40\n",
      "16330/16330 [==============================] - 320s 20ms/step - loss: 1.4900 - rmse: 0.7477 - acc: 0.9950 - val_loss: 1.7546 - val_rmse: 0.5769 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.75486 to 1.75463, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00038: acc improved from 0.99492 to 0.99498, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n",
      "Epoch 39/40\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 1.4897 - rmse: 0.7474 - acc: 0.9950 - val_loss: 1.7544 - val_rmse: 0.5768 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.75463 to 1.75441, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.99498\n",
      "Epoch 40/40\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 1.4901 - rmse: 0.7471 - acc: 0.9951 - val_loss: 1.7542 - val_rmse: 0.5767 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.75441 to 1.75420, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.hdf5\n",
      "\n",
      "Epoch 00040: acc improved from 0.99498 to 0.99510, saving model to D:/KITTI/Graph/Tests-decay/model/950/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206215d6fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#beta =  beta_list[cont]\n",
    "\n",
    "beta =  950\n",
    "# cont += 1\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "\n",
    "    return sqrt\n",
    "\n",
    "print(\"BETA igual a %s.\"%beta)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate, decay=0.2)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n",
    "\n",
    "model_path = \"D:/KITTI/Graph/Tests-decay/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tb_path = \"D:/KITTI/Graph/Tests-decay/model/\"+str(beta)+\"/1/\"\n",
    "tbCallBack = TensorBoard(log_dir=tb_path, histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+str(beta)+\"/\"+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=40, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beta igual a 950.\n",
      "\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "beta_list = []\n",
    "beta_list.append(950)\n",
    "\n",
    "for beta in beta_list:\n",
    "    print(\"\")\n",
    "    print(\"Beta igual a %s.\"%beta)\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    for sequence in kitti_test_dirs:\n",
    "        cont = 1\n",
    "        print(\"Sequence %s:\"%(sequence))\n",
    "        data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "        data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "        \n",
    "        model_path = \"D:/KITTI/Graph/DepthVOExpanded_Beta/model/\"\n",
    "        filepath_model = model_path+str(beta)+\"/\"+\"weights.best.hdf5\"\n",
    "        \n",
    "        prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                                   data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "\n",
    "        sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "\n",
    "        init_mat = np.identity(4)\n",
    "        sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "\n",
    "        position_X = 0\n",
    "        position_Z = 0\n",
    "        angle_total = pi/2\n",
    "\n",
    "        for element in prediction:\n",
    "            angle = element[0]\n",
    "            displacement = element[1]\n",
    "\n",
    "            angle_total = angle_total - angle\n",
    "\n",
    "            position_X = position_X + displacement*cos(angle_total)\n",
    "            position_Z = position_Z + displacement*sin(angle_total)\n",
    "\n",
    "            sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "\n",
    "            sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 3] = position_X\n",
    "            sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "            sequence_GT[cont, 11] = position_Z\n",
    "\n",
    "            cont += 1\n",
    "\n",
    "        output_path = \"D:/KITTI/output_to_draw/Test_BETA/val_loss/\"+str(beta)+\"/\"\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            # print (model_path)\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        np.savetxt(output_path+\"%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
