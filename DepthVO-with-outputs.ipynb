{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Robotics Toolbox for Python\n",
      "Based on Matlab Toolbox Version 7  April-2002\n",
      "\n",
      "What's new.\n",
      "  Readme      - New features and enhancements in this version.\n",
      "\n",
      "Homogeneous transformations\n",
      "  eul2tr      - Euler angle to transform \n",
      "  oa2tr       - orientation and approach vector to transform \n",
      "  rotx        - transform for rotation about X-axis \n",
      "  roty        - transform for rotation about Y-axis \n",
      "  rotz        - transform for rotation about Z-axis \n",
      "  rpy2tr      - roll/pitch/yaw angles to transform \n",
      "  tr2eul      - transform to Euler angles \n",
      "  tr2rot      - transform to rotation submatrix\n",
      "  tr2rpy      - transform to roll/pitch/yaw angles\n",
      "  transl      - set or extract the translational component of a transform \n",
      "  trnorm      - normalize a transform \n",
      "  \n",
      "Quaternions\n",
      "  /           - divide quaternion by quaternion or scalar\n",
      "  *           - multiply quaternion by a quaternion or vector\n",
      "  inv         - invert a quaternion \n",
      "  norm        - norm of a quaternion \n",
      "  plot        - display a quaternion as a 3D rotation\n",
      "  qinterp     - interpolate quaternions\n",
      "  unit        - unitize a quaternion \n",
      "\n",
      "Kinematics\n",
      "  diff2tr     - differential motion vector to transform \n",
      "  fkine       - compute forward kinematics \n",
      "  ikine       - compute inverse kinematics \n",
      "  ikine560    - compute inverse kinematics for Puma 560 like arm\n",
      "  jacob0      - compute Jacobian in base coordinate frame\n",
      "  jacobn      - compute Jacobian in end-effector coordinate frame\n",
      "  tr2diff     - transform to differential motion vector \n",
      "  tr2jac      - transform to Jacobian \n",
      "  \n",
      "Dynamics\n",
      "  accel       - compute forward dynamics\n",
      "  cinertia    - compute Cartesian manipulator inertia matrix \n",
      "  coriolis    - compute centripetal/coriolis torque \n",
      "  friction    - joint friction\n",
      "  ftrans      - transform force/moment \n",
      "  gravload    - compute gravity loading \n",
      "  inertia     - compute manipulator inertia matrix \n",
      "  itorque     - compute inertia torque \n",
      "  nofriction  - remove friction from a robot object \n",
      "  rne         - inverse dynamics \n",
      "  \n",
      "Trajectory generation\n",
      "  ctraj       - Cartesian trajectory \n",
      "  jtraj       - joint space trajectory \n",
      "  trinterp    - interpolate transform s\n",
      "  \n",
      "Graphics\n",
      "  drivebot    - drive a graphical  robot \n",
      "  plot        - plot/animate robot \n",
      "  \n",
      "Other\n",
      "  manipblty   - compute manipulability \n",
      "  unit        - unitize a vector\n",
      "\n",
      "Creation of robot models.\n",
      "  link        - construct a robot link object \n",
      "  puma560     - Puma 560 data \n",
      "  puma560akb  - Puma 560 data (modified Denavit-Hartenberg)\n",
      "  robot       - construct a robot object \n",
      "  stanford    - Stanford arm data \n",
      "  twolink     - simple 2-link example \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "from resizeimage import resizeimage\n",
    "from PIL import Image\n",
    "\n",
    "# from objectives.VoObjectives import rmse, vo_loss\n",
    "from models.AbstractModel import AbstractModel\n",
    "from dataset.DataGenerationStrategy import OpticalFlowGenerationStrategy\n",
    "from dataset.Sequence import Sequence\n",
    "import robot as rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_dir = 'D:/KITTI/dataset/'\n",
    "\n",
    "kitti_train_dirs = ['00', '01', '02', '03', '04', '05', '06', '07']\n",
    "kitti_test_dirs = ['08', '09', '10']\n",
    "\n",
    "input_width = 155\n",
    "input_height = 47\n",
    "\n",
    "#input_width = 310\n",
    "#input_height = 94\n",
    "\n",
    "input_channel = 1\n",
    "kitti_is_grayscale = True\n",
    "\n",
    "training_seqs = OrderedDict()\n",
    "test_seqs = OrderedDict()\n",
    "\n",
    "name = 'kitti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "\n",
    "        subdir = 'disparity'\n",
    "\n",
    "        \n",
    "        for dir in kitti_train_dirs:\n",
    "            seq_dir = os.path.normpath(os.path.join(data_set_dir, subdir, dir))\n",
    "            training_seqs[dir] = Sequence(seq_dir,\n",
    "                                               extension='png',\n",
    "                                               label_file=os.path.join(seq_dir, dir  + '.txt'),\n",
    "                                               dir=dir,\n",
    "                                               is_grayscale=kitti_is_grayscale,\n",
    "                                               name='Kitti_train/' + dir)\n",
    "\n",
    "        for dir in kitti_test_dirs:\n",
    "            seq_dir = os.path.normpath(os.path.join(data_set_dir, subdir, dir))\n",
    "            print(dir)\n",
    "            \n",
    "            print(os.path.join(seq_dir, subdir))\n",
    "            test_seqs[dir] = Sequence(seq_dir,\n",
    "                                           extension='png',\n",
    "                                           label_file=os.path.join(seq_dir, dir  + '.txt'),\n",
    "                                           dir=dir,\n",
    "                                           is_grayscale=kitti_is_grayscale,\n",
    "                                           name='Kitti_test/' + dir)\n",
    "            \n",
    "def print_info():\n",
    "\n",
    "        print('--------------------------')\n",
    "        print('------Dataset Info--------')\n",
    "        print('Dataset Name: {}'.format(name))\n",
    "        print('Number of Training dirs: {}'.format(len(training_seqs)))\n",
    "        print('Training dirs:')\n",
    "        for directory in training_seqs:\n",
    "            curr_sequence = training_seqs[directory]\n",
    "            print(directory,\n",
    "                  curr_sequence.sequence_dir,\n",
    "                  'Num imgs: {}'.format(curr_sequence.get_num_imgs()),\n",
    "                  'Num label: {}'.format(curr_sequence.get_num_label()))\n",
    "\n",
    "        print('Number of Test dirs: {}'.format(len(test_seqs)))\n",
    "        print('Test dirs:')\n",
    "        for directory in test_seqs:\n",
    "            curr_sequence = test_seqs[directory]\n",
    "            print(directory,\n",
    "                  curr_sequence.sequence_dir,\n",
    "                  'Num imgs: {}'.format(curr_sequence.get_num_imgs()),\n",
    "    'Num label: {}'.format(curr_sequence.get_num_label()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08\n",
      "D:\\KITTI\\dataset\\disparity\\08\\disparity\n",
      "09\n",
      "D:\\KITTI\\dataset\\disparity\\09\\disparity\n",
      "10\n",
      "D:\\KITTI\\dataset\\disparity\\10\\disparity\n",
      "--------------------------\n",
      "------Dataset Info--------\n",
      "Dataset Name: kitti\n",
      "Number of Training dirs: 8\n",
      "Training dirs:\n",
      "00 D:\\KITTI\\dataset\\disparity\\00 Num imgs: 4541 Num label: 4541\n",
      "01 D:\\KITTI\\dataset\\disparity\\01 Num imgs: 1101 Num label: 1101\n",
      "02 D:\\KITTI\\dataset\\disparity\\02 Num imgs: 4661 Num label: 4661\n",
      "03 D:\\KITTI\\dataset\\disparity\\03 Num imgs: 801 Num label: 801\n",
      "04 D:\\KITTI\\dataset\\disparity\\04 Num imgs: 271 Num label: 271\n",
      "05 D:\\KITTI\\dataset\\disparity\\05 Num imgs: 2761 Num label: 2761\n",
      "06 D:\\KITTI\\dataset\\disparity\\06 Num imgs: 1101 Num label: 1101\n",
      "07 D:\\KITTI\\dataset\\disparity\\07 Num imgs: 1101 Num label: 1101\n",
      "Number of Test dirs: 3\n",
      "Test dirs:\n",
      "08 D:\\KITTI\\dataset\\disparity\\08 Num imgs: 4071 Num label: 4071\n",
      "09 D:\\KITTI\\dataset\\disparity\\09 Num imgs: 1591 Num label: 1591\n",
      "10 D:\\KITTI\\dataset\\disparity\\10 Num imgs: 1201 Num label: 1201\n"
     ]
    }
   ],
   "source": [
    "read_data()\n",
    "print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform training pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "{'05', '04', '01', '00', '03', '06', '07', '02'}\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "label_training_all = {}\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "        \n",
    "        t_aux = matrix[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(matrix)\n",
    "        label_aux.append(np.concatenate((rpy, t),1))\n",
    "        \n",
    "    label_training_all[name] = label_aux[1:]\n",
    "\n",
    "print(len(label_training_all))\n",
    "print(set(label_training_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sequence 01: 1100\n",
      "Size of sequence 06: 1100\n",
      "Size of sequence 05: 2760\n",
      "Size of sequence 07: 1100\n",
      "Size of sequence 04: 270\n",
      "Size of sequence 00: 4540\n",
      "Size of sequence 03: 800\n",
      "Size of sequence 02: 4660\n"
     ]
    }
   ],
   "source": [
    "for element in label_training_all:\n",
    "    print(\"Size of sequence %s: %s\"%(element, len(label_training_all[element])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read and normalize training images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:  00\n",
      "List length:  4541\n",
      "Right list length:  4540\n",
      "Left list length:  4540\n",
      "\n",
      "Sequence:  01\n",
      "List length:  1101\n",
      "Right list length:  1100\n",
      "Left list length:  1100\n",
      "\n",
      "Sequence:  02\n",
      "List length:  4661\n",
      "Right list length:  4660\n",
      "Left list length:  4660\n",
      "\n",
      "Sequence:  03\n",
      "List length:  801\n",
      "Right list length:  800\n",
      "Left list length:  800\n",
      "\n",
      "Sequence:  04\n",
      "List length:  271\n",
      "Right list length:  270\n",
      "Left list length:  270\n",
      "\n",
      "Sequence:  05\n",
      "List length:  2761\n",
      "Right list length:  2760\n",
      "Left list length:  2760\n",
      "\n",
      "Sequence:  06\n",
      "List length:  1101\n",
      "Right list length:  1100\n",
      "Left list length:  1100\n",
      "\n",
      "Sequence:  07\n",
      "List length:  1101\n",
      "Right list length:  1100\n",
      "Left list length:  1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_training_all_l = {}\n",
    "dataset_training_all_r = {}\n",
    "\n",
    "for directory in training_seqs:\n",
    "    curr_sequence = training_seqs[directory]\n",
    "    paths = curr_sequence.get_image_paths()\n",
    "    name = curr_sequence.get_dir()\n",
    "    num_images = curr_sequence.get_num_imgs()\n",
    "    img_aux = []\n",
    "    cont = 0\n",
    "    print(\"Sequence: \", name)    \n",
    "    for path in paths:\n",
    "        img = Image.open(path)        \n",
    "        img = img.resize((input_width, input_height))\n",
    "        \n",
    "        img_new = np.array(img.getdata()).reshape(img.size[1], img.size[0])\n",
    "        img_new = img_new / 255.0        \n",
    "        img_aux.append(img_new)\n",
    "        \n",
    "        del(img_new)\n",
    "        del(img)\n",
    "\n",
    "        print(\"%s \\r\"%cont, end=\"\", flush=True)    \n",
    "        cont += 1\n",
    "        \n",
    "    print(\"List length: \", len(img_aux))\n",
    "    print(\"Right list length: \", len(img_aux[1:]))\n",
    "    print(\"Left list length: \", len(img_aux[:-1]))\n",
    "    print(\"\")\n",
    "    \n",
    "    dataset_training_all_r[name] = img_aux[1:]\n",
    "    dataset_training_all_l[name] = img_aux[:-1]\n",
    "    \n",
    "    del(img_aux)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training right: \n",
      "8\n",
      "{'05', '04', '01', '00', '03', '06', '07', '02'}\n",
      "Sequence 01: Size = 1100 and dim = (47, 155).\n",
      "Sequence 06: Size = 1100 and dim = (47, 155).\n",
      "Sequence 05: Size = 2760 and dim = (47, 155).\n",
      "Sequence 07: Size = 1100 and dim = (47, 155).\n",
      "Sequence 04: Size = 270 and dim = (47, 155).\n",
      "Sequence 00: Size = 4540 and dim = (47, 155).\n",
      "Sequence 03: Size = 800 and dim = (47, 155).\n",
      "Sequence 02: Size = 4660 and dim = (47, 155).\n",
      " \n",
      "Training left: \n",
      "8\n",
      "{'05', '04', '01', '00', '03', '06', '07', '02'}\n",
      "Sequence 01: Size = 1100 and dim = (47, 155).\n",
      "Sequence 06: Size = 1100 and dim = (47, 155).\n",
      "Sequence 05: Size = 2760 and dim = (47, 155).\n",
      "Sequence 07: Size = 1100 and dim = (47, 155).\n",
      "Sequence 04: Size = 270 and dim = (47, 155).\n",
      "Sequence 00: Size = 4540 and dim = (47, 155).\n",
      "Sequence 03: Size = 800 and dim = (47, 155).\n",
      "Sequence 02: Size = 4660 and dim = (47, 155).\n"
     ]
    }
   ],
   "source": [
    "print(\"Training right: \")\n",
    "print(len(dataset_training_all_r))\n",
    "print(set(dataset_training_all_r))\n",
    "\n",
    "for element in dataset_training_all_r:\n",
    "    img = dataset_training_all_r[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_training_all_r[element]), \n",
    "                                                  np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))\n",
    "    \n",
    "print(\" \")\n",
    "print(\"Training left: \")\n",
    "\n",
    "print(len(dataset_training_all_l))\n",
    "print(set(dataset_training_all_l))\n",
    "\n",
    "for element in dataset_training_all_l:\n",
    "    img = dataset_training_all_l[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_training_all_l[element]), \n",
    "                                                  np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and test pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'09', '08', '10'}\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "label_test_all = {}\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "        \n",
    "        t_aux = matrix[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(matrix)\n",
    "        label_aux.append(np.concatenate((rpy, t),1))\n",
    "        \n",
    "    label_test_all[name] = label_aux[1:]\n",
    "\n",
    "print(len(label_test_all))\n",
    "print(set(label_test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sequence 10: 1200\n",
      "Size of sequence 08: 4070\n",
      "Size of sequence 09: 1590\n"
     ]
    }
   ],
   "source": [
    "for element in label_test_all:\n",
    "    print(\"Size of sequence %s: %s\"%(element, len(label_test_all[element])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read and normalize test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:  08\n",
      "List length:  4071\n",
      "Right list length:  4070\n",
      "Left list length:  4070\n",
      "\n",
      "Sequence:  09\n",
      "List length:  1591\n",
      "Right list length:  1590\n",
      "Left list length:  1590\n",
      "\n",
      "Sequence:  10\n",
      "List length:  1201\n",
      "Right list length:  1200\n",
      "Left list length:  1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_test_all_r = {}\n",
    "dataset_test_all_l = {}\n",
    "\n",
    "for directory in test_seqs:\n",
    "    curr_sequence = test_seqs[directory]\n",
    "    paths = curr_sequence.get_image_paths()\n",
    "    name = curr_sequence.get_dir()\n",
    "    num_images = curr_sequence.get_num_imgs()\n",
    "    img_aux = []\n",
    "    cont = 0\n",
    "    print(\"Sequence: \", name)\n",
    "    \n",
    "    for path in paths:\n",
    "        img = Image.open(path)        \n",
    "        img = img.resize((input_width, input_height))\n",
    "        \n",
    "        img_new = np.array(img.getdata()).reshape(img.size[1], img.size[0])\n",
    "        img_new = img_new / 255.0        \n",
    "        img_aux.append(img_new)\n",
    "        \n",
    "        del(img_new)\n",
    "        del(img)\n",
    "        percentage = round((cont/num_images)*100,2)\n",
    "        \n",
    "        print(\"%s \\r\"%cont, end=\"\", flush=True)    \n",
    "        cont += 1\n",
    "        \n",
    "    print(\"List length: \", len(img_aux))\n",
    "    print(\"Right list length: \", len(img_aux[1:]))\n",
    "    print(\"Left list length: \", len(img_aux[:-1]))\n",
    "    print(\"\")\n",
    "    \n",
    "    dataset_test_all_r[name] = img_aux[1:]\n",
    "    dataset_test_all_l[name] = img_aux[:-1]\n",
    "    \n",
    "    del(img_aux)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test right: \n",
      "3\n",
      "{'09', '08', '10'}\n",
      "Sequence 10: Size = 1200 and dim = (47, 155).\n",
      "Sequence 08: Size = 4070 and dim = (47, 155).\n",
      "Sequence 09: Size = 1590 and dim = (47, 155).\n",
      " \n",
      "Test left: \n",
      "3\n",
      "{'09', '08', '10'}\n",
      "Sequence 10: Size = 1200 and dim = (47, 155).\n",
      "Sequence 08: Size = 4070 and dim = (47, 155).\n",
      "Sequence 09: Size = 1590 and dim = (47, 155).\n"
     ]
    }
   ],
   "source": [
    "print(\"Test right: \")\n",
    "print(len(dataset_test_all_r))\n",
    "print(set(dataset_test_all_r))\n",
    "\n",
    "for element in dataset_test_all_r:\n",
    "    img = dataset_test_all_r[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_test_all_r[element]), np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))\n",
    "          \n",
    "print(\" \")\n",
    "print(\"Test left: \")\n",
    "\n",
    "print(len(dataset_test_all_l))\n",
    "print(set(dataset_test_all_l))\n",
    "\n",
    "for element in dataset_test_all_l:\n",
    "    img = dataset_test_all_l[element][0]\n",
    "    print(\"Sequence %s: Size = %s and dim = %s.\"%(element, len(dataset_test_all_l[element]), np.shape(img)))\n",
    "    imsave(\"%s.jpg\"%element, img.reshape(input_height, input_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training > size right: 16330, size left: 16330, size label: 16330\n",
      " \n",
      "Test > Size right: 6860, size left: 6860, size label: 6860\n",
      " \n"
     ]
    }
   ],
   "source": [
    "training_r = []\n",
    "training_l = []\n",
    "training_poses = []\n",
    "\n",
    "test_r = []\n",
    "test_l = []\n",
    "test_poses = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    for img in dataset_training_all_r[sequence]:\n",
    "        training_r.append(img)        \n",
    "    for img in dataset_training_all_l[sequence]:\n",
    "        training_l.append(img)   \n",
    "    for pose in label_training_all[sequence]:\n",
    "        training_poses.append(pose)\n",
    "        \n",
    "        #training_r.append(dataset_training_all_r[sequence])\n",
    "        #training_l.append(dataset_training_all_l[sequence][:])\n",
    "        #training_poses.append(label_training_all[sequence][:])\n",
    "        \n",
    "#del(dataset_training_all_r)\n",
    "#del(dataset_training_all_l)\n",
    "#del(label_training_all)\n",
    "\n",
    "print(\"Training > size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(training_r), len(training_l), len(training_poses)))\n",
    "\n",
    "#r = training_poses\n",
    "#print(len(r))\n",
    "print(\" \")\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for img in dataset_test_all_r[sequence]:\n",
    "            test_r.append(img)        \n",
    "        for img in dataset_test_all_l[sequence]:\n",
    "            test_l.append(img)   \n",
    "        for pose in label_test_all[sequence]:\n",
    "            test_poses.append(pose)\n",
    "            \n",
    "#del(dataset_test_all_r)\n",
    "#del(dataset_test_all_l)\n",
    "#del(label_test_all)\n",
    "\n",
    "    #test_r.append(dataset_test_all_r[sequence])\n",
    "    #test_l.append(dataset_test_all_l[sequence])\n",
    "    #test_poses.append(label_test_all[sequence])\n",
    "    \n",
    "print(\"Test > Size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(test_r), len(test_l), len(test_poses)))\n",
    "\n",
    "#l = test_poses['all']\n",
    "#print(len(l))\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 8704)         92672       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 8704)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         17827840    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 2048)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         4196352     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 2048)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            12294       leaky_re_lu_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 22,129,158\n",
      "Trainable params: 22,129,158\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(LeakyReLU(alpha=0.6))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(LeakyReLU(alpha=0.6))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(LeakyReLU(alpha=0.6))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(LeakyReLU(alpha=0.6))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(2048, kernel_initializer='normal')(abs_diff)\n",
    "activation1 = LeakyReLU(alpha=0.6)(dense_layer)\n",
    "#dense_layer1 = Dense(2048, kernel_initializer='normal')(activation1)\n",
    "#activation2 = LeakyReLU(alpha=0.5)(dense_layer1)\n",
    "dense_layer2 = Dense(2048, kernel_initializer='normal')(activation1)\n",
    "activation3 = LeakyReLU(alpha=0.2)(dense_layer2)\n",
    "output = Dense(6, name='predictions', kernel_initializer='normal')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 47, 155, 1)\n",
      "(6860, 47, 155, 1)\n"
     ]
    }
   ],
   "source": [
    "training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "print(np.shape(training_r))\n",
    "\n",
    "test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "print(np.shape(test_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferente criação das poses\n",
    "\n",
    "### Training pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_training_0 = {}\n",
    "label_training_1 = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "    label_training_0[name] = label_aux[:-1]\n",
    "    label_training_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_train = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_training_0[name], label_training_1[name]):\n",
    "        transformation = pose_0.dot(np.linalg.inv(pose_1))\n",
    "        t_aux = transformation[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(transformation)\n",
    "        \n",
    "        T_aux.append(np.concatenate((rpy, t),1))\n",
    "    \n",
    "        T_train[name] = T_aux    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training > size right: 16330, size left: 16330, size label: 16330\n"
     ]
    }
   ],
   "source": [
    "training_poses_transformed = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "  \n",
    "    for pose in T_train[sequence]:\n",
    "        training_poses_transformed.append(pose)\n",
    "\n",
    "print(\"Training > size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(training_r), len(training_l), len(training_poses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_test_0 = {}\n",
    "label_test_1 = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_test_0[name] = label_aux[:-1]\n",
    "    label_test_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_test = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_test_0[name], label_test_1[name]):\n",
    "        transformation = pose_0.dot(np.linalg.inv(pose_1))\n",
    "        t_aux = transformation[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        rpy = rb.tr2rpy(transformation)\n",
    "        \n",
    "        T_aux.append(np.concatenate((rpy, t),1))\n",
    "    \n",
    "    T_test[name] = T_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test > Size right: 6860, size left: 6860, size label: 6860\n"
     ]
    }
   ],
   "source": [
    "test_poses_transformed = []\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for pose in T_test[sequence]:\n",
    "            test_poses_transformed.append(pose)\n",
    "    \n",
    "print(\"Test > Size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(test_r), len(test_l), len(test_poses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 6)\n"
     ]
    }
   ],
   "source": [
    "y_training = np.reshape(training_poses_transformed, (len(training_poses), 6))\n",
    "y_test = np.reshape(test_poses_transformed, (len(test_poses), 6))\n",
    "print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vo_loss2(y_true, y_pred):\n",
    "    loss_value = vo_loss(y_true, y_pred)*100    \n",
    "    return loss_value\n",
    "\n",
    "learning_rate = 0.0001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 4.1864 - rmse: 3.3449 - acc: 0.2222 - val_loss: 2.2808 - val_rmse: 1.7376 - val_acc: 0.2407\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.28078, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.22217, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 2.1557 - rmse: 3.1481 - acc: 0.2715 - val_loss: 1.8118 - val_rmse: 1.5740 - val_acc: 0.2908\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.28078 to 1.81184, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.22217 to 0.27152, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.9134 - rmse: 3.1283 - acc: 0.3043 - val_loss: 1.6078 - val_rmse: 1.5608 - val_acc: 0.2780\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.81184 to 1.60782, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.27152 to 0.30429, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 1.8349 - rmse: 3.0921 - acc: 0.3457 - val_loss: 1.6224 - val_rmse: 1.5641 - val_acc: 0.2797\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60782\n",
      "\n",
      "Epoch 00004: acc improved from 0.30429 to 0.34568, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.7945 - rmse: 3.0728 - acc: 0.3802 - val_loss: 1.5851 - val_rmse: 1.5862 - val_acc: 0.2507\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.60782 to 1.58509, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00005: acc improved from 0.34568 to 0.38016, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 1.7654 - rmse: 3.0642 - acc: 0.4128 - val_loss: 1.5981 - val_rmse: 1.6391 - val_acc: 0.3242\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00006: acc improved from 0.38016 to 0.41280, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.7302 - rmse: 3.0265 - acc: 0.4488 - val_loss: 1.6673 - val_rmse: 1.6127 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00007: acc improved from 0.41280 to 0.44881, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/200\n",
      "16330/16330 [==============================] - 51s 3ms/step - loss: 1.6930 - rmse: 2.9620 - acc: 0.4753 - val_loss: 1.6557 - val_rmse: 1.6405 - val_acc: 0.3433\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00008: acc improved from 0.44881 to 0.47532, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 1.6492 - rmse: 2.8707 - acc: 0.5023 - val_loss: 1.6091 - val_rmse: 1.6661 - val_acc: 0.3207\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00009: acc improved from 0.47532 to 0.50227, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 1.5882 - rmse: 2.7577 - acc: 0.5214 - val_loss: 1.7399 - val_rmse: 1.6891 - val_acc: 0.3278\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00010: acc improved from 0.50227 to 0.52137, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 1.5322 - rmse: 2.6805 - acc: 0.5393 - val_loss: 1.6261 - val_rmse: 1.7091 - val_acc: 0.3450\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00011: acc improved from 0.52137 to 0.53925, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 12/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.4714 - rmse: 2.5431 - acc: 0.5561 - val_loss: 1.6386 - val_rmse: 1.7121 - val_acc: 0.3175\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00012: acc improved from 0.53925 to 0.55609, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.3917 - rmse: 2.3739 - acc: 0.5636 - val_loss: 1.6501 - val_rmse: 1.7318 - val_acc: 0.3321\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00013: acc improved from 0.55609 to 0.56363, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 1.3138 - rmse: 2.1572 - acc: 0.5748 - val_loss: 1.7506 - val_rmse: 1.8614 - val_acc: 0.3306\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00014: acc improved from 0.56363 to 0.57483, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.2177 - rmse: 1.9147 - acc: 0.5783 - val_loss: 1.7323 - val_rmse: 1.7899 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00015: acc improved from 0.57483 to 0.57826, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 16/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 1.1376 - rmse: 1.7520 - acc: 0.5840 - val_loss: 1.6413 - val_rmse: 1.7400 - val_acc: 0.3372\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00016: acc improved from 0.57826 to 0.58396, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.0724 - rmse: 1.6068 - acc: 0.5942 - val_loss: 1.7408 - val_rmse: 1.8649 - val_acc: 0.3413\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00017: acc improved from 0.58396 to 0.59418, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.0175 - rmse: 1.4999 - acc: 0.5999 - val_loss: 1.6579 - val_rmse: 1.7397 - val_acc: 0.3338\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00018: acc improved from 0.59418 to 0.59988, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.9732 - rmse: 1.4270 - acc: 0.6103 - val_loss: 1.6524 - val_rmse: 1.7630 - val_acc: 0.3268\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00019: acc improved from 0.59988 to 0.61029, saving model to D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/200\n",
      "14992/16330 [==========================>...] - ETA: 3s - loss: 0.9455 - rmse: 1.3810 - acc: 0.6175"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-a7f3d255d89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n\u001b[1;32m---> 18\u001b[1;33m                              validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1222\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthSiameseVO/model/1/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthSiameseVO/1/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudar a função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vo_loss_mod(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]* 0.3\n",
    "    mean_rot = mean[:, 0:3] * 150\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "learning_rate = 0.0001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthSiameseVO/model/2/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.6345 - rmse: 1.2921 - acc: 0.6245 - val_loss: 0.9832 - val_rmse: 1.8217 - val_acc: 0.3277\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98322, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.62449, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.5798 - rmse: 1.2189 - acc: 0.6306 - val_loss: 1.0136 - val_rmse: 1.7706 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.98322\n",
      "\n",
      "Epoch 00002: acc improved from 0.62449 to 0.63056, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.5556 - rmse: 1.1949 - acc: 0.6329 - val_loss: 0.9972 - val_rmse: 1.7689 - val_acc: 0.3254\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.98322\n",
      "\n",
      "Epoch 00003: acc improved from 0.63056 to 0.63288, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.5419 - rmse: 1.1833 - acc: 0.6289 - val_loss: 0.9990 - val_rmse: 1.8056 - val_acc: 0.3308\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.98322\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.63288\n",
      "Epoch 5/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.5310 - rmse: 1.1310 - acc: 0.6364 - val_loss: 1.0216 - val_rmse: 1.7689 - val_acc: 0.3405\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.98322\n",
      "\n",
      "Epoch 00005: acc improved from 0.63288 to 0.63637, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.5142 - rmse: 1.1283 - acc: 0.6371 - val_loss: 0.9485 - val_rmse: 1.7707 - val_acc: 0.3241\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.98322 to 0.94847, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.63637 to 0.63711, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.5082 - rmse: 1.0957 - acc: 0.6416 - val_loss: 0.9624 - val_rmse: 1.7340 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.94847\n",
      "\n",
      "Epoch 00007: acc improved from 0.63711 to 0.64158, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4945 - rmse: 1.0819 - acc: 0.6453 - val_loss: 0.9563 - val_rmse: 1.7351 - val_acc: 0.3389\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.94847\n",
      "\n",
      "Epoch 00008: acc improved from 0.64158 to 0.64525, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4868 - rmse: 1.0626 - acc: 0.6462 - val_loss: 0.9460 - val_rmse: 1.7656 - val_acc: 0.3344\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.94847 to 0.94600, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00009: acc improved from 0.64525 to 0.64623, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4739 - rmse: 1.0267 - acc: 0.6506 - val_loss: 0.9331 - val_rmse: 1.7588 - val_acc: 0.3440\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.94600 to 0.93310, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00010: acc improved from 0.64623 to 0.65058, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4634 - rmse: 1.0104 - acc: 0.6542 - val_loss: 0.9313 - val_rmse: 1.7629 - val_acc: 0.3405\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.93310 to 0.93125, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00011: acc improved from 0.65058 to 0.65419, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 12/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4548 - rmse: 0.9896 - acc: 0.6615 - val_loss: 0.9363 - val_rmse: 1.7884 - val_acc: 0.3375\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.93125\n",
      "\n",
      "Epoch 00012: acc improved from 0.65419 to 0.66154, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4494 - rmse: 0.9830 - acc: 0.6541 - val_loss: 1.0425 - val_rmse: 1.8516 - val_acc: 0.3105\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.93125\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.66154\n",
      "Epoch 14/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4382 - rmse: 0.9615 - acc: 0.6662 - val_loss: 0.9075 - val_rmse: 1.7356 - val_acc: 0.3315\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.93125 to 0.90750, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00014: acc improved from 0.66154 to 0.66620, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4319 - rmse: 0.9396 - acc: 0.6658 - val_loss: 0.9575 - val_rmse: 1.7510 - val_acc: 0.3436\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.66620\n",
      "Epoch 16/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4266 - rmse: 0.9328 - acc: 0.6705 - val_loss: 0.9170 - val_rmse: 1.7624 - val_acc: 0.3258\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00016: acc improved from 0.66620 to 0.67048, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.4155 - rmse: 0.9031 - acc: 0.6779 - val_loss: 0.9568 - val_rmse: 1.7364 - val_acc: 0.3561\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00017: acc improved from 0.67048 to 0.67789, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4156 - rmse: 0.9181 - acc: 0.6773 - val_loss: 0.9632 - val_rmse: 1.8632 - val_acc: 0.3411\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.67789\n",
      "Epoch 19/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.4007 - rmse: 0.8800 - acc: 0.6807 - val_loss: 0.9618 - val_rmse: 1.7822 - val_acc: 0.3331\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00019: acc improved from 0.67789 to 0.68071, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3897 - rmse: 0.8536 - acc: 0.6856 - val_loss: 0.9467 - val_rmse: 1.8122 - val_acc: 0.3523\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00020: acc improved from 0.68071 to 0.68561, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 21/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3916 - rmse: 0.8643 - acc: 0.6830 - val_loss: 0.9124 - val_rmse: 1.7633 - val_acc: 0.3364\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.68561\n",
      "Epoch 22/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3873 - rmse: 0.8405 - acc: 0.6925 - val_loss: 0.9536 - val_rmse: 1.7919 - val_acc: 0.3248\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00022: acc improved from 0.68561 to 0.69253, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3755 - rmse: 0.8256 - acc: 0.6931 - val_loss: 0.9141 - val_rmse: 1.7733 - val_acc: 0.3283\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00023: acc improved from 0.69253 to 0.69314, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 24/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3721 - rmse: 0.8204 - acc: 0.6960 - val_loss: 0.9386 - val_rmse: 1.8157 - val_acc: 0.3477\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00024: acc improved from 0.69314 to 0.69602, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 25/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3659 - rmse: 0.7995 - acc: 0.7024 - val_loss: 0.9076 - val_rmse: 1.7716 - val_acc: 0.3306\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00025: acc improved from 0.69602 to 0.70239, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 26/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3576 - rmse: 0.7818 - acc: 0.7028 - val_loss: 0.9180 - val_rmse: 1.7529 - val_acc: 0.3273\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00026: acc improved from 0.70239 to 0.70282, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 27/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3527 - rmse: 0.7903 - acc: 0.7095 - val_loss: 0.9315 - val_rmse: 1.8351 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00027: acc improved from 0.70282 to 0.70949, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 28/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3442 - rmse: 0.7558 - acc: 0.7134 - val_loss: 0.9206 - val_rmse: 1.7339 - val_acc: 0.3378\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00028: acc improved from 0.70949 to 0.71341, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 29/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3385 - rmse: 0.7408 - acc: 0.7141 - val_loss: 0.9137 - val_rmse: 1.7747 - val_acc: 0.3539\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.90750\n",
      "\n",
      "Epoch 00029: acc improved from 0.71341 to 0.71408, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 30/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3402 - rmse: 0.7432 - acc: 0.7162 - val_loss: 0.8989 - val_rmse: 1.7045 - val_acc: 0.3236\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.90750 to 0.89894, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00030: acc improved from 0.71408 to 0.71617, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 31/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3262 - rmse: 0.7269 - acc: 0.7162 - val_loss: 0.9381 - val_rmse: 1.8250 - val_acc: 0.3405\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.89894\n",
      "\n",
      "Epoch 00031: acc did not improve from 0.71617\n",
      "Epoch 32/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3233 - rmse: 0.7143 - acc: 0.7252 - val_loss: 0.8878 - val_rmse: 1.6793 - val_acc: 0.3219\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.89894 to 0.88779, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00032: acc improved from 0.71617 to 0.72517, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 33/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3208 - rmse: 0.7004 - acc: 0.7273 - val_loss: 0.8900 - val_rmse: 1.7429 - val_acc: 0.3528\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.88779\n",
      "\n",
      "Epoch 00033: acc improved from 0.72517 to 0.72731, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 34/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3129 - rmse: 0.6994 - acc: 0.7284 - val_loss: 0.9203 - val_rmse: 1.8196 - val_acc: 0.3554\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.88779\n",
      "\n",
      "Epoch 00034: acc improved from 0.72731 to 0.72835, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 35/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3149 - rmse: 0.6967 - acc: 0.7310 - val_loss: 0.8989 - val_rmse: 1.7500 - val_acc: 0.3337\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.88779\n",
      "\n",
      "Epoch 00035: acc improved from 0.72835 to 0.73099, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 36/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3106 - rmse: 0.6801 - acc: 0.7366 - val_loss: 0.8977 - val_rmse: 1.7624 - val_acc: 0.3429\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.88779\n",
      "\n",
      "Epoch 00036: acc improved from 0.73099 to 0.73656, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 37/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.3029 - rmse: 0.6733 - acc: 0.7394 - val_loss: 0.8907 - val_rmse: 1.7431 - val_acc: 0.3276\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.88779\n",
      "\n",
      "Epoch 00037: acc improved from 0.73656 to 0.73944, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 38/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3022 - rmse: 0.6641 - acc: 0.7390 - val_loss: 0.9264 - val_rmse: 1.7566 - val_acc: 0.3270\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.88779\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.73944\n",
      "Epoch 39/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2993 - rmse: 0.6708 - acc: 0.7377 - val_loss: 0.8843 - val_rmse: 1.7198 - val_acc: 0.3456\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.88779 to 0.88432, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.73944\n",
      "Epoch 40/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2936 - rmse: 0.6447 - acc: 0.7437 - val_loss: 0.8745 - val_rmse: 1.6749 - val_acc: 0.3191\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.88432 to 0.87454, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00040: acc improved from 0.73944 to 0.74366, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 41/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2875 - rmse: 0.6390 - acc: 0.7491 - val_loss: 0.8755 - val_rmse: 1.6930 - val_acc: 0.3488\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.87454\n",
      "\n",
      "Epoch 00041: acc improved from 0.74366 to 0.74905, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 42/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2807 - rmse: 0.6234 - acc: 0.7549 - val_loss: 0.8869 - val_rmse: 1.6934 - val_acc: 0.2950\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.87454\n",
      "\n",
      "Epoch 00042: acc improved from 0.74905 to 0.75487, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 43/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2792 - rmse: 0.6297 - acc: 0.7558 - val_loss: 0.9357 - val_rmse: 1.7869 - val_acc: 0.3426\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.87454\n",
      "\n",
      "Epoch 00043: acc improved from 0.75487 to 0.75585, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 44/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2793 - rmse: 0.6244 - acc: 0.7491 - val_loss: 0.8773 - val_rmse: 1.7219 - val_acc: 0.3369\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.87454\n",
      "\n",
      "Epoch 00044: acc did not improve from 0.75585\n",
      "Epoch 45/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2767 - rmse: 0.6186 - acc: 0.7506 - val_loss: 0.8541 - val_rmse: 1.6590 - val_acc: 0.3485\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.87454 to 0.85409, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00045: acc did not improve from 0.75585\n",
      "Epoch 46/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2692 - rmse: 0.6071 - acc: 0.7583 - val_loss: 0.9025 - val_rmse: 1.7555 - val_acc: 0.3452\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00046: acc improved from 0.75585 to 0.75830, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 47/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2695 - rmse: 0.6023 - acc: 0.7560 - val_loss: 0.8630 - val_rmse: 1.6775 - val_acc: 0.3347\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00047: acc did not improve from 0.75830\n",
      "Epoch 48/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2654 - rmse: 0.5893 - acc: 0.7604 - val_loss: 0.8659 - val_rmse: 1.6824 - val_acc: 0.3509\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00048: acc improved from 0.75830 to 0.76038, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 49/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2576 - rmse: 0.5755 - acc: 0.7609 - val_loss: 0.8796 - val_rmse: 1.7254 - val_acc: 0.3472\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00049: acc improved from 0.76038 to 0.76093, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 50/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2613 - rmse: 0.5876 - acc: 0.7642 - val_loss: 0.8646 - val_rmse: 1.6972 - val_acc: 0.3382\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00050: acc improved from 0.76093 to 0.76418, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 51/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2575 - rmse: 0.5735 - acc: 0.7676 - val_loss: 0.8682 - val_rmse: 1.7054 - val_acc: 0.3650\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00051: acc improved from 0.76418 to 0.76761, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 52/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2525 - rmse: 0.5692 - acc: 0.7683 - val_loss: 0.8919 - val_rmse: 1.7357 - val_acc: 0.3385\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00052: acc improved from 0.76761 to 0.76828, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 53/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2518 - rmse: 0.5645 - acc: 0.7662 - val_loss: 0.8773 - val_rmse: 1.7177 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00053: acc did not improve from 0.76828\n",
      "Epoch 54/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2468 - rmse: 0.5588 - acc: 0.7694 - val_loss: 0.8831 - val_rmse: 1.7336 - val_acc: 0.3564\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00054: acc improved from 0.76828 to 0.76944, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 55/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2454 - rmse: 0.5617 - acc: 0.7726 - val_loss: 0.8646 - val_rmse: 1.6683 - val_acc: 0.3394\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00055: acc improved from 0.76944 to 0.77257, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 56/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2407 - rmse: 0.5434 - acc: 0.7743 - val_loss: 0.8670 - val_rmse: 1.7058 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00056: acc improved from 0.77257 to 0.77434, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 57/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2448 - rmse: 0.5486 - acc: 0.7751 - val_loss: 0.9032 - val_rmse: 1.7764 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00057: acc improved from 0.77434 to 0.77514, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 58/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2377 - rmse: 0.5346 - acc: 0.7715 - val_loss: 0.8797 - val_rmse: 1.7130 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00058: acc did not improve from 0.77514\n",
      "Epoch 59/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2378 - rmse: 0.5438 - acc: 0.7791 - val_loss: 0.8773 - val_rmse: 1.7201 - val_acc: 0.3362\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00059: acc improved from 0.77514 to 0.77912, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 60/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2317 - rmse: 0.5175 - acc: 0.7793 - val_loss: 0.8754 - val_rmse: 1.7111 - val_acc: 0.3554\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00060: acc improved from 0.77912 to 0.77930, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 61/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2328 - rmse: 0.5218 - acc: 0.7796 - val_loss: 0.8684 - val_rmse: 1.7030 - val_acc: 0.3359\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00061: acc improved from 0.77930 to 0.77961, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 62/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.2301 - rmse: 0.5263 - acc: 0.7851 - val_loss: 0.8865 - val_rmse: 1.7238 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.85409\n",
      "\n",
      "Epoch 00062: acc improved from 0.77961 to 0.78506, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 63/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2268 - rmse: 0.5127 - acc: 0.7827 - val_loss: 0.8466 - val_rmse: 1.6542 - val_acc: 0.3378\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.85409 to 0.84662, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00063: acc did not improve from 0.78506\n",
      "Epoch 64/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2226 - rmse: 0.5067 - acc: 0.7862 - val_loss: 0.8631 - val_rmse: 1.6798 - val_acc: 0.3257\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00064: acc improved from 0.78506 to 0.78622, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 65/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2246 - rmse: 0.5064 - acc: 0.7867 - val_loss: 0.8764 - val_rmse: 1.7327 - val_acc: 0.3270\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00065: acc improved from 0.78622 to 0.78665, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 66/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2243 - rmse: 0.5079 - acc: 0.7859 - val_loss: 0.8482 - val_rmse: 1.6657 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00066: acc did not improve from 0.78665\n",
      "Epoch 67/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2182 - rmse: 0.5009 - acc: 0.7855 - val_loss: 0.8484 - val_rmse: 1.6604 - val_acc: 0.3456\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00067: acc did not improve from 0.78665\n",
      "Epoch 68/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2159 - rmse: 0.4955 - acc: 0.7892 - val_loss: 0.8684 - val_rmse: 1.7046 - val_acc: 0.3461\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00068: acc improved from 0.78665 to 0.78922, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 69/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2142 - rmse: 0.4926 - acc: 0.7917 - val_loss: 0.8758 - val_rmse: 1.7282 - val_acc: 0.3404\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00069: acc improved from 0.78922 to 0.79173, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2133 - rmse: 0.4895 - acc: 0.7979 - val_loss: 0.8481 - val_rmse: 1.6649 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00070: acc improved from 0.79173 to 0.79786, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 71/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.2080 - rmse: 0.4789 - acc: 0.7957 - val_loss: 0.8722 - val_rmse: 1.7328 - val_acc: 0.3475\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00071: acc did not improve from 0.79786\n",
      "Epoch 72/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2086 - rmse: 0.4842 - acc: 0.7977 - val_loss: 0.8620 - val_rmse: 1.6938 - val_acc: 0.3431\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.84662\n",
      "\n",
      "Epoch 00072: acc did not improve from 0.79786\n",
      "Epoch 73/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2069 - rmse: 0.4822 - acc: 0.7974 - val_loss: 0.8464 - val_rmse: 1.6621 - val_acc: 0.3449\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.84662 to 0.84636, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00073: acc did not improve from 0.79786\n",
      "Epoch 74/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2067 - rmse: 0.4729 - acc: 0.8002 - val_loss: 0.8502 - val_rmse: 1.6670 - val_acc: 0.3448\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.84636\n",
      "\n",
      "Epoch 00074: acc improved from 0.79786 to 0.80018, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 75/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2031 - rmse: 0.4684 - acc: 0.7991 - val_loss: 0.8522 - val_rmse: 1.6686 - val_acc: 0.3443\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.84636\n",
      "\n",
      "Epoch 00075: acc did not improve from 0.80018\n",
      "Epoch 76/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2035 - rmse: 0.4734 - acc: 0.7991 - val_loss: 0.8461 - val_rmse: 1.6532 - val_acc: 0.3120\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.84636 to 0.84614, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00076: acc did not improve from 0.80018\n",
      "Epoch 77/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2002 - rmse: 0.4607 - acc: 0.7971 - val_loss: 0.8440 - val_rmse: 1.6544 - val_acc: 0.3517\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.84614 to 0.84398, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00077: acc did not improve from 0.80018\n",
      "Epoch 78/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2009 - rmse: 0.4735 - acc: 0.7970 - val_loss: 0.8459 - val_rmse: 1.6458 - val_acc: 0.3370\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.84398\n",
      "\n",
      "Epoch 00078: acc did not improve from 0.80018\n",
      "Epoch 79/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1955 - rmse: 0.4449 - acc: 0.8006 - val_loss: 0.8480 - val_rmse: 1.6772 - val_acc: 0.3612\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.84398\n",
      "\n",
      "Epoch 00079: acc improved from 0.80018 to 0.80055, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 80/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1958 - rmse: 0.4601 - acc: 0.7994 - val_loss: 0.8626 - val_rmse: 1.6993 - val_acc: 0.3528\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.84398\n",
      "\n",
      "Epoch 00080: acc did not improve from 0.80055\n",
      "Epoch 81/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1954 - rmse: 0.4506 - acc: 0.8004 - val_loss: 0.8478 - val_rmse: 1.6674 - val_acc: 0.3535\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.84398\n",
      "\n",
      "Epoch 00081: acc did not improve from 0.80055\n",
      "Epoch 82/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1936 - rmse: 0.4546 - acc: 0.7997 - val_loss: 0.8320 - val_rmse: 1.6303 - val_acc: 0.3452\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.84398 to 0.83201, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00082: acc did not improve from 0.80055\n",
      "Epoch 83/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1916 - rmse: 0.4544 - acc: 0.7984 - val_loss: 0.8620 - val_rmse: 1.7092 - val_acc: 0.3335\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.83201\n",
      "\n",
      "Epoch 00083: acc did not improve from 0.80055\n",
      "Epoch 84/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1882 - rmse: 0.4415 - acc: 0.8075 - val_loss: 0.8332 - val_rmse: 1.6332 - val_acc: 0.3364\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.83201\n",
      "\n",
      "Epoch 00084: acc improved from 0.80055 to 0.80753, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 85/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1902 - rmse: 0.4468 - acc: 0.8043 - val_loss: 0.8454 - val_rmse: 1.6715 - val_acc: 0.3395\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.83201\n",
      "\n",
      "Epoch 00085: acc did not improve from 0.80753\n",
      "Epoch 86/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1854 - rmse: 0.4342 - acc: 0.8063 - val_loss: 0.8423 - val_rmse: 1.6547 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.83201\n",
      "\n",
      "Epoch 00086: acc did not improve from 0.80753\n",
      "Epoch 87/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1868 - rmse: 0.4377 - acc: 0.8071 - val_loss: 0.8499 - val_rmse: 1.6744 - val_acc: 0.3493\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.83201\n",
      "\n",
      "Epoch 00087: acc did not improve from 0.80753\n",
      "Epoch 88/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1833 - rmse: 0.4274 - acc: 0.8085 - val_loss: 0.8489 - val_rmse: 1.6609 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.83201\n",
      "\n",
      "Epoch 00088: acc improved from 0.80753 to 0.80851, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 89/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1830 - rmse: 0.4310 - acc: 0.8130 - val_loss: 0.8316 - val_rmse: 1.6373 - val_acc: 0.3407\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.83201 to 0.83156, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00089: acc improved from 0.80851 to 0.81298, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 90/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.1846 - rmse: 0.4361 - acc: 0.8088 - val_loss: 0.8592 - val_rmse: 1.6930 - val_acc: 0.3366\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00090: acc did not improve from 0.81298\n",
      "Epoch 91/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1813 - rmse: 0.4254 - acc: 0.8089 - val_loss: 0.8577 - val_rmse: 1.7118 - val_acc: 0.3421\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00091: acc did not improve from 0.81298\n",
      "Epoch 92/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1770 - rmse: 0.4233 - acc: 0.8126 - val_loss: 0.8550 - val_rmse: 1.6760 - val_acc: 0.3426\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00092: acc did not improve from 0.81298\n",
      "Epoch 93/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1771 - rmse: 0.4146 - acc: 0.8151 - val_loss: 0.8445 - val_rmse: 1.6700 - val_acc: 0.3383\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00093: acc improved from 0.81298 to 0.81513, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 94/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1766 - rmse: 0.4191 - acc: 0.8141 - val_loss: 0.8507 - val_rmse: 1.6797 - val_acc: 0.3325\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00094: acc did not improve from 0.81513\n",
      "Epoch 95/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.1740 - rmse: 0.4139 - acc: 0.8169 - val_loss: 0.8643 - val_rmse: 1.7223 - val_acc: 0.3465\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00095: acc improved from 0.81513 to 0.81690, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1777 - rmse: 0.4290 - acc: 0.8126 - val_loss: 0.8410 - val_rmse: 1.6629 - val_acc: 0.3430\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00096: acc did not improve from 0.81690\n",
      "Epoch 97/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1715 - rmse: 0.4057 - acc: 0.8186 - val_loss: 0.8503 - val_rmse: 1.6777 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00097: acc improved from 0.81690 to 0.81862, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 98/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1727 - rmse: 0.4131 - acc: 0.8127 - val_loss: 0.8351 - val_rmse: 1.6389 - val_acc: 0.3459\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00098: acc did not improve from 0.81862\n",
      "Epoch 99/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1710 - rmse: 0.4067 - acc: 0.8180 - val_loss: 0.8441 - val_rmse: 1.6756 - val_acc: 0.3504\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00099: acc did not improve from 0.81862\n",
      "Epoch 100/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1696 - rmse: 0.4012 - acc: 0.8166 - val_loss: 0.8496 - val_rmse: 1.6833 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00100: acc did not improve from 0.81862\n",
      "Epoch 101/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1690 - rmse: 0.4035 - acc: 0.8156 - val_loss: 0.8477 - val_rmse: 1.6784 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00101: acc did not improve from 0.81862\n",
      "Epoch 102/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1662 - rmse: 0.4045 - acc: 0.8226 - val_loss: 0.8383 - val_rmse: 1.6564 - val_acc: 0.3515\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00102: acc improved from 0.81862 to 0.82260, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 103/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1658 - rmse: 0.3943 - acc: 0.8155 - val_loss: 0.8522 - val_rmse: 1.6957 - val_acc: 0.3496\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00103: acc did not improve from 0.82260\n",
      "Epoch 104/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1663 - rmse: 0.3936 - acc: 0.8211 - val_loss: 0.8374 - val_rmse: 1.6524 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00104: acc did not improve from 0.82260\n",
      "Epoch 105/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1665 - rmse: 0.3982 - acc: 0.8201 - val_loss: 0.8433 - val_rmse: 1.6652 - val_acc: 0.3501\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00105: acc did not improve from 0.82260\n",
      "Epoch 106/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1631 - rmse: 0.3916 - acc: 0.8184 - val_loss: 0.8375 - val_rmse: 1.6550 - val_acc: 0.3513\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00106: acc did not improve from 0.82260\n",
      "Epoch 107/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1605 - rmse: 0.3858 - acc: 0.8242 - val_loss: 0.8409 - val_rmse: 1.6668 - val_acc: 0.3338\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00107: acc improved from 0.82260 to 0.82419, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 108/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1618 - rmse: 0.3884 - acc: 0.8195 - val_loss: 0.8344 - val_rmse: 1.6461 - val_acc: 0.3633\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00108: acc did not improve from 0.82419\n",
      "Epoch 109/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1588 - rmse: 0.3823 - acc: 0.8239 - val_loss: 0.8527 - val_rmse: 1.7028 - val_acc: 0.3408\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.83156\n",
      "\n",
      "Epoch 00109: acc did not improve from 0.82419\n",
      "Epoch 110/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1601 - rmse: 0.3879 - acc: 0.8238 - val_loss: 0.8270 - val_rmse: 1.6373 - val_acc: 0.3517\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.83156 to 0.82695, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00110: acc did not improve from 0.82419\n",
      "Epoch 111/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1589 - rmse: 0.3824 - acc: 0.8198 - val_loss: 0.8509 - val_rmse: 1.6846 - val_acc: 0.3554\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.82695\n",
      "\n",
      "Epoch 00111: acc did not improve from 0.82419\n",
      "Epoch 112/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1571 - rmse: 0.3733 - acc: 0.8266 - val_loss: 0.8252 - val_rmse: 1.6348 - val_acc: 0.3528\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.82695 to 0.82516, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00112: acc improved from 0.82419 to 0.82658, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 113/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1564 - rmse: 0.3769 - acc: 0.8240 - val_loss: 0.8367 - val_rmse: 1.6575 - val_acc: 0.3650\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.82516\n",
      "\n",
      "Epoch 00113: acc did not improve from 0.82658\n",
      "Epoch 114/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1563 - rmse: 0.3800 - acc: 0.8236 - val_loss: 0.8246 - val_rmse: 1.6239 - val_acc: 0.3542\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.82516 to 0.82460, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00114: acc did not improve from 0.82658\n",
      "Epoch 115/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1544 - rmse: 0.3728 - acc: 0.8280 - val_loss: 0.8425 - val_rmse: 1.6706 - val_acc: 0.3469\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.82460\n",
      "\n",
      "Epoch 00115: acc improved from 0.82658 to 0.82805, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 116/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1555 - rmse: 0.3749 - acc: 0.8320 - val_loss: 0.8367 - val_rmse: 1.6597 - val_acc: 0.3478\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.82460\n",
      "\n",
      "Epoch 00116: acc improved from 0.82805 to 0.83203, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 117/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1532 - rmse: 0.3726 - acc: 0.8270 - val_loss: 0.8293 - val_rmse: 1.6438 - val_acc: 0.3672\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.82460\n",
      "\n",
      "Epoch 00117: acc did not improve from 0.83203\n",
      "Epoch 118/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1520 - rmse: 0.3724 - acc: 0.8293 - val_loss: 0.8537 - val_rmse: 1.6919 - val_acc: 0.3487\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.82460\n",
      "\n",
      "Epoch 00118: acc did not improve from 0.83203\n",
      "Epoch 119/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1504 - rmse: 0.3620 - acc: 0.8317 - val_loss: 0.8359 - val_rmse: 1.6541 - val_acc: 0.3357\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.82460\n",
      "\n",
      "Epoch 00119: acc did not improve from 0.83203\n",
      "Epoch 120/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1520 - rmse: 0.3753 - acc: 0.8290 - val_loss: 0.8415 - val_rmse: 1.6718 - val_acc: 0.3426\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.82460\n",
      "\n",
      "Epoch 00120: acc did not improve from 0.83203\n",
      "Epoch 121/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1496 - rmse: 0.3686 - acc: 0.8307 - val_loss: 0.8169 - val_rmse: 1.6147 - val_acc: 0.3417\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.82460 to 0.81694, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00121: acc did not improve from 0.83203\n",
      "Epoch 122/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1489 - rmse: 0.3628 - acc: 0.8273 - val_loss: 0.8339 - val_rmse: 1.6451 - val_acc: 0.3389\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00122: acc did not improve from 0.83203\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1489 - rmse: 0.3597 - acc: 0.8310 - val_loss: 0.8471 - val_rmse: 1.6853 - val_acc: 0.3395\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00123: acc did not improve from 0.83203\n",
      "Epoch 124/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1469 - rmse: 0.3532 - acc: 0.8344 - val_loss: 0.8278 - val_rmse: 1.6359 - val_acc: 0.3464\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00124: acc improved from 0.83203 to 0.83442, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 125/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1476 - rmse: 0.3648 - acc: 0.8317 - val_loss: 0.8256 - val_rmse: 1.6270 - val_acc: 0.3561\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00125: acc did not improve from 0.83442\n",
      "Epoch 126/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1462 - rmse: 0.3599 - acc: 0.8339 - val_loss: 0.8301 - val_rmse: 1.6423 - val_acc: 0.3517\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00126: acc did not improve from 0.83442\n",
      "Epoch 127/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1468 - rmse: 0.3642 - acc: 0.8307 - val_loss: 0.8269 - val_rmse: 1.6315 - val_acc: 0.3504\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00127: acc did not improve from 0.83442\n",
      "Epoch 128/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1440 - rmse: 0.3554 - acc: 0.8307 - val_loss: 0.8280 - val_rmse: 1.6394 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00128: acc did not improve from 0.83442\n",
      "Epoch 129/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1443 - rmse: 0.3513 - acc: 0.8343 - val_loss: 0.8187 - val_rmse: 1.6163 - val_acc: 0.3602\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00129: acc did not improve from 0.83442\n",
      "Epoch 130/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1430 - rmse: 0.3541 - acc: 0.8378 - val_loss: 0.8401 - val_rmse: 1.6709 - val_acc: 0.3350\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00130: acc improved from 0.83442 to 0.83778, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 131/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1409 - rmse: 0.3437 - acc: 0.8331 - val_loss: 0.8309 - val_rmse: 1.6382 - val_acc: 0.3363\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00131: acc did not improve from 0.83778\n",
      "Epoch 132/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1417 - rmse: 0.3473 - acc: 0.8334 - val_loss: 0.8310 - val_rmse: 1.6471 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00132: acc did not improve from 0.83778\n",
      "Epoch 133/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1396 - rmse: 0.3437 - acc: 0.8355 - val_loss: 0.8333 - val_rmse: 1.6479 - val_acc: 0.3376\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00133: acc did not improve from 0.83778\n",
      "Epoch 134/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1385 - rmse: 0.3380 - acc: 0.8349 - val_loss: 0.8216 - val_rmse: 1.6227 - val_acc: 0.3392\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00134: acc did not improve from 0.83778\n",
      "Epoch 135/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1401 - rmse: 0.3418 - acc: 0.8374 - val_loss: 0.8249 - val_rmse: 1.6264 - val_acc: 0.3439\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00135: acc did not improve from 0.83778\n",
      "Epoch 136/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1390 - rmse: 0.3461 - acc: 0.8391 - val_loss: 0.8441 - val_rmse: 1.6773 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00136: acc improved from 0.83778 to 0.83913, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 137/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1380 - rmse: 0.3401 - acc: 0.8374 - val_loss: 0.8310 - val_rmse: 1.6298 - val_acc: 0.3397\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00137: acc did not improve from 0.83913\n",
      "Epoch 138/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1369 - rmse: 0.3354 - acc: 0.8371 - val_loss: 0.8385 - val_rmse: 1.6691 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00138: acc did not improve from 0.83913\n",
      "Epoch 139/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1366 - rmse: 0.3352 - acc: 0.8353 - val_loss: 0.8242 - val_rmse: 1.6269 - val_acc: 0.3443\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00139: acc did not improve from 0.83913\n",
      "Epoch 140/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1365 - rmse: 0.3363 - acc: 0.8402 - val_loss: 0.8217 - val_rmse: 1.6247 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00140: acc improved from 0.83913 to 0.84017, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 141/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1332 - rmse: 0.3285 - acc: 0.8440 - val_loss: 0.8312 - val_rmse: 1.6517 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00141: acc improved from 0.84017 to 0.84403, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 142/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1339 - rmse: 0.3258 - acc: 0.8410 - val_loss: 0.8292 - val_rmse: 1.6416 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00142: acc did not improve from 0.84403\n",
      "Epoch 143/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1344 - rmse: 0.3301 - acc: 0.8454 - val_loss: 0.8254 - val_rmse: 1.6283 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00143: acc improved from 0.84403 to 0.84544, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 144/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1327 - rmse: 0.3292 - acc: 0.8430 - val_loss: 0.8290 - val_rmse: 1.6441 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00144: acc did not improve from 0.84544\n",
      "Epoch 145/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1322 - rmse: 0.3223 - acc: 0.8415 - val_loss: 0.8228 - val_rmse: 1.6331 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00145: acc did not improve from 0.84544\n",
      "Epoch 146/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1340 - rmse: 0.3360 - acc: 0.8405 - val_loss: 0.8270 - val_rmse: 1.6423 - val_acc: 0.3471\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00146: acc did not improve from 0.84544\n",
      "Epoch 147/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1311 - rmse: 0.3275 - acc: 0.8432 - val_loss: 0.8240 - val_rmse: 1.6274 - val_acc: 0.3496\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00147: acc did not improve from 0.84544\n",
      "Epoch 148/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1310 - rmse: 0.3239 - acc: 0.8448 - val_loss: 0.8256 - val_rmse: 1.6323 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00148: acc did not improve from 0.84544\n",
      "Epoch 149/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1314 - rmse: 0.3261 - acc: 0.8453 - val_loss: 0.8280 - val_rmse: 1.6426 - val_acc: 0.3401\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00149: acc did not improve from 0.84544\n",
      "Epoch 150/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1295 - rmse: 0.3194 - acc: 0.8451 - val_loss: 0.8280 - val_rmse: 1.6339 - val_acc: 0.3472\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00150: acc did not improve from 0.84544\n",
      "Epoch 151/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1298 - rmse: 0.3233 - acc: 0.8447 - val_loss: 0.8296 - val_rmse: 1.6461 - val_acc: 0.3545\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00151: acc did not improve from 0.84544\n",
      "Epoch 152/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1271 - rmse: 0.3163 - acc: 0.8477 - val_loss: 0.8357 - val_rmse: 1.6628 - val_acc: 0.3472\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00152: acc improved from 0.84544 to 0.84770, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 153/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1264 - rmse: 0.3123 - acc: 0.8507 - val_loss: 0.8462 - val_rmse: 1.6651 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00153: acc improved from 0.84770 to 0.85070, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 154/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1283 - rmse: 0.3165 - acc: 0.8445 - val_loss: 0.8254 - val_rmse: 1.6330 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00154: acc did not improve from 0.85070\n",
      "Epoch 155/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1290 - rmse: 0.3175 - acc: 0.8479 - val_loss: 0.8201 - val_rmse: 1.6276 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00155: acc did not improve from 0.85070\n",
      "Epoch 156/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1255 - rmse: 0.3113 - acc: 0.8435 - val_loss: 0.8191 - val_rmse: 1.6198 - val_acc: 0.3545\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00156: acc did not improve from 0.85070\n",
      "Epoch 157/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1274 - rmse: 0.3163 - acc: 0.8468 - val_loss: 0.8320 - val_rmse: 1.6496 - val_acc: 0.3404\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00157: acc did not improve from 0.85070\n",
      "Epoch 158/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1270 - rmse: 0.3156 - acc: 0.8487 - val_loss: 0.8256 - val_rmse: 1.6381 - val_acc: 0.3469\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.81694\n",
      "\n",
      "Epoch 00158: acc did not improve from 0.85070\n",
      "Epoch 159/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1233 - rmse: 0.3022 - acc: 0.8509 - val_loss: 0.8112 - val_rmse: 1.5951 - val_acc: 0.3328\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.81694 to 0.81122, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00159: acc improved from 0.85070 to 0.85089, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 160/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1273 - rmse: 0.3166 - acc: 0.8491 - val_loss: 0.8117 - val_rmse: 1.5919 - val_acc: 0.3137\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00160: acc did not improve from 0.85089\n",
      "Epoch 161/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1254 - rmse: 0.3125 - acc: 0.8508 - val_loss: 0.8166 - val_rmse: 1.6144 - val_acc: 0.3350\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00161: acc did not improve from 0.85089\n",
      "Epoch 162/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1249 - rmse: 0.3119 - acc: 0.8482 - val_loss: 0.8282 - val_rmse: 1.6409 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00162: acc did not improve from 0.85089\n",
      "Epoch 163/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1232 - rmse: 0.3057 - acc: 0.8490 - val_loss: 0.8202 - val_rmse: 1.6225 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00163: acc did not improve from 0.85089\n",
      "Epoch 164/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1248 - rmse: 0.3097 - acc: 0.8528 - val_loss: 0.8141 - val_rmse: 1.6088 - val_acc: 0.3574\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00164: acc improved from 0.85089 to 0.85285, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 165/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1214 - rmse: 0.3024 - acc: 0.8557 - val_loss: 0.8306 - val_rmse: 1.6435 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00165: acc improved from 0.85285 to 0.85566, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 166/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1219 - rmse: 0.3001 - acc: 0.8539 - val_loss: 0.8204 - val_rmse: 1.6143 - val_acc: 0.3455\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00166: acc did not improve from 0.85566\n",
      "Epoch 167/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1204 - rmse: 0.2981 - acc: 0.8539 - val_loss: 0.8200 - val_rmse: 1.6305 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00167: acc did not improve from 0.85566\n",
      "Epoch 168/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1208 - rmse: 0.2983 - acc: 0.8509 - val_loss: 0.8307 - val_rmse: 1.6573 - val_acc: 0.3487\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00168: acc did not improve from 0.85566\n",
      "Epoch 169/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1199 - rmse: 0.2969 - acc: 0.8533 - val_loss: 0.8144 - val_rmse: 1.6023 - val_acc: 0.3302\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00169: acc did not improve from 0.85566\n",
      "Epoch 170/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1220 - rmse: 0.3071 - acc: 0.8505 - val_loss: 0.8436 - val_rmse: 1.6833 - val_acc: 0.3440\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00170: acc did not improve from 0.85566\n",
      "Epoch 171/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1182 - rmse: 0.2906 - acc: 0.8528 - val_loss: 0.8331 - val_rmse: 1.6609 - val_acc: 0.3499\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00171: acc did not improve from 0.85566\n",
      "Epoch 172/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1193 - rmse: 0.2952 - acc: 0.8570 - val_loss: 0.8260 - val_rmse: 1.6328 - val_acc: 0.3300\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00172: acc improved from 0.85566 to 0.85695, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 173/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1184 - rmse: 0.2922 - acc: 0.8530 - val_loss: 0.8341 - val_rmse: 1.6472 - val_acc: 0.3554\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00173: acc did not improve from 0.85695\n",
      "Epoch 174/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1193 - rmse: 0.2986 - acc: 0.8516 - val_loss: 0.8193 - val_rmse: 1.6099 - val_acc: 0.3351\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00174: acc did not improve from 0.85695\n",
      "Epoch 175/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1194 - rmse: 0.3000 - acc: 0.8552 - val_loss: 0.8422 - val_rmse: 1.6817 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00175: acc did not improve from 0.85695\n",
      "Epoch 176/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1166 - rmse: 0.2869 - acc: 0.8566 - val_loss: 0.8161 - val_rmse: 1.6167 - val_acc: 0.3491\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00176: acc did not improve from 0.85695\n",
      "Epoch 177/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1148 - rmse: 0.2828 - acc: 0.8587 - val_loss: 0.8277 - val_rmse: 1.6455 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00177: acc improved from 0.85695 to 0.85867, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 178/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1168 - rmse: 0.2923 - acc: 0.8592 - val_loss: 0.8261 - val_rmse: 1.6358 - val_acc: 0.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00178: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00178: acc improved from 0.85867 to 0.85915, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 179/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1162 - rmse: 0.2898 - acc: 0.8566 - val_loss: 0.8238 - val_rmse: 1.6326 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00179: acc did not improve from 0.85915\n",
      "Epoch 180/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.1169 - rmse: 0.2907 - acc: 0.8567 - val_loss: 0.8333 - val_rmse: 1.6580 - val_acc: 0.3564\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00180: acc did not improve from 0.85915\n",
      "Epoch 181/200\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.1169 - rmse: 0.2935 - acc: 0.8554 - val_loss: 0.8287 - val_rmse: 1.6432 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00181: acc did not improve from 0.85915\n",
      "Epoch 182/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.1167 - rmse: 0.2894 - acc: 0.8612 - val_loss: 0.8356 - val_rmse: 1.6606 - val_acc: 0.3620\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00182: acc improved from 0.85915 to 0.86118, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 183/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.1152 - rmse: 0.2905 - acc: 0.8590 - val_loss: 0.8287 - val_rmse: 1.6406 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.81122\n",
      "\n",
      "Epoch 00183: acc did not improve from 0.86118\n",
      "Epoch 184/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1139 - rmse: 0.2855 - acc: 0.8588 - val_loss: 0.8104 - val_rmse: 1.6060 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.81122 to 0.81044, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00184: acc did not improve from 0.86118\n",
      "Epoch 185/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1132 - rmse: 0.2806 - acc: 0.8562 - val_loss: 0.8209 - val_rmse: 1.6243 - val_acc: 0.3503\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00185: acc did not improve from 0.86118\n",
      "Epoch 186/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1152 - rmse: 0.2889 - acc: 0.8586 - val_loss: 0.8160 - val_rmse: 1.6113 - val_acc: 0.3496\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00186: acc did not improve from 0.86118\n",
      "Epoch 187/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1136 - rmse: 0.2839 - acc: 0.8598 - val_loss: 0.8318 - val_rmse: 1.6524 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00187: acc did not improve from 0.86118\n",
      "Epoch 188/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1134 - rmse: 0.2837 - acc: 0.8596 - val_loss: 0.8501 - val_rmse: 1.7023 - val_acc: 0.3523\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00188: acc did not improve from 0.86118\n",
      "Epoch 189/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1129 - rmse: 0.2827 - acc: 0.8641 - val_loss: 0.8163 - val_rmse: 1.6103 - val_acc: 0.3366\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00189: acc improved from 0.86118 to 0.86405, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 190/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1118 - rmse: 0.2842 - acc: 0.8601 - val_loss: 0.8279 - val_rmse: 1.6462 - val_acc: 0.3499\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00190: acc did not improve from 0.86405\n",
      "Epoch 191/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1124 - rmse: 0.2815 - acc: 0.8603 - val_loss: 0.8299 - val_rmse: 1.6520 - val_acc: 0.3665\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00191: acc did not improve from 0.86405\n",
      "Epoch 192/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1123 - rmse: 0.2789 - acc: 0.8595 - val_loss: 0.8276 - val_rmse: 1.6482 - val_acc: 0.3536\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00192: acc did not improve from 0.86405\n",
      "Epoch 193/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1108 - rmse: 0.2779 - acc: 0.8603 - val_loss: 0.8364 - val_rmse: 1.6761 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.81044\n",
      "\n",
      "Epoch 00193: acc did not improve from 0.86405\n",
      "Epoch 194/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1109 - rmse: 0.2784 - acc: 0.8650 - val_loss: 0.8093 - val_rmse: 1.5941 - val_acc: 0.3525\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.81044 to 0.80932, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00194: acc improved from 0.86405 to 0.86503, saving model to D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5\n",
      "Epoch 195/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1123 - rmse: 0.2800 - acc: 0.8570 - val_loss: 0.8232 - val_rmse: 1.6287 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.80932\n",
      "\n",
      "Epoch 00195: acc did not improve from 0.86503\n",
      "Epoch 196/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1107 - rmse: 0.2805 - acc: 0.8633 - val_loss: 0.8180 - val_rmse: 1.6172 - val_acc: 0.3474\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.80932\n",
      "\n",
      "Epoch 00196: acc did not improve from 0.86503\n",
      "Epoch 197/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1092 - rmse: 0.2687 - acc: 0.8609 - val_loss: 0.8258 - val_rmse: 1.6439 - val_acc: 0.3356\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.80932\n",
      "\n",
      "Epoch 00197: acc did not improve from 0.86503\n",
      "Epoch 198/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1089 - rmse: 0.2730 - acc: 0.8637 - val_loss: 0.8295 - val_rmse: 1.6477 - val_acc: 0.3395\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.80932\n",
      "\n",
      "Epoch 00198: acc did not improve from 0.86503\n",
      "Epoch 199/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1104 - rmse: 0.2753 - acc: 0.8647 - val_loss: 0.8121 - val_rmse: 1.6045 - val_acc: 0.3586\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.80932\n",
      "\n",
      "Epoch 00199: acc did not improve from 0.86503\n",
      "Epoch 200/200\n",
      "16330/16330 [==============================] - 47s 3ms/step - loss: 0.1075 - rmse: 0.2658 - acc: 0.8617 - val_loss: 0.8335 - val_rmse: 1.6551 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.80932\n",
      "\n",
      "Epoch 00200: acc did not improve from 0.86503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2079da0f400>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthSiameseVO/model/2/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthSiameseVO/2/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/1/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/1/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "    \n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/1/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/1/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/1/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n",
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/2/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/2/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "    \n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/2/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/2/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/2/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes com o valore de Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudar a métrica para compreender os valores de perdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translation_loss(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]\n",
    "    # mean_rot = mean[:, 0:3] * 150\n",
    "    #mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean_trasl, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "def rotation_loss(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    #mean_trasl = mean[:, 3:6]\n",
    "    mean_rot = mean[:, 0:3]\n",
    "    #mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean_rot, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "def mean_loss(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]\n",
    "    mean_rot = mean[:, 0:3]\n",
    "    #mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt_trasl = K.sqrt(K.mean(mean_rot, axis=-1))\n",
    "    sqrt_rot = K.sqrt(K.mean(mean_trasl, axis=-1))\n",
    "    return (sqrt_rot/sqrt_trasl)\n",
    "\n",
    "def vo_loss_mod(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]* 0.3\n",
    "    mean_rot = mean[:, 0:3] * 150\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "def vo_loss_mod2(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]* 0.5\n",
    "    mean_rot = mean[:, 0:3] * 120\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "learning_rate = 0.0005\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod], optimizer=opt, metrics=[rmse, mean_loss, 'acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 1.2594 - rmse: 3.1446 - mean_loss: 76.9689 - acc: 0.2515 - val_loss: 0.9317 - val_rmse: 1.5439 - val_mean_loss: 82.9117 - val_acc: 0.2958\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93173, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.25150, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 1.0327 - rmse: 3.1379 - mean_loss: 132.9902 - acc: 0.2918 - val_loss: 0.8293 - val_rmse: 1.5433 - val_mean_loss: 172.6612 - val_acc: 0.3069\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93173 to 0.82930, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.25150 to 0.29179, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9888 - rmse: 3.1553 - mean_loss: 167.9470 - acc: 0.3310 - val_loss: 0.8605 - val_rmse: 1.5433 - val_mean_loss: 93.4834 - val_acc: 0.3515\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.82930\n",
      "\n",
      "Epoch 00003: acc improved from 0.29179 to 0.33099, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9760 - rmse: 3.1240 - mean_loss: 180.3595 - acc: 0.3425 - val_loss: 0.8556 - val_rmse: 1.5466 - val_mean_loss: 110.9579 - val_acc: 0.2792\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.82930\n",
      "\n",
      "Epoch 00004: acc improved from 0.33099 to 0.34250, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9703 - rmse: 3.1238 - mean_loss: 188.1621 - acc: 0.3481 - val_loss: 0.8253 - val_rmse: 1.5318 - val_mean_loss: 133.8285 - val_acc: 0.3411\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.82930 to 0.82526, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00005: acc improved from 0.34250 to 0.34807, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9657 - rmse: 3.1293 - mean_loss: 196.6989 - acc: 0.3555 - val_loss: 0.8218 - val_rmse: 1.5229 - val_mean_loss: 133.6080 - val_acc: 0.3421\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.82526 to 0.82183, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.34807 to 0.35548, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9632 - rmse: 3.1090 - mean_loss: 199.9850 - acc: 0.3542 - val_loss: 0.8341 - val_rmse: 1.5360 - val_mean_loss: 147.9998 - val_acc: 0.3090\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.82183\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.35548\n",
      "Epoch 8/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9635 - rmse: 3.0895 - mean_loss: 197.8716 - acc: 0.3583 - val_loss: 0.8384 - val_rmse: 1.5353 - val_mean_loss: 118.9976 - val_acc: 0.3388\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.82183\n",
      "\n",
      "Epoch 00008: acc improved from 0.35548 to 0.35830, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9554 - rmse: 3.0329 - mean_loss: 214.9687 - acc: 0.3616 - val_loss: 0.8541 - val_rmse: 1.5686 - val_mean_loss: 127.8842 - val_acc: 0.3281\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.82183\n",
      "\n",
      "Epoch 00009: acc improved from 0.35830 to 0.36160, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9477 - rmse: 3.0214 - mean_loss: 213.6032 - acc: 0.3765 - val_loss: 0.8072 - val_rmse: 1.5388 - val_mean_loss: 253.3476 - val_acc: 0.2162\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.82183 to 0.80720, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00010: acc improved from 0.36160 to 0.37648, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9437 - rmse: 3.0076 - mean_loss: 221.2477 - acc: 0.3695 - val_loss: 0.8849 - val_rmse: 1.6038 - val_mean_loss: 131.5677 - val_acc: 0.2576\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.37648\n",
      "Epoch 12/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9311 - rmse: 2.9531 - mean_loss: 225.9905 - acc: 0.3885 - val_loss: 0.8636 - val_rmse: 1.6358 - val_mean_loss: 153.9432 - val_acc: 0.2876\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00012: acc improved from 0.37648 to 0.38855, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9191 - rmse: 2.8525 - mean_loss: 212.5995 - acc: 0.3975 - val_loss: 0.8553 - val_rmse: 1.6393 - val_mean_loss: 236.8113 - val_acc: 0.3450\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00013: acc improved from 0.38855 to 0.39749, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.9068 - rmse: 2.7136 - mean_loss: 179.7224 - acc: 0.4066 - val_loss: 0.8904 - val_rmse: 1.6978 - val_mean_loss: 156.5960 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00014: acc improved from 0.39749 to 0.40661, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.8706 - rmse: 2.5028 - mean_loss: 174.7427 - acc: 0.4163 - val_loss: 0.8564 - val_rmse: 1.5926 - val_mean_loss: 123.0278 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00015: acc improved from 0.40661 to 0.41629, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 16/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.8285 - rmse: 2.3831 - mean_loss: 177.5104 - acc: 0.4297 - val_loss: 0.8230 - val_rmse: 1.5604 - val_mean_loss: 169.4227 - val_acc: 0.3334\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00016: acc improved from 0.41629 to 0.42970, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.7951 - rmse: 2.2636 - mean_loss: 186.1251 - acc: 0.4425 - val_loss: 0.9546 - val_rmse: 1.7890 - val_mean_loss: 172.8071 - val_acc: 0.3694\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00017: acc improved from 0.42970 to 0.44250, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.7866 - rmse: 2.2001 - mean_loss: 161.9935 - acc: 0.4504 - val_loss: 0.8148 - val_rmse: 1.5761 - val_mean_loss: 228.1853 - val_acc: 0.3429\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00018: acc improved from 0.44250 to 0.45040, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.7586 - rmse: 2.1125 - mean_loss: 165.0810 - acc: 0.4604 - val_loss: 0.8441 - val_rmse: 1.6450 - val_mean_loss: 204.2865 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00019: acc improved from 0.45040 to 0.46038, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.7373 - rmse: 2.0297 - mean_loss: 149.1246 - acc: 0.4776 - val_loss: 0.9015 - val_rmse: 1.6624 - val_mean_loss: 146.4281 - val_acc: 0.3302\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00020: acc improved from 0.46038 to 0.47765, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 21/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.7142 - rmse: 1.9498 - mean_loss: 143.1228 - acc: 0.4802 - val_loss: 0.8822 - val_rmse: 1.7463 - val_mean_loss: 185.7753 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00021: acc improved from 0.47765 to 0.48022, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 22/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.7011 - rmse: 1.9007 - mean_loss: 144.1237 - acc: 0.4855 - val_loss: 0.8871 - val_rmse: 1.6355 - val_mean_loss: 108.0214 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00022: acc improved from 0.48022 to 0.48549, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.6788 - rmse: 1.8106 - mean_loss: 140.7384 - acc: 0.5053 - val_loss: 0.9173 - val_rmse: 1.8568 - val_mean_loss: 246.3342 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00023: acc improved from 0.48549 to 0.50527, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 24/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.6645 - rmse: 1.7503 - mean_loss: 135.1086 - acc: 0.5067 - val_loss: 0.8813 - val_rmse: 1.7161 - val_mean_loss: 169.6495 - val_acc: 0.3536\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00024: acc improved from 0.50527 to 0.50667, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 25/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.6417 - rmse: 1.6910 - mean_loss: 134.5512 - acc: 0.5200 - val_loss: 0.8937 - val_rmse: 1.7194 - val_mean_loss: 150.9292 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00025: acc improved from 0.50667 to 0.51996, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 26/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.6308 - rmse: 1.6357 - mean_loss: 125.8798 - acc: 0.5284 - val_loss: 0.8506 - val_rmse: 1.6255 - val_mean_loss: 139.0648 - val_acc: 0.3513\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00026: acc improved from 0.51996 to 0.52835, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 27/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.6098 - rmse: 1.5722 - mean_loss: 124.9722 - acc: 0.5326 - val_loss: 0.9190 - val_rmse: 1.7058 - val_mean_loss: 120.7828 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00027: acc improved from 0.52835 to 0.53264, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 28/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.6020 - rmse: 1.5209 - mean_loss: 124.1806 - acc: 0.5415 - val_loss: 0.9069 - val_rmse: 1.6497 - val_mean_loss: 122.4844 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00028: acc improved from 0.53264 to 0.54146, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 29/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5861 - rmse: 1.4910 - mean_loss: 119.0181 - acc: 0.5536 - val_loss: 0.9194 - val_rmse: 1.6830 - val_mean_loss: 97.9265 - val_acc: 0.3690\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00029: acc improved from 0.54146 to 0.55358, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 30/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5683 - rmse: 1.4266 - mean_loss: 119.6514 - acc: 0.5506 - val_loss: 0.8888 - val_rmse: 1.7251 - val_mean_loss: 167.0838 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00030: acc did not improve from 0.55358\n",
      "Epoch 31/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5518 - rmse: 1.3761 - mean_loss: 112.8780 - acc: 0.5688 - val_loss: 0.9599 - val_rmse: 1.7757 - val_mean_loss: 122.4354 - val_acc: 0.3735\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00031: acc improved from 0.55358 to 0.56877, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 32/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5487 - rmse: 1.3545 - mean_loss: 106.4974 - acc: 0.5667 - val_loss: 0.8912 - val_rmse: 1.7446 - val_mean_loss: 186.5306 - val_acc: 0.3362\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.56877\n",
      "Epoch 33/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5435 - rmse: 1.3391 - mean_loss: 112.0554 - acc: 0.5676 - val_loss: 0.8805 - val_rmse: 1.7482 - val_mean_loss: 198.5438 - val_acc: 0.3620\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00033: acc did not improve from 0.56877\n",
      "Epoch 34/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5224 - rmse: 1.2785 - mean_loss: 105.6282 - acc: 0.5789 - val_loss: 0.9174 - val_rmse: 1.6992 - val_mean_loss: 137.2753 - val_acc: 0.3169\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00034: acc improved from 0.56877 to 0.57893, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 35/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5089 - rmse: 1.2291 - mean_loss: 104.1094 - acc: 0.5879 - val_loss: 0.8749 - val_rmse: 1.7148 - val_mean_loss: 154.2490 - val_acc: 0.3211\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00035: acc improved from 0.57893 to 0.58788, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 36/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.5041 - rmse: 1.2301 - mean_loss: 107.6947 - acc: 0.5920 - val_loss: 0.8738 - val_rmse: 1.6511 - val_mean_loss: 147.9146 - val_acc: 0.3478\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00036: acc improved from 0.58788 to 0.59204, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 37/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4929 - rmse: 1.1841 - mean_loss: 103.9774 - acc: 0.5965 - val_loss: 0.8651 - val_rmse: 1.6985 - val_mean_loss: 235.0959 - val_acc: 0.3452\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00037: acc improved from 0.59204 to 0.59651, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 38/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4962 - rmse: 1.1793 - mean_loss: 94.7280 - acc: 0.5979 - val_loss: 0.8514 - val_rmse: 1.6635 - val_mean_loss: 194.5410 - val_acc: 0.3796\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00038: acc improved from 0.59651 to 0.59786, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4807 - rmse: 1.1401 - mean_loss: 95.5066 - acc: 0.6032 - val_loss: 0.8858 - val_rmse: 1.6793 - val_mean_loss: 128.6345 - val_acc: 0.3515\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00039: acc improved from 0.59786 to 0.60318, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 40/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4715 - rmse: 1.1279 - mean_loss: 97.2412 - acc: 0.6109 - val_loss: 0.9162 - val_rmse: 1.8048 - val_mean_loss: 183.4147 - val_acc: 0.3532\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00040: acc improved from 0.60318 to 0.61090, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 41/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4568 - rmse: 1.0783 - mean_loss: 96.0100 - acc: 0.6199 - val_loss: 0.9168 - val_rmse: 1.7932 - val_mean_loss: 172.1058 - val_acc: 0.3431\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00041: acc improved from 0.61090 to 0.61990, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 42/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4545 - rmse: 1.0650 - mean_loss: 89.3825 - acc: 0.6180 - val_loss: 0.8864 - val_rmse: 1.7005 - val_mean_loss: 168.4220 - val_acc: 0.3539\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00042: acc did not improve from 0.61990\n",
      "Epoch 43/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4542 - rmse: 1.0603 - mean_loss: 90.2693 - acc: 0.6243 - val_loss: 0.9119 - val_rmse: 1.7811 - val_mean_loss: 174.5295 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00043: acc improved from 0.61990 to 0.62431, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 44/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4327 - rmse: 1.0103 - mean_loss: 88.7063 - acc: 0.6382 - val_loss: 0.8580 - val_rmse: 1.6347 - val_mean_loss: 139.5285 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00044: acc improved from 0.62431 to 0.63815, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 45/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4276 - rmse: 0.9947 - mean_loss: 86.8635 - acc: 0.6369 - val_loss: 0.8827 - val_rmse: 1.6951 - val_mean_loss: 160.9502 - val_acc: 0.3262\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00045: acc did not improve from 0.63815\n",
      "Epoch 46/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4239 - rmse: 0.9796 - mean_loss: 87.5380 - acc: 0.6400 - val_loss: 0.8524 - val_rmse: 1.6652 - val_mean_loss: 192.3735 - val_acc: 0.3423\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00046: acc improved from 0.63815 to 0.64005, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 47/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4192 - rmse: 0.9712 - mean_loss: 87.9291 - acc: 0.6414 - val_loss: 0.8634 - val_rmse: 1.6782 - val_mean_loss: 160.7320 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00047: acc improved from 0.64005 to 0.64140, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 48/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4184 - rmse: 0.9556 - mean_loss: 83.3088 - acc: 0.6457 - val_loss: 0.8924 - val_rmse: 1.7412 - val_mean_loss: 158.8142 - val_acc: 0.3194\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00048: acc improved from 0.64140 to 0.64574, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 49/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.4112 - rmse: 0.9333 - mean_loss: 79.3175 - acc: 0.6547 - val_loss: 0.9068 - val_rmse: 1.7640 - val_mean_loss: 154.9782 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00049: acc improved from 0.64574 to 0.65468, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 50/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3988 - rmse: 0.9045 - mean_loss: 83.8724 - acc: 0.6543 - val_loss: 0.8880 - val_rmse: 1.6844 - val_mean_loss: 133.7859 - val_acc: 0.3755\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.65468\n",
      "Epoch 51/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3981 - rmse: 0.9109 - mean_loss: 84.2790 - acc: 0.6581 - val_loss: 0.8832 - val_rmse: 1.7230 - val_mean_loss: 162.0954 - val_acc: 0.3634\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00051: acc improved from 0.65468 to 0.65811, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 52/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3925 - rmse: 0.8898 - mean_loss: 81.7279 - acc: 0.6604 - val_loss: 0.8923 - val_rmse: 1.6525 - val_mean_loss: 136.1835 - val_acc: 0.3310\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00052: acc improved from 0.65811 to 0.66044, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 53/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3891 - rmse: 0.8876 - mean_loss: 80.2037 - acc: 0.6663 - val_loss: 0.8856 - val_rmse: 1.7019 - val_mean_loss: 156.3122 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00053: acc improved from 0.66044 to 0.66632, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 54/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3816 - rmse: 0.8535 - mean_loss: 79.2022 - acc: 0.6666 - val_loss: 0.8612 - val_rmse: 1.6979 - val_mean_loss: 201.7946 - val_acc: 0.3401\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00054: acc improved from 0.66632 to 0.66663, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 55/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3833 - rmse: 0.8609 - mean_loss: 78.9570 - acc: 0.6693 - val_loss: 0.8696 - val_rmse: 1.6636 - val_mean_loss: 139.2274 - val_acc: 0.3545\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00055: acc improved from 0.66663 to 0.66926, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 56/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3754 - rmse: 0.8371 - mean_loss: 80.1854 - acc: 0.6740 - val_loss: 0.8868 - val_rmse: 1.7046 - val_mean_loss: 148.4244 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00056: acc improved from 0.66926 to 0.67404, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 57/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3807 - rmse: 0.8458 - mean_loss: 76.0777 - acc: 0.6764 - val_loss: 0.8835 - val_rmse: 1.7119 - val_mean_loss: 159.4035 - val_acc: 0.2901\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00057: acc improved from 0.67404 to 0.67642, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 58/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3690 - rmse: 0.8167 - mean_loss: 75.0262 - acc: 0.6810 - val_loss: 0.8837 - val_rmse: 1.7271 - val_mean_loss: 147.8397 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00058: acc improved from 0.67642 to 0.68096, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3715 - rmse: 0.8281 - mean_loss: 75.8941 - acc: 0.6731 - val_loss: 0.9432 - val_rmse: 1.8281 - val_mean_loss: 163.8126 - val_acc: 0.3391\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00059: acc did not improve from 0.68096\n",
      "Epoch 60/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3552 - rmse: 0.7908 - mean_loss: 76.5075 - acc: 0.6805 - val_loss: 0.8616 - val_rmse: 1.6595 - val_mean_loss: 169.8625 - val_acc: 0.3440\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00060: acc did not improve from 0.68096\n",
      "Epoch 61/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3612 - rmse: 0.8019 - mean_loss: 74.4389 - acc: 0.6873 - val_loss: 0.8686 - val_rmse: 1.6920 - val_mean_loss: 195.3062 - val_acc: 0.3446\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00061: acc improved from 0.68096 to 0.68726, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 62/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3589 - rmse: 0.7874 - mean_loss: 74.3762 - acc: 0.6832 - val_loss: 0.8921 - val_rmse: 1.6416 - val_mean_loss: 107.2649 - val_acc: 0.3232\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00062: acc did not improve from 0.68726\n",
      "Epoch 63/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3686 - rmse: 0.8062 - mean_loss: 70.5294 - acc: 0.6778 - val_loss: 0.8758 - val_rmse: 1.7299 - val_mean_loss: 196.1405 - val_acc: 0.3724\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00063: acc did not improve from 0.68726\n",
      "Epoch 64/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3513 - rmse: 0.7759 - mean_loss: 72.8128 - acc: 0.6842 - val_loss: 0.8779 - val_rmse: 1.6955 - val_mean_loss: 142.3233 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00064: acc did not improve from 0.68726\n",
      "Epoch 65/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3478 - rmse: 0.7596 - mean_loss: 72.6080 - acc: 0.6911 - val_loss: 0.8695 - val_rmse: 1.7040 - val_mean_loss: 210.1360 - val_acc: 0.3423\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00065: acc improved from 0.68726 to 0.69112, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 66/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3437 - rmse: 0.7588 - mean_loss: 75.0213 - acc: 0.6942 - val_loss: 0.8455 - val_rmse: 1.6452 - val_mean_loss: 210.7589 - val_acc: 0.3485\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00066: acc improved from 0.69112 to 0.69418, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 67/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3395 - rmse: 0.7406 - mean_loss: 68.9544 - acc: 0.6936 - val_loss: 0.8756 - val_rmse: 1.6093 - val_mean_loss: 98.9486 - val_acc: 0.3491\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00067: acc did not improve from 0.69418\n",
      "Epoch 68/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3428 - rmse: 0.7511 - mean_loss: 69.9180 - acc: 0.6900 - val_loss: 0.8403 - val_rmse: 1.6235 - val_mean_loss: 182.2059 - val_acc: 0.3413\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00068: acc did not improve from 0.69418\n",
      "Epoch 69/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3513 - rmse: 0.7540 - mean_loss: 66.6216 - acc: 0.6915 - val_loss: 0.8825 - val_rmse: 1.7078 - val_mean_loss: 185.0096 - val_acc: 0.3729\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00069: acc did not improve from 0.69418\n",
      "Epoch 70/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3356 - rmse: 0.7307 - mean_loss: 69.2452 - acc: 0.6987 - val_loss: 0.8749 - val_rmse: 1.7077 - val_mean_loss: 176.5744 - val_acc: 0.3446\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00070: acc improved from 0.69418 to 0.69871, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 71/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3373 - rmse: 0.7313 - mean_loss: 68.2885 - acc: 0.6941 - val_loss: 0.8609 - val_rmse: 1.6555 - val_mean_loss: 180.5334 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00071: acc did not improve from 0.69871\n",
      "Epoch 72/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3267 - rmse: 0.7068 - mean_loss: 70.9475 - acc: 0.7038 - val_loss: 0.9082 - val_rmse: 1.7444 - val_mean_loss: 168.9462 - val_acc: 0.3309\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00072: acc improved from 0.69871 to 0.70380, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 73/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3301 - rmse: 0.7064 - mean_loss: 68.5640 - acc: 0.7003 - val_loss: 0.8857 - val_rmse: 1.5988 - val_mean_loss: 126.5900 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00073: acc did not improve from 0.70380\n",
      "Epoch 74/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3391 - rmse: 0.7374 - mean_loss: 70.2489 - acc: 0.6923 - val_loss: 0.8652 - val_rmse: 1.6733 - val_mean_loss: 156.7669 - val_acc: 0.3477\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00074: acc did not improve from 0.70380\n",
      "Epoch 75/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3308 - rmse: 0.7264 - mean_loss: 70.3008 - acc: 0.7020 - val_loss: 0.8576 - val_rmse: 1.6811 - val_mean_loss: 206.1060 - val_acc: 0.3490\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00075: acc did not improve from 0.70380\n",
      "Epoch 76/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3195 - rmse: 0.6997 - mean_loss: 69.6417 - acc: 0.7097 - val_loss: 0.8406 - val_rmse: 1.6331 - val_mean_loss: 190.5042 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00076: acc improved from 0.70380 to 0.70968, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 77/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3157 - rmse: 0.6750 - mean_loss: 66.0301 - acc: 0.7087 - val_loss: 0.8484 - val_rmse: 1.6590 - val_mean_loss: 227.0270 - val_acc: 0.3045\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00077: acc did not improve from 0.70968\n",
      "Epoch 78/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3252 - rmse: 0.7052 - mean_loss: 68.6592 - acc: 0.7043 - val_loss: 0.8428 - val_rmse: 1.6230 - val_mean_loss: 182.0495 - val_acc: 0.3499\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00078: acc did not improve from 0.70968\n",
      "Epoch 79/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3155 - rmse: 0.6784 - mean_loss: 68.0869 - acc: 0.7111 - val_loss: 0.9049 - val_rmse: 1.7088 - val_mean_loss: 148.8193 - val_acc: 0.3494\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00079: acc improved from 0.70968 to 0.71115, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 80/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3135 - rmse: 0.6697 - mean_loss: 68.0638 - acc: 0.7130 - val_loss: 0.8692 - val_rmse: 1.6416 - val_mean_loss: 149.5912 - val_acc: 0.3506\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00080: acc improved from 0.71115 to 0.71304, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 81/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3198 - rmse: 0.6901 - mean_loss: 66.7386 - acc: 0.7111 - val_loss: 0.8636 - val_rmse: 1.6927 - val_mean_loss: 212.7953 - val_acc: 0.3529\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00081: acc did not improve from 0.71304\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3188 - rmse: 0.6895 - mean_loss: 66.7912 - acc: 0.7114 - val_loss: 0.8849 - val_rmse: 1.7040 - val_mean_loss: 156.9220 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00082: acc did not improve from 0.71304\n",
      "Epoch 83/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3106 - rmse: 0.6702 - mean_loss: 67.2017 - acc: 0.7151 - val_loss: 0.8760 - val_rmse: 1.6915 - val_mean_loss: 156.2214 - val_acc: 0.3464\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00083: acc improved from 0.71304 to 0.71513, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 84/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3113 - rmse: 0.6704 - mean_loss: 63.2259 - acc: 0.7183 - val_loss: 0.8663 - val_rmse: 1.6560 - val_mean_loss: 146.4432 - val_acc: 0.3155\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00084: acc improved from 0.71513 to 0.71831, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 85/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3144 - rmse: 0.6821 - mean_loss: 68.3510 - acc: 0.7099 - val_loss: 0.8523 - val_rmse: 1.6712 - val_mean_loss: 212.0574 - val_acc: 0.3673\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00085: acc did not improve from 0.71831\n",
      "Epoch 86/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3113 - rmse: 0.6612 - mean_loss: 64.0549 - acc: 0.7171 - val_loss: 0.8696 - val_rmse: 1.6660 - val_mean_loss: 171.6477 - val_acc: 0.3478\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00086: acc did not improve from 0.71831\n",
      "Epoch 87/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3069 - rmse: 0.6588 - mean_loss: 67.2145 - acc: 0.7176 - val_loss: 0.9052 - val_rmse: 1.7595 - val_mean_loss: 157.9382 - val_acc: 0.3633\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00087: acc did not improve from 0.71831\n",
      "Epoch 88/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3008 - rmse: 0.6379 - mean_loss: 64.4355 - acc: 0.7200 - val_loss: 0.8404 - val_rmse: 1.6478 - val_mean_loss: 226.5524 - val_acc: 0.3338\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00088: acc improved from 0.71831 to 0.71996, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 89/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3160 - rmse: 0.6619 - mean_loss: 61.8937 - acc: 0.7170 - val_loss: 0.8920 - val_rmse: 1.7113 - val_mean_loss: 149.4821 - val_acc: 0.3262\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00089: acc did not improve from 0.71996\n",
      "Epoch 90/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3058 - rmse: 0.6527 - mean_loss: 65.1553 - acc: 0.7167 - val_loss: 0.8485 - val_rmse: 1.6503 - val_mean_loss: 164.1586 - val_acc: 0.3812\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00090: acc did not improve from 0.71996\n",
      "Epoch 91/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3040 - rmse: 0.6550 - mean_loss: 67.1200 - acc: 0.7229 - val_loss: 0.8633 - val_rmse: 1.6754 - val_mean_loss: 188.3952 - val_acc: 0.3477\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00091: acc improved from 0.71996 to 0.72290, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 92/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3034 - rmse: 0.6454 - mean_loss: 61.5317 - acc: 0.7237 - val_loss: 0.8561 - val_rmse: 1.6748 - val_mean_loss: 188.7181 - val_acc: 0.3778\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00092: acc improved from 0.72290 to 0.72370, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 93/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3025 - rmse: 0.6423 - mean_loss: 64.0874 - acc: 0.7206 - val_loss: 0.8548 - val_rmse: 1.6652 - val_mean_loss: 199.8965 - val_acc: 0.3252\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00093: acc did not improve from 0.72370\n",
      "Epoch 94/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3070 - rmse: 0.6562 - mean_loss: 62.9242 - acc: 0.7187 - val_loss: 0.8661 - val_rmse: 1.6433 - val_mean_loss: 152.8005 - val_acc: 0.3669\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00094: acc did not improve from 0.72370\n",
      "Epoch 95/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3013 - rmse: 0.6366 - mean_loss: 62.1529 - acc: 0.7203 - val_loss: 0.8502 - val_rmse: 1.6674 - val_mean_loss: 206.5378 - val_acc: 0.3464\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00095: acc did not improve from 0.72370\n",
      "Epoch 96/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3021 - rmse: 0.6326 - mean_loss: 60.6345 - acc: 0.7223 - val_loss: 0.8829 - val_rmse: 1.6991 - val_mean_loss: 169.3068 - val_acc: 0.3669\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00096: acc did not improve from 0.72370\n",
      "Epoch 97/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2987 - rmse: 0.6252 - mean_loss: 60.0328 - acc: 0.7242 - val_loss: 0.8606 - val_rmse: 1.6597 - val_mean_loss: 182.5398 - val_acc: 0.3676\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00097: acc improved from 0.72370 to 0.72425, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 98/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2889 - rmse: 0.6045 - mean_loss: 62.7642 - acc: 0.7249 - val_loss: 0.8675 - val_rmse: 1.6677 - val_mean_loss: 139.7383 - val_acc: 0.3643\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00098: acc improved from 0.72425 to 0.72492, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 99/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2912 - rmse: 0.6187 - mean_loss: 63.6110 - acc: 0.7221 - val_loss: 0.8486 - val_rmse: 1.6561 - val_mean_loss: 198.2999 - val_acc: 0.3538\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00099: acc did not improve from 0.72492\n",
      "Epoch 100/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2975 - rmse: 0.6345 - mean_loss: 62.7304 - acc: 0.7270 - val_loss: 0.8778 - val_rmse: 1.7074 - val_mean_loss: 181.1958 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00100: acc improved from 0.72492 to 0.72701, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 101/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.3013 - rmse: 0.6373 - mean_loss: 62.4881 - acc: 0.7225 - val_loss: 0.8849 - val_rmse: 1.6844 - val_mean_loss: 123.5805 - val_acc: 0.3483\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00101: acc did not improve from 0.72701\n",
      "Epoch 102/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2909 - rmse: 0.6129 - mean_loss: 63.4241 - acc: 0.7246 - val_loss: 0.8534 - val_rmse: 1.6720 - val_mean_loss: 190.3008 - val_acc: 0.3353\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00102: acc did not improve from 0.72701\n",
      "Epoch 103/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2933 - rmse: 0.6115 - mean_loss: 60.2319 - acc: 0.7284 - val_loss: 0.9016 - val_rmse: 1.6409 - val_mean_loss: 95.7545 - val_acc: 0.3548\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00103: acc improved from 0.72701 to 0.72841, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 104/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2942 - rmse: 0.6159 - mean_loss: 62.2593 - acc: 0.7274 - val_loss: 0.8405 - val_rmse: 1.6135 - val_mean_loss: 163.9859 - val_acc: 0.3625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00104: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00104: acc did not improve from 0.72841\n",
      "Epoch 105/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2894 - rmse: 0.6027 - mean_loss: 60.0384 - acc: 0.7308 - val_loss: 0.8658 - val_rmse: 1.7002 - val_mean_loss: 197.6582 - val_acc: 0.3525\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00105: acc improved from 0.72841 to 0.73080, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 106/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2888 - rmse: 0.6160 - mean_loss: 63.8565 - acc: 0.7305 - val_loss: 0.8644 - val_rmse: 1.6096 - val_mean_loss: 126.3219 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00106: acc did not improve from 0.73080\n",
      "Epoch 107/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2837 - rmse: 0.5924 - mean_loss: 61.0894 - acc: 0.7309 - val_loss: 0.9590 - val_rmse: 1.7234 - val_mean_loss: 95.3598 - val_acc: 0.3567\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00107: acc improved from 0.73080 to 0.73092, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 108/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2926 - rmse: 0.6179 - mean_loss: 62.0775 - acc: 0.7259 - val_loss: 0.8426 - val_rmse: 1.6271 - val_mean_loss: 170.6378 - val_acc: 0.3515\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00108: acc did not improve from 0.73092\n",
      "Epoch 109/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2814 - rmse: 0.5920 - mean_loss: 59.6946 - acc: 0.7399 - val_loss: 0.8430 - val_rmse: 1.6512 - val_mean_loss: 193.9909 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00109: acc improved from 0.73092 to 0.73993, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 110/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2837 - rmse: 0.5878 - mean_loss: 60.5768 - acc: 0.7254 - val_loss: 0.8878 - val_rmse: 1.7163 - val_mean_loss: 156.4446 - val_acc: 0.3526\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00110: acc did not improve from 0.73993\n",
      "Epoch 111/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2892 - rmse: 0.6063 - mean_loss: 60.6276 - acc: 0.7320 - val_loss: 0.8402 - val_rmse: 1.6295 - val_mean_loss: 212.8892 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00111: acc did not improve from 0.73993\n",
      "Epoch 112/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2867 - rmse: 0.6038 - mean_loss: 60.6395 - acc: 0.7336 - val_loss: 0.8312 - val_rmse: 1.6223 - val_mean_loss: 187.8101 - val_acc: 0.3490\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00112: acc did not improve from 0.73993\n",
      "Epoch 113/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2845 - rmse: 0.5967 - mean_loss: 58.7429 - acc: 0.7311 - val_loss: 0.8551 - val_rmse: 1.6619 - val_mean_loss: 213.4791 - val_acc: 0.3679\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00113: acc did not improve from 0.73993\n",
      "Epoch 114/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2870 - rmse: 0.5979 - mean_loss: 59.0096 - acc: 0.7309 - val_loss: 0.8443 - val_rmse: 1.6133 - val_mean_loss: 135.4999 - val_acc: 0.3426\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00114: acc did not improve from 0.73993\n",
      "Epoch 115/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2753 - rmse: 0.5705 - mean_loss: 60.5726 - acc: 0.7383 - val_loss: 0.8460 - val_rmse: 1.6519 - val_mean_loss: 211.9616 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00115: acc did not improve from 0.73993\n",
      "Epoch 116/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2817 - rmse: 0.5963 - mean_loss: 61.1675 - acc: 0.7350 - val_loss: 0.8219 - val_rmse: 1.5969 - val_mean_loss: 227.3343 - val_acc: 0.3429\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00116: acc did not improve from 0.73993\n",
      "Epoch 117/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2843 - rmse: 0.5894 - mean_loss: 57.8801 - acc: 0.7381 - val_loss: 0.8483 - val_rmse: 1.6497 - val_mean_loss: 181.2132 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00117: acc did not improve from 0.73993\n",
      "Epoch 118/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2787 - rmse: 0.5756 - mean_loss: 60.9811 - acc: 0.7358 - val_loss: 0.8588 - val_rmse: 1.6253 - val_mean_loss: 121.9384 - val_acc: 0.3423\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00118: acc did not improve from 0.73993\n",
      "Epoch 119/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2814 - rmse: 0.5853 - mean_loss: 59.3730 - acc: 0.7414 - val_loss: 0.8561 - val_rmse: 1.6865 - val_mean_loss: 238.1564 - val_acc: 0.3364\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00119: acc improved from 0.73993 to 0.74140, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 120/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2796 - rmse: 0.5818 - mean_loss: 57.9689 - acc: 0.7318 - val_loss: 0.8798 - val_rmse: 1.7299 - val_mean_loss: 201.4731 - val_acc: 0.3442\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00120: acc did not improve from 0.74140\n",
      "Epoch 121/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2691 - rmse: 0.5676 - mean_loss: 62.6772 - acc: 0.7382 - val_loss: 0.8373 - val_rmse: 1.6150 - val_mean_loss: 179.0371 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00121: acc did not improve from 0.74140\n",
      "Epoch 122/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2743 - rmse: 0.5729 - mean_loss: 58.8258 - acc: 0.7402 - val_loss: 0.8665 - val_rmse: 1.6593 - val_mean_loss: 130.8342 - val_acc: 0.3491\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00122: acc did not improve from 0.74140\n",
      "Epoch 123/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2837 - rmse: 0.5889 - mean_loss: 57.8773 - acc: 0.7378 - val_loss: 0.8655 - val_rmse: 1.6869 - val_mean_loss: 213.9424 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00123: acc did not improve from 0.74140\n",
      "Epoch 124/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2773 - rmse: 0.5854 - mean_loss: 59.3729 - acc: 0.7410 - val_loss: 0.8436 - val_rmse: 1.6325 - val_mean_loss: 192.5298 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00124: acc did not improve from 0.74140\n",
      "Epoch 125/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2748 - rmse: 0.5725 - mean_loss: 59.3732 - acc: 0.7401 - val_loss: 0.8356 - val_rmse: 1.6393 - val_mean_loss: 221.7507 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00125: acc did not improve from 0.74140\n",
      "Epoch 126/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2784 - rmse: 0.5847 - mean_loss: 60.1626 - acc: 0.7396 - val_loss: 0.8422 - val_rmse: 1.6174 - val_mean_loss: 205.2682 - val_acc: 0.3348\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00126: acc did not improve from 0.74140\n",
      "Epoch 127/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2732 - rmse: 0.5581 - mean_loss: 58.4392 - acc: 0.7411 - val_loss: 0.8554 - val_rmse: 1.6735 - val_mean_loss: 214.0202 - val_acc: 0.3204\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00127: acc did not improve from 0.74140\n",
      "Epoch 128/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2729 - rmse: 0.5722 - mean_loss: 61.4255 - acc: 0.7377 - val_loss: 0.8220 - val_rmse: 1.6093 - val_mean_loss: 268.6877 - val_acc: 0.3453\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00128: acc did not improve from 0.74140\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2759 - rmse: 0.5709 - mean_loss: 57.6903 - acc: 0.7353 - val_loss: 0.8473 - val_rmse: 1.6381 - val_mean_loss: 192.9648 - val_acc: 0.3472\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00129: acc did not improve from 0.74140\n",
      "Epoch 130/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2835 - rmse: 0.5802 - mean_loss: 57.5284 - acc: 0.7342 - val_loss: 0.8518 - val_rmse: 1.6132 - val_mean_loss: 108.0586 - val_acc: 0.3198\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00130: acc did not improve from 0.74140\n",
      "Epoch 131/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2672 - rmse: 0.5638 - mean_loss: 60.3114 - acc: 0.7356 - val_loss: 0.8801 - val_rmse: 1.6950 - val_mean_loss: 159.6144 - val_acc: 0.3402\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00131: acc did not improve from 0.74140\n",
      "Epoch 132/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2674 - rmse: 0.5438 - mean_loss: 55.9615 - acc: 0.7448 - val_loss: 0.8440 - val_rmse: 1.6281 - val_mean_loss: 168.3352 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00132: acc improved from 0.74140 to 0.74483, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 133/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2726 - rmse: 0.5580 - mean_loss: 57.4851 - acc: 0.7415 - val_loss: 0.8522 - val_rmse: 1.6675 - val_mean_loss: 222.4787 - val_acc: 0.3701\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00133: acc did not improve from 0.74483\n",
      "Epoch 134/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2696 - rmse: 0.5547 - mean_loss: 57.1638 - acc: 0.7420 - val_loss: 0.8556 - val_rmse: 1.6476 - val_mean_loss: 172.5565 - val_acc: 0.3507\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00134: acc did not improve from 0.74483\n",
      "Epoch 135/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2749 - rmse: 0.5682 - mean_loss: 57.1627 - acc: 0.7403 - val_loss: 0.8714 - val_rmse: 1.6924 - val_mean_loss: 163.8045 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00135: acc did not improve from 0.74483\n",
      "Epoch 136/200\n",
      "16330/16330 [==============================] - 51s 3ms/step - loss: 0.2622 - rmse: 0.5431 - mean_loss: 58.0896 - acc: 0.7478 - val_loss: 0.8467 - val_rmse: 1.6296 - val_mean_loss: 158.7491 - val_acc: 0.3184\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00136: acc improved from 0.74483 to 0.74776, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 137/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2638 - rmse: 0.5542 - mean_loss: 58.4957 - acc: 0.7492 - val_loss: 0.8391 - val_rmse: 1.6406 - val_mean_loss: 203.9543 - val_acc: 0.3491\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00137: acc improved from 0.74776 to 0.74917, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 138/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2743 - rmse: 0.5618 - mean_loss: 55.5215 - acc: 0.7442 - val_loss: 0.8262 - val_rmse: 1.5951 - val_mean_loss: 192.9838 - val_acc: 0.3509\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00138: acc did not improve from 0.74917\n",
      "Epoch 139/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2781 - rmse: 0.5652 - mean_loss: 55.7248 - acc: 0.7391 - val_loss: 0.8784 - val_rmse: 1.6282 - val_mean_loss: 96.2646 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00139: acc did not improve from 0.74917\n",
      "Epoch 140/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2724 - rmse: 0.5568 - mean_loss: 57.4190 - acc: 0.7473 - val_loss: 0.8762 - val_rmse: 1.6549 - val_mean_loss: 123.5101 - val_acc: 0.3509\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00140: acc did not improve from 0.74917\n",
      "Epoch 141/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2671 - rmse: 0.5514 - mean_loss: 58.3378 - acc: 0.7456 - val_loss: 0.8440 - val_rmse: 1.6437 - val_mean_loss: 193.6634 - val_acc: 0.3347\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00141: acc did not improve from 0.74917\n",
      "Epoch 142/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2714 - rmse: 0.5613 - mean_loss: 56.4607 - acc: 0.7403 - val_loss: 0.8810 - val_rmse: 1.6683 - val_mean_loss: 120.1838 - val_acc: 0.3500\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00142: acc did not improve from 0.74917\n",
      "Epoch 143/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2665 - rmse: 0.5408 - mean_loss: 57.9794 - acc: 0.7462 - val_loss: 0.8481 - val_rmse: 1.6557 - val_mean_loss: 205.5882 - val_acc: 0.3401\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00143: acc did not improve from 0.74917\n",
      "Epoch 144/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2731 - rmse: 0.5655 - mean_loss: 58.7462 - acc: 0.7386 - val_loss: 0.8554 - val_rmse: 1.6575 - val_mean_loss: 155.9296 - val_acc: 0.3405\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00144: acc did not improve from 0.74917\n",
      "Epoch 145/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2686 - rmse: 0.5482 - mean_loss: 55.3593 - acc: 0.7473 - val_loss: 0.8720 - val_rmse: 1.6290 - val_mean_loss: 111.9227 - val_acc: 0.3773\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00145: acc did not improve from 0.74917\n",
      "Epoch 146/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2617 - rmse: 0.5382 - mean_loss: 55.6001 - acc: 0.7461 - val_loss: 0.8230 - val_rmse: 1.6040 - val_mean_loss: 214.4083 - val_acc: 0.3290\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00146: acc did not improve from 0.74917\n",
      "Epoch 147/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2691 - rmse: 0.5490 - mean_loss: 55.2518 - acc: 0.7442 - val_loss: 0.8401 - val_rmse: 1.6391 - val_mean_loss: 204.3047 - val_acc: 0.3468\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00147: acc did not improve from 0.74917\n",
      "Epoch 148/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2683 - rmse: 0.5562 - mean_loss: 58.6666 - acc: 0.7441 - val_loss: 0.8611 - val_rmse: 1.6642 - val_mean_loss: 203.8896 - val_acc: 0.3305\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00148: acc did not improve from 0.74917\n",
      "Epoch 149/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2615 - rmse: 0.5404 - mean_loss: 56.1575 - acc: 0.7483 - val_loss: 0.8954 - val_rmse: 1.7172 - val_mean_loss: 146.9902 - val_acc: 0.3411\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00149: acc did not improve from 0.74917\n",
      "Epoch 150/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2620 - rmse: 0.5376 - mean_loss: 56.6291 - acc: 0.7445 - val_loss: 0.8748 - val_rmse: 1.6223 - val_mean_loss: 105.4690 - val_acc: 0.3493\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00150: acc did not improve from 0.74917\n",
      "Epoch 151/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2658 - rmse: 0.5521 - mean_loss: 57.5537 - acc: 0.7453 - val_loss: 0.8832 - val_rmse: 1.7316 - val_mean_loss: 186.5624 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00151: acc did not improve from 0.74917\n",
      "Epoch 152/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2597 - rmse: 0.5409 - mean_loss: 56.7976 - acc: 0.7469 - val_loss: 0.8240 - val_rmse: 1.6004 - val_mean_loss: 191.8961 - val_acc: 0.3417\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00152: acc did not improve from 0.74917\n",
      "Epoch 153/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2722 - rmse: 0.5546 - mean_loss: 56.9198 - acc: 0.7416 - val_loss: 0.9045 - val_rmse: 1.6911 - val_mean_loss: 115.3409 - val_acc: 0.3421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00153: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00153: acc did not improve from 0.74917\n",
      "Epoch 154/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2588 - rmse: 0.5365 - mean_loss: 59.2615 - acc: 0.7475 - val_loss: 0.8606 - val_rmse: 1.6793 - val_mean_loss: 187.0230 - val_acc: 0.3372\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00154: acc did not improve from 0.74917\n",
      "Epoch 155/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2678 - rmse: 0.5530 - mean_loss: 55.9695 - acc: 0.7487 - val_loss: 0.8433 - val_rmse: 1.6522 - val_mean_loss: 214.6897 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00155: acc did not improve from 0.74917\n",
      "Epoch 156/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2682 - rmse: 0.5490 - mean_loss: 55.7880 - acc: 0.7464 - val_loss: 0.8475 - val_rmse: 1.6174 - val_mean_loss: 144.7049 - val_acc: 0.3738\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00156: acc did not improve from 0.74917\n",
      "Epoch 157/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2658 - rmse: 0.5506 - mean_loss: 56.8785 - acc: 0.7428 - val_loss: 0.8505 - val_rmse: 1.6570 - val_mean_loss: 222.1749 - val_acc: 0.3405\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00157: acc did not improve from 0.74917\n",
      "Epoch 158/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2685 - rmse: 0.5445 - mean_loss: 54.0676 - acc: 0.7402 - val_loss: 0.8450 - val_rmse: 1.6763 - val_mean_loss: 206.4574 - val_acc: 0.3738\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00158: acc did not improve from 0.74917\n",
      "Epoch 159/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2537 - rmse: 0.5234 - mean_loss: 57.6113 - acc: 0.7498 - val_loss: 0.8603 - val_rmse: 1.6609 - val_mean_loss: 167.9030 - val_acc: 0.3529\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00159: acc improved from 0.74917 to 0.74979, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 160/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2572 - rmse: 0.5276 - mean_loss: 55.2640 - acc: 0.7527 - val_loss: 0.8637 - val_rmse: 1.6753 - val_mean_loss: 160.4165 - val_acc: 0.3448\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00160: acc improved from 0.74979 to 0.75266, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 161/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2507 - rmse: 0.5114 - mean_loss: 55.4890 - acc: 0.7569 - val_loss: 0.8257 - val_rmse: 1.5880 - val_mean_loss: 185.9413 - val_acc: 0.3484\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00161: acc improved from 0.75266 to 0.75689, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 162/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2599 - rmse: 0.5336 - mean_loss: 55.2781 - acc: 0.7472 - val_loss: 0.8273 - val_rmse: 1.6084 - val_mean_loss: 223.0595 - val_acc: 0.3544\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00162: acc did not improve from 0.75689\n",
      "Epoch 163/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2568 - rmse: 0.5299 - mean_loss: 56.8001 - acc: 0.7555 - val_loss: 0.8473 - val_rmse: 1.6621 - val_mean_loss: 233.1520 - val_acc: 0.3676\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00163: acc did not improve from 0.75689\n",
      "Epoch 164/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2599 - rmse: 0.5303 - mean_loss: 53.8106 - acc: 0.7544 - val_loss: 0.8338 - val_rmse: 1.6187 - val_mean_loss: 181.9704 - val_acc: 0.3389\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00164: acc did not improve from 0.75689\n",
      "Epoch 165/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2604 - rmse: 0.5400 - mean_loss: 56.9656 - acc: 0.7521 - val_loss: 0.8462 - val_rmse: 1.6323 - val_mean_loss: 158.9157 - val_acc: 0.3395\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00165: acc did not improve from 0.75689\n",
      "Epoch 166/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2622 - rmse: 0.5277 - mean_loss: 53.6422 - acc: 0.7546 - val_loss: 0.8542 - val_rmse: 1.6769 - val_mean_loss: 208.9585 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00166: acc did not improve from 0.75689\n",
      "Epoch 167/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2554 - rmse: 0.5179 - mean_loss: 54.9637 - acc: 0.7549 - val_loss: 0.8630 - val_rmse: 1.6705 - val_mean_loss: 177.6206 - val_acc: 0.3506\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00167: acc did not improve from 0.75689\n",
      "Epoch 168/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2575 - rmse: 0.5313 - mean_loss: 57.2089 - acc: 0.7541 - val_loss: 0.8409 - val_rmse: 1.6316 - val_mean_loss: 190.8669 - val_acc: 0.3168\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00168: acc did not improve from 0.75689\n",
      "Epoch 169/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2548 - rmse: 0.5194 - mean_loss: 54.3321 - acc: 0.7514 - val_loss: 0.8498 - val_rmse: 1.6810 - val_mean_loss: 232.7526 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00169: acc did not improve from 0.75689\n",
      "Epoch 170/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2589 - rmse: 0.5279 - mean_loss: 54.0147 - acc: 0.7527 - val_loss: 0.8380 - val_rmse: 1.6332 - val_mean_loss: 236.3244 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00170: acc did not improve from 0.75689\n",
      "Epoch 171/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2561 - rmse: 0.5208 - mean_loss: 55.0006 - acc: 0.7528 - val_loss: 0.8206 - val_rmse: 1.5842 - val_mean_loss: 185.0854 - val_acc: 0.3523\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00171: acc did not improve from 0.75689\n",
      "Epoch 172/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2615 - rmse: 0.5268 - mean_loss: 53.6855 - acc: 0.7462 - val_loss: 0.8942 - val_rmse: 1.6873 - val_mean_loss: 123.9664 - val_acc: 0.3283\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00172: acc did not improve from 0.75689\n",
      "Epoch 173/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2562 - rmse: 0.5316 - mean_loss: 57.1383 - acc: 0.7465 - val_loss: 0.8385 - val_rmse: 1.6416 - val_mean_loss: 200.8289 - val_acc: 0.3643\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00173: acc did not improve from 0.75689\n",
      "Epoch 174/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2567 - rmse: 0.5286 - mean_loss: 56.1917 - acc: 0.7528 - val_loss: 0.8479 - val_rmse: 1.6578 - val_mean_loss: 226.3446 - val_acc: 0.3614\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00174: acc did not improve from 0.75689\n",
      "Epoch 175/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2552 - rmse: 0.5171 - mean_loss: 54.1615 - acc: 0.7576 - val_loss: 0.9288 - val_rmse: 1.8149 - val_mean_loss: 125.5684 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00175: acc improved from 0.75689 to 0.75762, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 176/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2588 - rmse: 0.5276 - mean_loss: 56.6869 - acc: 0.7492 - val_loss: 0.8525 - val_rmse: 1.6180 - val_mean_loss: 145.5219 - val_acc: 0.3529\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00176: acc did not improve from 0.75762\n",
      "Epoch 177/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2545 - rmse: 0.5110 - mean_loss: 53.0777 - acc: 0.7538 - val_loss: 0.8812 - val_rmse: 1.6761 - val_mean_loss: 141.7260 - val_acc: 0.3427\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00177: acc did not improve from 0.75762\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2509 - rmse: 0.5156 - mean_loss: 56.8526 - acc: 0.7538 - val_loss: 0.8568 - val_rmse: 1.6820 - val_mean_loss: 257.2732 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00178: acc did not improve from 0.75762\n",
      "Epoch 179/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2537 - rmse: 0.5189 - mean_loss: 54.3201 - acc: 0.7554 - val_loss: 0.8697 - val_rmse: 1.6003 - val_mean_loss: 114.6400 - val_acc: 0.3399\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00179: acc did not improve from 0.75762\n",
      "Epoch 180/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2615 - rmse: 0.5352 - mean_loss: 57.1682 - acc: 0.7468 - val_loss: 0.8486 - val_rmse: 1.6651 - val_mean_loss: 222.5780 - val_acc: 0.3443\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00180: acc did not improve from 0.75762\n",
      "Epoch 181/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2622 - rmse: 0.5459 - mean_loss: 57.7719 - acc: 0.7475 - val_loss: 0.8423 - val_rmse: 1.6362 - val_mean_loss: 202.2766 - val_acc: 0.3453\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00181: acc did not improve from 0.75762\n",
      "Epoch 182/200\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.2605 - rmse: 0.5236 - mean_loss: 53.3204 - acc: 0.7510 - val_loss: 0.8677 - val_rmse: 1.6602 - val_mean_loss: 132.7654 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00182: acc did not improve from 0.75762\n",
      "Epoch 183/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2557 - rmse: 0.5307 - mean_loss: 56.2900 - acc: 0.7588 - val_loss: 0.8308 - val_rmse: 1.6235 - val_mean_loss: 211.3317 - val_acc: 0.3468\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00183: acc improved from 0.75762 to 0.75885, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 184/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2563 - rmse: 0.5205 - mean_loss: 54.1989 - acc: 0.7538 - val_loss: 0.8598 - val_rmse: 1.6776 - val_mean_loss: 189.0254 - val_acc: 0.3331\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00184: acc did not improve from 0.75885\n",
      "Epoch 185/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2471 - rmse: 0.5030 - mean_loss: 54.3308 - acc: 0.7591 - val_loss: 0.8472 - val_rmse: 1.6388 - val_mean_loss: 194.3123 - val_acc: 0.3294\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00185: acc improved from 0.75885 to 0.75909, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 186/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2460 - rmse: 0.4985 - mean_loss: 54.8369 - acc: 0.7558 - val_loss: 0.8557 - val_rmse: 1.6808 - val_mean_loss: 194.8071 - val_acc: 0.3372\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00186: acc did not improve from 0.75909\n",
      "Epoch 187/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2559 - rmse: 0.5278 - mean_loss: 55.6775 - acc: 0.7495 - val_loss: 0.8741 - val_rmse: 1.6705 - val_mean_loss: 156.6485 - val_acc: 0.3334\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00187: acc did not improve from 0.75909\n",
      "Epoch 188/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2540 - rmse: 0.5237 - mean_loss: 55.0700 - acc: 0.7555 - val_loss: 0.8653 - val_rmse: 1.6959 - val_mean_loss: 200.7490 - val_acc: 0.3615\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00188: acc did not improve from 0.75909\n",
      "Epoch 189/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2469 - rmse: 0.5118 - mean_loss: 58.0876 - acc: 0.7523 - val_loss: 0.8389 - val_rmse: 1.6395 - val_mean_loss: 223.4578 - val_acc: 0.3376\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00189: acc did not improve from 0.75909\n",
      "Epoch 190/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2584 - rmse: 0.5191 - mean_loss: 52.3375 - acc: 0.7521 - val_loss: 0.8620 - val_rmse: 1.5998 - val_mean_loss: 116.8485 - val_acc: 0.3468\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00190: acc did not improve from 0.75909\n",
      "Epoch 191/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2466 - rmse: 0.5110 - mean_loss: 56.9886 - acc: 0.7559 - val_loss: 0.8527 - val_rmse: 1.6710 - val_mean_loss: 239.5592 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00191: acc did not improve from 0.75909\n",
      "Epoch 192/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2521 - rmse: 0.5129 - mean_loss: 55.3215 - acc: 0.7571 - val_loss: 0.8378 - val_rmse: 1.6201 - val_mean_loss: 210.6644 - val_acc: 0.3383\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00192: acc did not improve from 0.75909\n",
      "Epoch 193/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2536 - rmse: 0.5166 - mean_loss: 53.3032 - acc: 0.7590 - val_loss: 0.8380 - val_rmse: 1.6383 - val_mean_loss: 207.9727 - val_acc: 0.3462\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00193: acc did not improve from 0.75909\n",
      "Epoch 194/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2448 - rmse: 0.4974 - mean_loss: 54.0771 - acc: 0.7617 - val_loss: 0.8627 - val_rmse: 1.6712 - val_mean_loss: 170.6621 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00194: acc improved from 0.75909 to 0.76173, saving model to D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/weights.best.by.accuracy.hdf5\n",
      "Epoch 195/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2477 - rmse: 0.5080 - mean_loss: 55.1931 - acc: 0.7579 - val_loss: 0.8962 - val_rmse: 1.6564 - val_mean_loss: 139.3894 - val_acc: 0.3453\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00195: acc did not improve from 0.76173\n",
      "Epoch 196/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2567 - rmse: 0.5206 - mean_loss: 54.2980 - acc: 0.7552 - val_loss: 0.8618 - val_rmse: 1.6721 - val_mean_loss: 169.7666 - val_acc: 0.3348\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00196: acc did not improve from 0.76173\n",
      "Epoch 197/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2473 - rmse: 0.5108 - mean_loss: 54.3463 - acc: 0.7604 - val_loss: 0.9216 - val_rmse: 1.6508 - val_mean_loss: 111.3211 - val_acc: 0.3493\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00197: acc did not improve from 0.76173\n",
      "Epoch 198/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2446 - rmse: 0.5010 - mean_loss: 55.0466 - acc: 0.7541 - val_loss: 0.8299 - val_rmse: 1.5992 - val_mean_loss: 175.9926 - val_acc: 0.3424\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00198: acc did not improve from 0.76173\n",
      "Epoch 199/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2480 - rmse: 0.5001 - mean_loss: 54.4069 - acc: 0.7552 - val_loss: 0.8439 - val_rmse: 1.6466 - val_mean_loss: 239.5465 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00199: acc did not improve from 0.76173\n",
      "Epoch 200/200\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.2523 - rmse: 0.5152 - mean_loss: 54.9945 - acc: 0.7521 - val_loss: 0.8569 - val_rmse: 1.6653 - val_mean_loss: 191.0505 - val_acc: 0.3474\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.80720\n",
      "\n",
      "Epoch 00200: acc did not improve from 0.76173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d399a58ef0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthSiameseVO/model/test-learning-rate-higher/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthSiameseVO/test-learning-rate-higher/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mil épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vo_loss_mod(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]* 0.3\n",
    "    mean_rot = mean[:, 0:3] * 150\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod], optimizer=opt, metrics=[rmse, 'acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1503 - rmse: 0.3580 - acc: 0.8139 - val_loss: 0.7986 - val_rmse: 1.5693 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79862, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.81390, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1185 - rmse: 0.2632 - acc: 0.8331 - val_loss: 0.8058 - val_rmse: 1.5966 - val_acc: 0.3496\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.79862\n",
      "\n",
      "Epoch 00002: acc improved from 0.81390 to 0.83313, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.1039 - rmse: 0.2186 - acc: 0.8447 - val_loss: 0.7974 - val_rmse: 1.5686 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.79862 to 0.79738, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.83313 to 0.84470, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0947 - rmse: 0.1959 - acc: 0.8500 - val_loss: 0.7991 - val_rmse: 1.5714 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00004: acc improved from 0.84470 to 0.84997, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0887 - rmse: 0.1819 - acc: 0.8556 - val_loss: 0.8077 - val_rmse: 1.5825 - val_acc: 0.3570\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00005: acc improved from 0.84997 to 0.85560, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0835 - rmse: 0.1701 - acc: 0.8631 - val_loss: 0.8038 - val_rmse: 1.5823 - val_acc: 0.3503\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00006: acc improved from 0.85560 to 0.86314, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0805 - rmse: 0.1635 - acc: 0.8623 - val_loss: 0.8058 - val_rmse: 1.5894 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.86314\n",
      "Epoch 8/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0769 - rmse: 0.1550 - acc: 0.8654 - val_loss: 0.8047 - val_rmse: 1.5862 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00008: acc improved from 0.86314 to 0.86540, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0750 - rmse: 0.1529 - acc: 0.8735 - val_loss: 0.8016 - val_rmse: 1.5795 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00009: acc improved from 0.86540 to 0.87348, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0726 - rmse: 0.1484 - acc: 0.8772 - val_loss: 0.8014 - val_rmse: 1.5767 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00010: acc improved from 0.87348 to 0.87716, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0707 - rmse: 0.1445 - acc: 0.8789 - val_loss: 0.8015 - val_rmse: 1.5802 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00011: acc improved from 0.87716 to 0.87893, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 12/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0685 - rmse: 0.1391 - acc: 0.8808 - val_loss: 0.8031 - val_rmse: 1.5859 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00012: acc improved from 0.87893 to 0.88077, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0697 - rmse: 0.1463 - acc: 0.8828 - val_loss: 0.8030 - val_rmse: 1.5854 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00013: acc improved from 0.88077 to 0.88279, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0673 - rmse: 0.1392 - acc: 0.8833 - val_loss: 0.8017 - val_rmse: 1.5805 - val_acc: 0.3516\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00014: acc improved from 0.88279 to 0.88328, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0652 - rmse: 0.1334 - acc: 0.8825 - val_loss: 0.8029 - val_rmse: 1.5856 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.88328\n",
      "Epoch 16/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0643 - rmse: 0.1328 - acc: 0.8890 - val_loss: 0.8039 - val_rmse: 1.5881 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00016: acc improved from 0.88328 to 0.88898, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0640 - rmse: 0.1322 - acc: 0.8906 - val_loss: 0.8059 - val_rmse: 1.5906 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00017: acc improved from 0.88898 to 0.89063, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0631 - rmse: 0.1316 - acc: 0.8908 - val_loss: 0.8037 - val_rmse: 1.5846 - val_acc: 0.3548\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00018: acc improved from 0.89063 to 0.89075, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0609 - rmse: 0.1259 - acc: 0.8945 - val_loss: 0.8076 - val_rmse: 1.5918 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00019: acc improved from 0.89075 to 0.89455, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0612 - rmse: 0.1280 - acc: 0.8953 - val_loss: 0.8054 - val_rmse: 1.5917 - val_acc: 0.3602\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00020: acc improved from 0.89455 to 0.89528, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 21/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0601 - rmse: 0.1242 - acc: 0.8942 - val_loss: 0.8081 - val_rmse: 1.5963 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.89528\n",
      "Epoch 22/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0601 - rmse: 0.1234 - acc: 0.8964 - val_loss: 0.8023 - val_rmse: 1.5792 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00022: acc improved from 0.89528 to 0.89645, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0602 - rmse: 0.1261 - acc: 0.8936 - val_loss: 0.8111 - val_rmse: 1.6075 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.89645\n",
      "Epoch 24/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0586 - rmse: 0.1227 - acc: 0.8963 - val_loss: 0.8055 - val_rmse: 1.5909 - val_acc: 0.3493\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.89645\n",
      "Epoch 25/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0584 - rmse: 0.1223 - acc: 0.8961 - val_loss: 0.8046 - val_rmse: 1.5909 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.89645\n",
      "Epoch 26/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0578 - rmse: 0.1184 - acc: 0.8996 - val_loss: 0.8044 - val_rmse: 1.5888 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00026: acc improved from 0.89645 to 0.89963, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 27/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0580 - rmse: 0.1206 - acc: 0.8971 - val_loss: 0.8067 - val_rmse: 1.5960 - val_acc: 0.3545\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00027: acc did not improve from 0.89963\n",
      "Epoch 28/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0573 - rmse: 0.1184 - acc: 0.9021 - val_loss: 0.8078 - val_rmse: 1.5974 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00028: acc improved from 0.89963 to 0.90208, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 29/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0565 - rmse: 0.1182 - acc: 0.9039 - val_loss: 0.8072 - val_rmse: 1.5924 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00029: acc improved from 0.90208 to 0.90386, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 30/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0562 - rmse: 0.1194 - acc: 0.9045 - val_loss: 0.8069 - val_rmse: 1.5975 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00030: acc improved from 0.90386 to 0.90447, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 31/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0552 - rmse: 0.1146 - acc: 0.8991 - val_loss: 0.8135 - val_rmse: 1.6071 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00031: acc did not improve from 0.90447\n",
      "Epoch 32/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0560 - rmse: 0.1180 - acc: 0.9012 - val_loss: 0.8063 - val_rmse: 1.5901 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.90447\n",
      "Epoch 33/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0553 - rmse: 0.1157 - acc: 0.9045 - val_loss: 0.8060 - val_rmse: 1.5953 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00033: acc did not improve from 0.90447\n",
      "Epoch 34/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0545 - rmse: 0.1162 - acc: 0.9072 - val_loss: 0.8071 - val_rmse: 1.5962 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00034: acc improved from 0.90447 to 0.90716, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 35/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0544 - rmse: 0.1148 - acc: 0.9056 - val_loss: 0.8083 - val_rmse: 1.5980 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00035: acc did not improve from 0.90716\n",
      "Epoch 36/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0546 - rmse: 0.1163 - acc: 0.9051 - val_loss: 0.8073 - val_rmse: 1.6005 - val_acc: 0.3570\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00036: acc did not improve from 0.90716\n",
      "Epoch 37/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0547 - rmse: 0.1160 - acc: 0.9018 - val_loss: 0.8085 - val_rmse: 1.6030 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00037: acc did not improve from 0.90716\n",
      "Epoch 38/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0538 - rmse: 0.1123 - acc: 0.9092 - val_loss: 0.8109 - val_rmse: 1.6042 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00038: acc improved from 0.90716 to 0.90919, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 39/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0538 - rmse: 0.1142 - acc: 0.9072 - val_loss: 0.8099 - val_rmse: 1.6062 - val_acc: 0.3574\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.90919\n",
      "Epoch 40/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0539 - rmse: 0.1139 - acc: 0.9054 - val_loss: 0.8082 - val_rmse: 1.5976 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00040: acc did not improve from 0.90919\n",
      "Epoch 41/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0533 - rmse: 0.1152 - acc: 0.9073 - val_loss: 0.8071 - val_rmse: 1.5987 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.90919\n",
      "Epoch 42/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0531 - rmse: 0.1114 - acc: 0.9051 - val_loss: 0.8128 - val_rmse: 1.6157 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00042: acc did not improve from 0.90919\n",
      "Epoch 43/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0526 - rmse: 0.1124 - acc: 0.9069 - val_loss: 0.8089 - val_rmse: 1.6026 - val_acc: 0.3620\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.90919\n",
      "Epoch 44/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0531 - rmse: 0.1130 - acc: 0.9064 - val_loss: 0.8109 - val_rmse: 1.6038 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00044: acc did not improve from 0.90919\n",
      "Epoch 45/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0525 - rmse: 0.1125 - acc: 0.9093 - val_loss: 0.8121 - val_rmse: 1.6122 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00045: acc improved from 0.90919 to 0.90931, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 46/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0513 - rmse: 0.1088 - acc: 0.9089 - val_loss: 0.8078 - val_rmse: 1.5986 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00046: acc did not improve from 0.90931\n",
      "Epoch 47/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0526 - rmse: 0.1134 - acc: 0.9078 - val_loss: 0.8083 - val_rmse: 1.6040 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00047: acc did not improve from 0.90931\n",
      "Epoch 48/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0521 - rmse: 0.1130 - acc: 0.9071 - val_loss: 0.8118 - val_rmse: 1.6105 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00048: acc did not improve from 0.90931\n",
      "Epoch 49/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0518 - rmse: 0.1122 - acc: 0.9130 - val_loss: 0.8073 - val_rmse: 1.5988 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00049: acc improved from 0.90931 to 0.91298, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0502 - rmse: 0.1074 - acc: 0.9107 - val_loss: 0.8060 - val_rmse: 1.5945 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.91298\n",
      "Epoch 51/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0509 - rmse: 0.1102 - acc: 0.9122 - val_loss: 0.8110 - val_rmse: 1.6089 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00051: acc did not improve from 0.91298\n",
      "Epoch 52/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0515 - rmse: 0.1102 - acc: 0.9115 - val_loss: 0.8137 - val_rmse: 1.6194 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00052: acc did not improve from 0.91298\n",
      "Epoch 53/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0512 - rmse: 0.1104 - acc: 0.9091 - val_loss: 0.8131 - val_rmse: 1.6140 - val_acc: 0.3614\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00053: acc did not improve from 0.91298\n",
      "Epoch 54/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0504 - rmse: 0.1069 - acc: 0.9121 - val_loss: 0.8083 - val_rmse: 1.6005 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00054: acc did not improve from 0.91298\n",
      "Epoch 55/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0505 - rmse: 0.1077 - acc: 0.9130 - val_loss: 0.8108 - val_rmse: 1.6067 - val_acc: 0.3545\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00055: acc improved from 0.91298 to 0.91298, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 56/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0501 - rmse: 0.1070 - acc: 0.9156 - val_loss: 0.8118 - val_rmse: 1.6096 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00056: acc improved from 0.91298 to 0.91555, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 57/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0504 - rmse: 0.1092 - acc: 0.9125 - val_loss: 0.8103 - val_rmse: 1.6079 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00057: acc did not improve from 0.91555\n",
      "Epoch 58/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0506 - rmse: 0.1080 - acc: 0.9127 - val_loss: 0.8091 - val_rmse: 1.6012 - val_acc: 0.3506\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00058: acc did not improve from 0.91555\n",
      "Epoch 59/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0505 - rmse: 0.1071 - acc: 0.9127 - val_loss: 0.8097 - val_rmse: 1.6050 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00059: acc did not improve from 0.91555\n",
      "Epoch 60/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0498 - rmse: 0.1089 - acc: 0.9157 - val_loss: 0.8105 - val_rmse: 1.6077 - val_acc: 0.3528\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00060: acc improved from 0.91555 to 0.91568, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 61/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0496 - rmse: 0.1064 - acc: 0.9121 - val_loss: 0.8163 - val_rmse: 1.6228 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00061: acc did not improve from 0.91568\n",
      "Epoch 62/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0496 - rmse: 0.1064 - acc: 0.9148 - val_loss: 0.8108 - val_rmse: 1.6056 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00062: acc did not improve from 0.91568\n",
      "Epoch 63/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0491 - rmse: 0.1065 - acc: 0.9162 - val_loss: 0.8106 - val_rmse: 1.6056 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00063: acc improved from 0.91568 to 0.91623, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 64/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0499 - rmse: 0.1098 - acc: 0.9120 - val_loss: 0.8114 - val_rmse: 1.6107 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00064: acc did not improve from 0.91623\n",
      "Epoch 65/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0494 - rmse: 0.1052 - acc: 0.9141 - val_loss: 0.8105 - val_rmse: 1.6073 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00065: acc did not improve from 0.91623\n",
      "Epoch 66/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0495 - rmse: 0.1079 - acc: 0.9154 - val_loss: 0.8124 - val_rmse: 1.6139 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00066: acc did not improve from 0.91623\n",
      "Epoch 67/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0488 - rmse: 0.1048 - acc: 0.9131 - val_loss: 0.8105 - val_rmse: 1.6079 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00067: acc did not improve from 0.91623\n",
      "Epoch 68/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0495 - rmse: 0.1090 - acc: 0.9137 - val_loss: 0.8123 - val_rmse: 1.6127 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00068: acc did not improve from 0.91623\n",
      "Epoch 69/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0488 - rmse: 0.1048 - acc: 0.9157 - val_loss: 0.8164 - val_rmse: 1.6222 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00069: acc did not improve from 0.91623\n",
      "Epoch 70/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0490 - rmse: 0.1072 - acc: 0.9145 - val_loss: 0.8142 - val_rmse: 1.6158 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00070: acc did not improve from 0.91623\n",
      "Epoch 71/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0483 - rmse: 0.1047 - acc: 0.9132 - val_loss: 0.8078 - val_rmse: 1.5989 - val_acc: 0.3561\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00071: acc did not improve from 0.91623\n",
      "Epoch 72/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0486 - rmse: 0.1049 - acc: 0.9159 - val_loss: 0.8150 - val_rmse: 1.6184 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00072: acc did not improve from 0.91623\n",
      "Epoch 73/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0486 - rmse: 0.1057 - acc: 0.9186 - val_loss: 0.8099 - val_rmse: 1.6043 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00073: acc improved from 0.91623 to 0.91855, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 74/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0482 - rmse: 0.1037 - acc: 0.9138 - val_loss: 0.8143 - val_rmse: 1.6169 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00074: acc did not improve from 0.91855\n",
      "Epoch 75/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0480 - rmse: 0.1061 - acc: 0.9160 - val_loss: 0.8109 - val_rmse: 1.6076 - val_acc: 0.3532\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00075: acc did not improve from 0.91855\n",
      "Epoch 76/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0474 - rmse: 0.1015 - acc: 0.9181 - val_loss: 0.8156 - val_rmse: 1.6196 - val_acc: 0.3615\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00076: acc did not improve from 0.91855\n",
      "Epoch 77/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0481 - rmse: 0.1033 - acc: 0.9141 - val_loss: 0.8149 - val_rmse: 1.6192 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00077: acc did not improve from 0.91855\n",
      "Epoch 78/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0481 - rmse: 0.1055 - acc: 0.9186 - val_loss: 0.8197 - val_rmse: 1.6296 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00078: acc improved from 0.91855 to 0.91862, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 79/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0474 - rmse: 0.1025 - acc: 0.9128 - val_loss: 0.8152 - val_rmse: 1.6203 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00079: acc did not improve from 0.91862\n",
      "Epoch 80/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0475 - rmse: 0.1052 - acc: 0.9184 - val_loss: 0.8181 - val_rmse: 1.6262 - val_acc: 0.3579\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00080: acc did not improve from 0.91862\n",
      "Epoch 81/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0472 - rmse: 0.1019 - acc: 0.9173 - val_loss: 0.8180 - val_rmse: 1.6268 - val_acc: 0.3538\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00081: acc did not improve from 0.91862\n",
      "Epoch 82/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0477 - rmse: 0.1040 - acc: 0.9174 - val_loss: 0.8150 - val_rmse: 1.6187 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00082: acc did not improve from 0.91862\n",
      "Epoch 83/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0478 - rmse: 0.1026 - acc: 0.9179 - val_loss: 0.8158 - val_rmse: 1.6234 - val_acc: 0.3567\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00083: acc did not improve from 0.91862\n",
      "Epoch 84/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0476 - rmse: 0.1039 - acc: 0.9174 - val_loss: 0.8197 - val_rmse: 1.6325 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00084: acc did not improve from 0.91862\n",
      "Epoch 85/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0475 - rmse: 0.1038 - acc: 0.9173 - val_loss: 0.8145 - val_rmse: 1.6193 - val_acc: 0.3563\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00085: acc did not improve from 0.91862\n",
      "Epoch 86/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0470 - rmse: 0.1014 - acc: 0.9201 - val_loss: 0.8178 - val_rmse: 1.6292 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00086: acc improved from 0.91862 to 0.92015, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 87/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0460 - rmse: 0.0984 - acc: 0.9173 - val_loss: 0.8169 - val_rmse: 1.6226 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00087: acc did not improve from 0.92015\n",
      "Epoch 88/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0466 - rmse: 0.1008 - acc: 0.9175 - val_loss: 0.8153 - val_rmse: 1.6194 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00088: acc did not improve from 0.92015\n",
      "Epoch 89/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0478 - rmse: 0.1047 - acc: 0.9183 - val_loss: 0.8184 - val_rmse: 1.6281 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00089: acc did not improve from 0.92015\n",
      "Epoch 90/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0473 - rmse: 0.1043 - acc: 0.9176 - val_loss: 0.8198 - val_rmse: 1.6332 - val_acc: 0.3561\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00090: acc did not improve from 0.92015\n",
      "Epoch 91/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0468 - rmse: 0.0998 - acc: 0.9179 - val_loss: 0.8154 - val_rmse: 1.6233 - val_acc: 0.3555\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00091: acc did not improve from 0.92015\n",
      "Epoch 92/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0472 - rmse: 0.1021 - acc: 0.9212 - val_loss: 0.8172 - val_rmse: 1.6260 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00092: acc improved from 0.92015 to 0.92125, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 93/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0465 - rmse: 0.1010 - acc: 0.9220 - val_loss: 0.8101 - val_rmse: 1.6104 - val_acc: 0.3615\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00093: acc improved from 0.92125 to 0.92198, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 94/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0464 - rmse: 0.1010 - acc: 0.9171 - val_loss: 0.8169 - val_rmse: 1.6232 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00094: acc did not improve from 0.92198\n",
      "Epoch 95/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0471 - rmse: 0.1034 - acc: 0.9179 - val_loss: 0.8131 - val_rmse: 1.6134 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00095: acc did not improve from 0.92198\n",
      "Epoch 96/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0467 - rmse: 0.1018 - acc: 0.9176 - val_loss: 0.8137 - val_rmse: 1.6179 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00096: acc did not improve from 0.92198\n",
      "Epoch 97/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0463 - rmse: 0.1021 - acc: 0.9201 - val_loss: 0.8143 - val_rmse: 1.6183 - val_acc: 0.3552\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00097: acc did not improve from 0.92198\n",
      "Epoch 98/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0461 - rmse: 0.1016 - acc: 0.9192 - val_loss: 0.8221 - val_rmse: 1.6396 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00098: acc did not improve from 0.92198\n",
      "Epoch 99/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0460 - rmse: 0.1014 - acc: 0.9198 - val_loss: 0.8109 - val_rmse: 1.6101 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00099: acc did not improve from 0.92198\n",
      "Epoch 100/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0450 - rmse: 0.0966 - acc: 0.9201 - val_loss: 0.8111 - val_rmse: 1.6092 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00100: acc did not improve from 0.92198\n",
      "Epoch 101/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0459 - rmse: 0.1017 - acc: 0.9200 - val_loss: 0.8162 - val_rmse: 1.6227 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00101: acc did not improve from 0.92198\n",
      "Epoch 102/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0460 - rmse: 0.1015 - acc: 0.9204 - val_loss: 0.8156 - val_rmse: 1.6201 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00102: acc did not improve from 0.92198\n",
      "Epoch 103/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0455 - rmse: 0.0995 - acc: 0.9200 - val_loss: 0.8176 - val_rmse: 1.6295 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00103: acc did not improve from 0.92198\n",
      "Epoch 104/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0462 - rmse: 0.1032 - acc: 0.9172 - val_loss: 0.8163 - val_rmse: 1.6245 - val_acc: 0.3612\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00104: acc did not improve from 0.92198\n",
      "Epoch 105/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0460 - rmse: 0.0996 - acc: 0.9187 - val_loss: 0.8177 - val_rmse: 1.6301 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00105: acc did not improve from 0.92198\n",
      "Epoch 106/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0455 - rmse: 0.1015 - acc: 0.9198 - val_loss: 0.8159 - val_rmse: 1.6246 - val_acc: 0.3640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00106: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00106: acc did not improve from 0.92198\n",
      "Epoch 107/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0458 - rmse: 0.0994 - acc: 0.9206 - val_loss: 0.8171 - val_rmse: 1.6267 - val_acc: 0.3519\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00107: acc did not improve from 0.92198\n",
      "Epoch 108/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0456 - rmse: 0.1003 - acc: 0.9225 - val_loss: 0.8156 - val_rmse: 1.6229 - val_acc: 0.3656\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00108: acc improved from 0.92198 to 0.92254, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 109/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0453 - rmse: 0.0983 - acc: 0.9190 - val_loss: 0.8134 - val_rmse: 1.6173 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00109: acc did not improve from 0.92254\n",
      "Epoch 110/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0448 - rmse: 0.0985 - acc: 0.9199 - val_loss: 0.8197 - val_rmse: 1.6313 - val_acc: 0.3647\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00110: acc did not improve from 0.92254\n",
      "Epoch 111/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0456 - rmse: 0.1023 - acc: 0.9192 - val_loss: 0.8175 - val_rmse: 1.6290 - val_acc: 0.3564\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00111: acc did not improve from 0.92254\n",
      "Epoch 112/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0451 - rmse: 0.0992 - acc: 0.9246 - val_loss: 0.8203 - val_rmse: 1.6346 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00112: acc improved from 0.92254 to 0.92456, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 113/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0451 - rmse: 0.0980 - acc: 0.9228 - val_loss: 0.8218 - val_rmse: 1.6421 - val_acc: 0.3634\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00113: acc did not improve from 0.92456\n",
      "Epoch 114/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0459 - rmse: 0.1003 - acc: 0.9241 - val_loss: 0.8210 - val_rmse: 1.6319 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00114: acc did not improve from 0.92456\n",
      "Epoch 115/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0452 - rmse: 0.0986 - acc: 0.9175 - val_loss: 0.8155 - val_rmse: 1.6223 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00115: acc did not improve from 0.92456\n",
      "Epoch 116/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0454 - rmse: 0.1005 - acc: 0.9227 - val_loss: 0.8212 - val_rmse: 1.6411 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00116: acc did not improve from 0.92456\n",
      "Epoch 117/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0445 - rmse: 0.0984 - acc: 0.9214 - val_loss: 0.8159 - val_rmse: 1.6231 - val_acc: 0.3649\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00117: acc did not improve from 0.92456\n",
      "Epoch 118/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0453 - rmse: 0.0999 - acc: 0.9204 - val_loss: 0.8210 - val_rmse: 1.6389 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00118: acc did not improve from 0.92456\n",
      "Epoch 119/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0451 - rmse: 0.0994 - acc: 0.9200 - val_loss: 0.8166 - val_rmse: 1.6258 - val_acc: 0.3655\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00119: acc did not improve from 0.92456\n",
      "Epoch 120/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0445 - rmse: 0.0978 - acc: 0.9224 - val_loss: 0.8154 - val_rmse: 1.6221 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00120: acc did not improve from 0.92456\n",
      "Epoch 121/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0456 - rmse: 0.1010 - acc: 0.9217 - val_loss: 0.8157 - val_rmse: 1.6245 - val_acc: 0.3536\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00121: acc did not improve from 0.92456\n",
      "Epoch 122/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0445 - rmse: 0.0983 - acc: 0.9230 - val_loss: 0.8152 - val_rmse: 1.6210 - val_acc: 0.3663\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00122: acc did not improve from 0.92456\n",
      "Epoch 123/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0459 - rmse: 0.1024 - acc: 0.9189 - val_loss: 0.8184 - val_rmse: 1.6282 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00123: acc did not improve from 0.92456\n",
      "Epoch 124/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0443 - rmse: 0.0976 - acc: 0.9194 - val_loss: 0.8123 - val_rmse: 1.6152 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00124: acc did not improve from 0.92456\n",
      "Epoch 125/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0447 - rmse: 0.0994 - acc: 0.9211 - val_loss: 0.8240 - val_rmse: 1.6441 - val_acc: 0.3535\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00125: acc did not improve from 0.92456\n",
      "Epoch 126/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0451 - rmse: 0.0989 - acc: 0.9228 - val_loss: 0.8225 - val_rmse: 1.6411 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00126: acc did not improve from 0.92456\n",
      "Epoch 127/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0444 - rmse: 0.0960 - acc: 0.9227 - val_loss: 0.8143 - val_rmse: 1.6206 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00127: acc did not improve from 0.92456\n",
      "Epoch 128/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0452 - rmse: 0.1004 - acc: 0.9214 - val_loss: 0.8213 - val_rmse: 1.6387 - val_acc: 0.3598\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00128: acc did not improve from 0.92456\n",
      "Epoch 129/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0448 - rmse: 0.0992 - acc: 0.9191 - val_loss: 0.8247 - val_rmse: 1.6478 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00129: acc did not improve from 0.92456\n",
      "Epoch 130/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0447 - rmse: 0.1001 - acc: 0.9228 - val_loss: 0.8195 - val_rmse: 1.6309 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00130: acc did not improve from 0.92456\n",
      "Epoch 131/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0444 - rmse: 0.0980 - acc: 0.9228 - val_loss: 0.8161 - val_rmse: 1.6267 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00131: acc did not improve from 0.92456\n",
      "Epoch 132/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0437 - rmse: 0.0962 - acc: 0.9244 - val_loss: 0.8216 - val_rmse: 1.6386 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00132: acc did not improve from 0.92456\n",
      "Epoch 133/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0444 - rmse: 0.0978 - acc: 0.9216 - val_loss: 0.8179 - val_rmse: 1.6275 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00133: acc did not improve from 0.92456\n",
      "Epoch 134/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0446 - rmse: 0.0973 - acc: 0.9228 - val_loss: 0.8216 - val_rmse: 1.6408 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00134: acc did not improve from 0.92456\n",
      "Epoch 135/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0444 - rmse: 0.0978 - acc: 0.9206 - val_loss: 0.8196 - val_rmse: 1.6326 - val_acc: 0.3570\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00135: acc did not improve from 0.92456\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0439 - rmse: 0.0975 - acc: 0.9219 - val_loss: 0.8201 - val_rmse: 1.6337 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00136: acc did not improve from 0.92456\n",
      "Epoch 137/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0449 - rmse: 0.0995 - acc: 0.9222 - val_loss: 0.8167 - val_rmse: 1.6246 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00137: acc did not improve from 0.92456\n",
      "Epoch 138/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0445 - rmse: 0.0976 - acc: 0.9239 - val_loss: 0.8177 - val_rmse: 1.6278 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00138: acc did not improve from 0.92456\n",
      "Epoch 139/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0434 - rmse: 0.0961 - acc: 0.9223 - val_loss: 0.8229 - val_rmse: 1.6395 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00139: acc did not improve from 0.92456\n",
      "Epoch 140/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0443 - rmse: 0.0994 - acc: 0.9225 - val_loss: 0.8224 - val_rmse: 1.6416 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00140: acc did not improve from 0.92456\n",
      "Epoch 141/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0443 - rmse: 0.0982 - acc: 0.9214 - val_loss: 0.8174 - val_rmse: 1.6257 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00141: acc did not improve from 0.92456\n",
      "Epoch 142/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0440 - rmse: 0.0966 - acc: 0.9213 - val_loss: 0.8177 - val_rmse: 1.6278 - val_acc: 0.3542\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00142: acc did not improve from 0.92456\n",
      "Epoch 143/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0433 - rmse: 0.0964 - acc: 0.9252 - val_loss: 0.8156 - val_rmse: 1.6216 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00143: acc improved from 0.92456 to 0.92517, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 144/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0438 - rmse: 0.0966 - acc: 0.9249 - val_loss: 0.8211 - val_rmse: 1.6355 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00144: acc did not improve from 0.92517\n",
      "Epoch 145/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0442 - rmse: 0.0980 - acc: 0.9218 - val_loss: 0.8209 - val_rmse: 1.6350 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00145: acc did not improve from 0.92517\n",
      "Epoch 146/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0433 - rmse: 0.0949 - acc: 0.9231 - val_loss: 0.8190 - val_rmse: 1.6322 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00146: acc did not improve from 0.92517\n",
      "Epoch 147/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0438 - rmse: 0.0963 - acc: 0.9226 - val_loss: 0.8207 - val_rmse: 1.6351 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00147: acc did not improve from 0.92517\n",
      "Epoch 148/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0434 - rmse: 0.0949 - acc: 0.9239 - val_loss: 0.8154 - val_rmse: 1.6217 - val_acc: 0.3528\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00148: acc did not improve from 0.92517\n",
      "Epoch 149/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0444 - rmse: 0.0993 - acc: 0.9224 - val_loss: 0.8183 - val_rmse: 1.6293 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00149: acc did not improve from 0.92517\n",
      "Epoch 150/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0441 - rmse: 0.0977 - acc: 0.9227 - val_loss: 0.8227 - val_rmse: 1.6392 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00150: acc did not improve from 0.92517\n",
      "Epoch 151/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0429 - rmse: 0.0960 - acc: 0.9261 - val_loss: 0.8214 - val_rmse: 1.6385 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00151: acc improved from 0.92517 to 0.92609, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 152/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0441 - rmse: 0.0990 - acc: 0.9236 - val_loss: 0.8185 - val_rmse: 1.6302 - val_acc: 0.3563\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00152: acc did not improve from 0.92609\n",
      "Epoch 153/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0438 - rmse: 0.0975 - acc: 0.9236 - val_loss: 0.8214 - val_rmse: 1.6355 - val_acc: 0.3633\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00153: acc did not improve from 0.92609\n",
      "Epoch 154/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0434 - rmse: 0.0944 - acc: 0.9237 - val_loss: 0.8197 - val_rmse: 1.6333 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00154: acc did not improve from 0.92609\n",
      "Epoch 155/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0435 - rmse: 0.0966 - acc: 0.9211 - val_loss: 0.8214 - val_rmse: 1.6366 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00155: acc did not improve from 0.92609\n",
      "Epoch 156/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0433 - rmse: 0.0972 - acc: 0.9249 - val_loss: 0.8218 - val_rmse: 1.6404 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00156: acc did not improve from 0.92609\n",
      "Epoch 157/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0431 - rmse: 0.0963 - acc: 0.9257 - val_loss: 0.8216 - val_rmse: 1.6384 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00157: acc did not improve from 0.92609\n",
      "Epoch 158/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0437 - rmse: 0.0970 - acc: 0.9245 - val_loss: 0.8198 - val_rmse: 1.6341 - val_acc: 0.3544\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00158: acc did not improve from 0.92609\n",
      "Epoch 159/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0433 - rmse: 0.0950 - acc: 0.9227 - val_loss: 0.8230 - val_rmse: 1.6411 - val_acc: 0.3663\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00159: acc did not improve from 0.92609\n",
      "Epoch 160/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0428 - rmse: 0.0951 - acc: 0.9225 - val_loss: 0.8193 - val_rmse: 1.6330 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00160: acc did not improve from 0.92609\n",
      "Epoch 161/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0435 - rmse: 0.0978 - acc: 0.9228 - val_loss: 0.8255 - val_rmse: 1.6492 - val_acc: 0.3563\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00161: acc did not improve from 0.92609\n",
      "Epoch 162/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0432 - rmse: 0.0957 - acc: 0.9195 - val_loss: 0.8185 - val_rmse: 1.6328 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00162: acc did not improve from 0.92609\n",
      "Epoch 163/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0431 - rmse: 0.0963 - acc: 0.9257 - val_loss: 0.8200 - val_rmse: 1.6335 - val_acc: 0.3548\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00163: acc did not improve from 0.92609\n",
      "Epoch 164/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0429 - rmse: 0.0951 - acc: 0.9236 - val_loss: 0.8212 - val_rmse: 1.6379 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00164: acc did not improve from 0.92609\n",
      "Epoch 165/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0428 - rmse: 0.0957 - acc: 0.9251 - val_loss: 0.8231 - val_rmse: 1.6432 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00165: acc did not improve from 0.92609\n",
      "Epoch 166/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0425 - rmse: 0.0956 - acc: 0.9223 - val_loss: 0.8188 - val_rmse: 1.6331 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00166: acc did not improve from 0.92609\n",
      "Epoch 167/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0425 - rmse: 0.0939 - acc: 0.9224 - val_loss: 0.8205 - val_rmse: 1.6344 - val_acc: 0.3570\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00167: acc did not improve from 0.92609\n",
      "Epoch 168/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0434 - rmse: 0.0941 - acc: 0.9242 - val_loss: 0.8208 - val_rmse: 1.6360 - val_acc: 0.3586\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00168: acc did not improve from 0.92609\n",
      "Epoch 169/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0435 - rmse: 0.0990 - acc: 0.9264 - val_loss: 0.8196 - val_rmse: 1.6342 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00169: acc improved from 0.92609 to 0.92639, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 170/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0430 - rmse: 0.0966 - acc: 0.9245 - val_loss: 0.8183 - val_rmse: 1.6292 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00170: acc did not improve from 0.92639\n",
      "Epoch 171/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0438 - rmse: 0.0978 - acc: 0.9232 - val_loss: 0.8232 - val_rmse: 1.6414 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00171: acc did not improve from 0.92639\n",
      "Epoch 172/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0435 - rmse: 0.0974 - acc: 0.9249 - val_loss: 0.8229 - val_rmse: 1.6432 - val_acc: 0.3620\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00172: acc did not improve from 0.92639\n",
      "Epoch 173/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0428 - rmse: 0.0954 - acc: 0.9252 - val_loss: 0.8206 - val_rmse: 1.6347 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00173: acc did not improve from 0.92639\n",
      "Epoch 174/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0435 - rmse: 0.0948 - acc: 0.9222 - val_loss: 0.8240 - val_rmse: 1.6464 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00174: acc did not improve from 0.92639\n",
      "Epoch 175/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0429 - rmse: 0.0979 - acc: 0.9249 - val_loss: 0.8215 - val_rmse: 1.6384 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00175: acc did not improve from 0.92639\n",
      "Epoch 176/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0433 - rmse: 0.0960 - acc: 0.9252 - val_loss: 0.8209 - val_rmse: 1.6319 - val_acc: 0.3579\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00176: acc did not improve from 0.92639\n",
      "Epoch 177/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0429 - rmse: 0.0950 - acc: 0.9245 - val_loss: 0.8200 - val_rmse: 1.6332 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00177: acc did not improve from 0.92639\n",
      "Epoch 178/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0429 - rmse: 0.0962 - acc: 0.9248 - val_loss: 0.8216 - val_rmse: 1.6377 - val_acc: 0.3692\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00178: acc did not improve from 0.92639\n",
      "Epoch 179/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0933 - acc: 0.9254 - val_loss: 0.8213 - val_rmse: 1.6404 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00179: acc did not improve from 0.92639\n",
      "Epoch 180/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0430 - rmse: 0.0970 - acc: 0.9241 - val_loss: 0.8170 - val_rmse: 1.6253 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00180: acc did not improve from 0.92639\n",
      "Epoch 181/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0433 - rmse: 0.0952 - acc: 0.9243 - val_loss: 0.8227 - val_rmse: 1.6394 - val_acc: 0.3634\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00181: acc did not improve from 0.92639\n",
      "Epoch 182/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0427 - rmse: 0.0949 - acc: 0.9232 - val_loss: 0.8174 - val_rmse: 1.6267 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00182: acc did not improve from 0.92639\n",
      "Epoch 183/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0424 - rmse: 0.0950 - acc: 0.9263 - val_loss: 0.8218 - val_rmse: 1.6384 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00183: acc did not improve from 0.92639\n",
      "Epoch 184/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0426 - rmse: 0.0946 - acc: 0.9253 - val_loss: 0.8200 - val_rmse: 1.6321 - val_acc: 0.3579\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00184: acc did not improve from 0.92639\n",
      "Epoch 185/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0427 - rmse: 0.0954 - acc: 0.9224 - val_loss: 0.8245 - val_rmse: 1.6457 - val_acc: 0.3554\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00185: acc did not improve from 0.92639\n",
      "Epoch 186/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0425 - rmse: 0.0952 - acc: 0.9261 - val_loss: 0.8214 - val_rmse: 1.6392 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00186: acc did not improve from 0.92639\n",
      "Epoch 187/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0426 - rmse: 0.0940 - acc: 0.9269 - val_loss: 0.8200 - val_rmse: 1.6339 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00187: acc improved from 0.92639 to 0.92694, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 188/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0424 - rmse: 0.0957 - acc: 0.9224 - val_loss: 0.8234 - val_rmse: 1.6448 - val_acc: 0.3561\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00188: acc did not improve from 0.92694\n",
      "Epoch 189/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0425 - rmse: 0.0928 - acc: 0.9250 - val_loss: 0.8220 - val_rmse: 1.6397 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00189: acc did not improve from 0.92694\n",
      "Epoch 190/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0422 - rmse: 0.0954 - acc: 0.9271 - val_loss: 0.8240 - val_rmse: 1.6458 - val_acc: 0.3601\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00190: acc improved from 0.92694 to 0.92707, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 191/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0420 - rmse: 0.0939 - acc: 0.9264 - val_loss: 0.8215 - val_rmse: 1.6388 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00191: acc did not improve from 0.92707\n",
      "Epoch 192/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0938 - acc: 0.9238 - val_loss: 0.8211 - val_rmse: 1.6352 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00192: acc did not improve from 0.92707\n",
      "Epoch 193/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0422 - rmse: 0.0945 - acc: 0.9265 - val_loss: 0.8251 - val_rmse: 1.6474 - val_acc: 0.3574\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00193: acc did not improve from 0.92707\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0429 - rmse: 0.0949 - acc: 0.9227 - val_loss: 0.8284 - val_rmse: 1.6576 - val_acc: 0.3612\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00194: acc did not improve from 0.92707\n",
      "Epoch 195/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0938 - acc: 0.9252 - val_loss: 0.8243 - val_rmse: 1.6459 - val_acc: 0.3601\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00195: acc did not improve from 0.92707\n",
      "Epoch 196/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0973 - acc: 0.9276 - val_loss: 0.8236 - val_rmse: 1.6410 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00196: acc improved from 0.92707 to 0.92756, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 197/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0424 - rmse: 0.0951 - acc: 0.9238 - val_loss: 0.8212 - val_rmse: 1.6358 - val_acc: 0.3644\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00197: acc did not improve from 0.92756\n",
      "Epoch 198/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0430 - rmse: 0.0967 - acc: 0.9247 - val_loss: 0.8189 - val_rmse: 1.6313 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00198: acc did not improve from 0.92756\n",
      "Epoch 199/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0427 - rmse: 0.0953 - acc: 0.9236 - val_loss: 0.8244 - val_rmse: 1.6445 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00199: acc did not improve from 0.92756\n",
      "Epoch 200/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0933 - acc: 0.9261 - val_loss: 0.8172 - val_rmse: 1.6283 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00200: acc did not improve from 0.92756\n",
      "Epoch 201/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0420 - rmse: 0.0946 - acc: 0.9258 - val_loss: 0.8246 - val_rmse: 1.6469 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00201: acc did not improve from 0.92756\n",
      "Epoch 202/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0424 - rmse: 0.0940 - acc: 0.9265 - val_loss: 0.8200 - val_rmse: 1.6356 - val_acc: 0.3633\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00202: acc did not improve from 0.92756\n",
      "Epoch 203/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0926 - acc: 0.9265 - val_loss: 0.8200 - val_rmse: 1.6330 - val_acc: 0.3542\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00203: acc did not improve from 0.92756\n",
      "Epoch 204/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0420 - rmse: 0.0940 - acc: 0.9278 - val_loss: 0.8207 - val_rmse: 1.6366 - val_acc: 0.3601\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00204: acc improved from 0.92756 to 0.92780, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 205/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0422 - rmse: 0.0935 - acc: 0.9238 - val_loss: 0.8207 - val_rmse: 1.6359 - val_acc: 0.3650\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00205: acc did not improve from 0.92780\n",
      "Epoch 206/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0417 - rmse: 0.0927 - acc: 0.9223 - val_loss: 0.8200 - val_rmse: 1.6336 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00206: acc did not improve from 0.92780\n",
      "Epoch 207/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0421 - rmse: 0.0935 - acc: 0.9260 - val_loss: 0.8258 - val_rmse: 1.6516 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00207: acc did not improve from 0.92780\n",
      "Epoch 208/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0411 - rmse: 0.0909 - acc: 0.9292 - val_loss: 0.8250 - val_rmse: 1.6478 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00208: acc improved from 0.92780 to 0.92921, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 209/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0414 - rmse: 0.0921 - acc: 0.9265 - val_loss: 0.8223 - val_rmse: 1.6385 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00209: acc did not improve from 0.92921\n",
      "Epoch 210/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0420 - rmse: 0.0950 - acc: 0.9249 - val_loss: 0.8227 - val_rmse: 1.6418 - val_acc: 0.3531\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00210: acc did not improve from 0.92921\n",
      "Epoch 211/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0417 - rmse: 0.0935 - acc: 0.9250 - val_loss: 0.8245 - val_rmse: 1.6463 - val_acc: 0.3570\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00211: acc did not improve from 0.92921\n",
      "Epoch 212/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0419 - rmse: 0.0951 - acc: 0.9256 - val_loss: 0.8233 - val_rmse: 1.6429 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00212: acc did not improve from 0.92921\n",
      "Epoch 213/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0415 - rmse: 0.0920 - acc: 0.9254 - val_loss: 0.8245 - val_rmse: 1.6499 - val_acc: 0.3644\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00213: acc did not improve from 0.92921\n",
      "Epoch 214/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0425 - rmse: 0.0950 - acc: 0.9263 - val_loss: 0.8231 - val_rmse: 1.6413 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00214: acc did not improve from 0.92921\n",
      "Epoch 215/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0414 - rmse: 0.0926 - acc: 0.9275 - val_loss: 0.8217 - val_rmse: 1.6397 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00215: acc did not improve from 0.92921\n",
      "Epoch 216/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0418 - rmse: 0.0917 - acc: 0.9243 - val_loss: 0.8253 - val_rmse: 1.6489 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00216: acc did not improve from 0.92921\n",
      "Epoch 217/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0416 - rmse: 0.0915 - acc: 0.9239 - val_loss: 0.8240 - val_rmse: 1.6426 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00217: acc did not improve from 0.92921\n",
      "Epoch 218/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0419 - rmse: 0.0938 - acc: 0.9263 - val_loss: 0.8275 - val_rmse: 1.6540 - val_acc: 0.3620\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00218: acc did not improve from 0.92921\n",
      "Epoch 219/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0413 - rmse: 0.0937 - acc: 0.9253 - val_loss: 0.8234 - val_rmse: 1.6440 - val_acc: 0.3570\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00219: acc did not improve from 0.92921\n",
      "Epoch 220/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0950 - acc: 0.9290 - val_loss: 0.8203 - val_rmse: 1.6360 - val_acc: 0.3567\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00220: acc did not improve from 0.92921\n",
      "Epoch 221/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0422 - rmse: 0.0944 - acc: 0.9261 - val_loss: 0.8236 - val_rmse: 1.6437 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00221: acc did not improve from 0.92921\n",
      "Epoch 222/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0418 - rmse: 0.0933 - acc: 0.9273 - val_loss: 0.8231 - val_rmse: 1.6424 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00222: acc did not improve from 0.92921\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0416 - rmse: 0.0934 - acc: 0.9280 - val_loss: 0.8201 - val_rmse: 1.6331 - val_acc: 0.3618\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00223: acc did not improve from 0.92921\n",
      "Epoch 224/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0416 - rmse: 0.0931 - acc: 0.9287 - val_loss: 0.8203 - val_rmse: 1.6331 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00224: acc did not improve from 0.92921\n",
      "Epoch 225/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0415 - rmse: 0.0950 - acc: 0.9237 - val_loss: 0.8223 - val_rmse: 1.6406 - val_acc: 0.3615\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00225: acc did not improve from 0.92921\n",
      "Epoch 226/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0414 - rmse: 0.0922 - acc: 0.9241 - val_loss: 0.8257 - val_rmse: 1.6465 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00226: acc did not improve from 0.92921\n",
      "Epoch 227/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0420 - rmse: 0.0942 - acc: 0.9273 - val_loss: 0.8213 - val_rmse: 1.6393 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00227: acc did not improve from 0.92921\n",
      "Epoch 228/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0412 - rmse: 0.0926 - acc: 0.9284 - val_loss: 0.8207 - val_rmse: 1.6378 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00228: acc did not improve from 0.92921\n",
      "Epoch 229/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0420 - rmse: 0.0963 - acc: 0.9280 - val_loss: 0.8272 - val_rmse: 1.6515 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00229: acc did not improve from 0.92921\n",
      "Epoch 230/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0412 - rmse: 0.0913 - acc: 0.9299 - val_loss: 0.8222 - val_rmse: 1.6419 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00230: acc improved from 0.92921 to 0.92988, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 231/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0423 - rmse: 0.0962 - acc: 0.9244 - val_loss: 0.8222 - val_rmse: 1.6406 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00231: acc did not improve from 0.92988\n",
      "Epoch 232/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0414 - rmse: 0.0930 - acc: 0.9301 - val_loss: 0.8260 - val_rmse: 1.6497 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00232: acc improved from 0.92988 to 0.93013, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 233/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0410 - rmse: 0.0903 - acc: 0.9261 - val_loss: 0.8252 - val_rmse: 1.6456 - val_acc: 0.3634\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00233: acc did not improve from 0.93013\n",
      "Epoch 234/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0418 - rmse: 0.0939 - acc: 0.9264 - val_loss: 0.8235 - val_rmse: 1.6446 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00234: acc did not improve from 0.93013\n",
      "Epoch 235/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0414 - rmse: 0.0926 - acc: 0.9263 - val_loss: 0.8208 - val_rmse: 1.6373 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00235: acc did not improve from 0.93013\n",
      "Epoch 236/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0919 - acc: 0.9274 - val_loss: 0.8218 - val_rmse: 1.6399 - val_acc: 0.3655\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00236: acc did not improve from 0.93013\n",
      "Epoch 237/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0411 - rmse: 0.0918 - acc: 0.9260 - val_loss: 0.8283 - val_rmse: 1.6559 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00237: acc did not improve from 0.93013\n",
      "Epoch 238/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0415 - rmse: 0.0941 - acc: 0.9285 - val_loss: 0.8239 - val_rmse: 1.6460 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00238: acc did not improve from 0.93013\n",
      "Epoch 239/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0416 - rmse: 0.0937 - acc: 0.9289 - val_loss: 0.8279 - val_rmse: 1.6529 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00239: acc did not improve from 0.93013\n",
      "Epoch 240/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0413 - rmse: 0.0928 - acc: 0.9254 - val_loss: 0.8232 - val_rmse: 1.6432 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00240: acc did not improve from 0.93013\n",
      "Epoch 241/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0412 - rmse: 0.0930 - acc: 0.9303 - val_loss: 0.8238 - val_rmse: 1.6437 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00241: acc improved from 0.93013 to 0.93031, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 242/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0914 - acc: 0.9257 - val_loss: 0.8221 - val_rmse: 1.6382 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00242: acc did not improve from 0.93031\n",
      "Epoch 243/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0411 - rmse: 0.0938 - acc: 0.9247 - val_loss: 0.8248 - val_rmse: 1.6470 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00243: acc did not improve from 0.93031\n",
      "Epoch 244/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0415 - rmse: 0.0926 - acc: 0.9291 - val_loss: 0.8223 - val_rmse: 1.6415 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00244: acc did not improve from 0.93031\n",
      "Epoch 245/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0410 - rmse: 0.0909 - acc: 0.9275 - val_loss: 0.8208 - val_rmse: 1.6353 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00245: acc did not improve from 0.93031\n",
      "Epoch 246/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0418 - rmse: 0.0940 - acc: 0.9272 - val_loss: 0.8271 - val_rmse: 1.6513 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00246: acc did not improve from 0.93031\n",
      "Epoch 247/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0422 - rmse: 0.0951 - acc: 0.9267 - val_loss: 0.8246 - val_rmse: 1.6433 - val_acc: 0.3614\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00247: acc did not improve from 0.93031\n",
      "Epoch 248/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0406 - rmse: 0.0897 - acc: 0.9284 - val_loss: 0.8229 - val_rmse: 1.6433 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00248: acc did not improve from 0.93031\n",
      "Epoch 249/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0416 - rmse: 0.0930 - acc: 0.9265 - val_loss: 0.8301 - val_rmse: 1.6613 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00249: acc did not improve from 0.93031\n",
      "Epoch 250/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0926 - acc: 0.9286 - val_loss: 0.8293 - val_rmse: 1.6576 - val_acc: 0.3653\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00250: acc did not improve from 0.93031\n",
      "Epoch 251/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0414 - rmse: 0.0920 - acc: 0.9284 - val_loss: 0.8226 - val_rmse: 1.6371 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00251: acc did not improve from 0.93031\n",
      "Epoch 252/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0912 - acc: 0.9278 - val_loss: 0.8244 - val_rmse: 1.6458 - val_acc: 0.3545\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00252: acc did not improve from 0.93031\n",
      "Epoch 253/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0917 - acc: 0.9303 - val_loss: 0.8258 - val_rmse: 1.6493 - val_acc: 0.3669\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00253: acc did not improve from 0.93031\n",
      "Epoch 254/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0918 - acc: 0.9292 - val_loss: 0.8288 - val_rmse: 1.6581 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00254: acc did not improve from 0.93031\n",
      "Epoch 255/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0406 - rmse: 0.0915 - acc: 0.9270 - val_loss: 0.8209 - val_rmse: 1.6360 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00255: acc did not improve from 0.93031\n",
      "Epoch 256/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0410 - rmse: 0.0926 - acc: 0.9294 - val_loss: 0.8260 - val_rmse: 1.6521 - val_acc: 0.3657\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00256: acc did not improve from 0.93031\n",
      "Epoch 257/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0411 - rmse: 0.0917 - acc: 0.9272 - val_loss: 0.8193 - val_rmse: 1.6348 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00257: acc did not improve from 0.93031\n",
      "Epoch 258/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0411 - rmse: 0.0930 - acc: 0.9266 - val_loss: 0.8254 - val_rmse: 1.6484 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00258: acc did not improve from 0.93031\n",
      "Epoch 259/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0908 - acc: 0.9287 - val_loss: 0.8228 - val_rmse: 1.6425 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00259: acc did not improve from 0.93031\n",
      "Epoch 260/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0404 - rmse: 0.0905 - acc: 0.9298 - val_loss: 0.8296 - val_rmse: 1.6556 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00260: acc did not improve from 0.93031\n",
      "Epoch 261/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0410 - rmse: 0.0927 - acc: 0.9246 - val_loss: 0.8213 - val_rmse: 1.6396 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00261: acc did not improve from 0.93031\n",
      "Epoch 262/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0925 - acc: 0.9311 - val_loss: 0.8254 - val_rmse: 1.6507 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00262: acc improved from 0.93031 to 0.93111, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 263/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0411 - rmse: 0.0927 - acc: 0.9267 - val_loss: 0.8233 - val_rmse: 1.6421 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00263: acc did not improve from 0.93111\n",
      "Epoch 264/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0922 - acc: 0.9264 - val_loss: 0.8301 - val_rmse: 1.6602 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00264: acc did not improve from 0.93111\n",
      "Epoch 265/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0404 - rmse: 0.0906 - acc: 0.9290 - val_loss: 0.8264 - val_rmse: 1.6519 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00265: acc did not improve from 0.93111\n",
      "Epoch 266/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0921 - acc: 0.9274 - val_loss: 0.8231 - val_rmse: 1.6408 - val_acc: 0.3517\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00266: acc did not improve from 0.93111\n",
      "Epoch 267/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0920 - acc: 0.9295 - val_loss: 0.8247 - val_rmse: 1.6470 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00267: acc did not improve from 0.93111\n",
      "Epoch 268/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0919 - acc: 0.9265 - val_loss: 0.8226 - val_rmse: 1.6399 - val_acc: 0.3586\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00268: acc did not improve from 0.93111\n",
      "Epoch 269/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0905 - acc: 0.9297 - val_loss: 0.8273 - val_rmse: 1.6543 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00269: acc did not improve from 0.93111\n",
      "Epoch 270/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0404 - rmse: 0.0905 - acc: 0.9304 - val_loss: 0.8280 - val_rmse: 1.6547 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00270: acc did not improve from 0.93111\n",
      "Epoch 271/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0909 - acc: 0.9296 - val_loss: 0.8231 - val_rmse: 1.6413 - val_acc: 0.3649\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00271: acc did not improve from 0.93111\n",
      "Epoch 272/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0908 - acc: 0.9290 - val_loss: 0.8231 - val_rmse: 1.6440 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00272: acc did not improve from 0.93111\n",
      "Epoch 273/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0405 - rmse: 0.0907 - acc: 0.9269 - val_loss: 0.8295 - val_rmse: 1.6606 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00273: acc did not improve from 0.93111\n",
      "Epoch 274/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0923 - acc: 0.9292 - val_loss: 0.8183 - val_rmse: 1.6267 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00274: acc did not improve from 0.93111\n",
      "Epoch 275/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0901 - acc: 0.9286 - val_loss: 0.8277 - val_rmse: 1.6534 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00275: acc did not improve from 0.93111\n",
      "Epoch 276/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0404 - rmse: 0.0912 - acc: 0.9303 - val_loss: 0.8235 - val_rmse: 1.6436 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00276: acc did not improve from 0.93111\n",
      "Epoch 277/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0914 - acc: 0.9284 - val_loss: 0.8284 - val_rmse: 1.6565 - val_acc: 0.3561\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00277: acc did not improve from 0.93111\n",
      "Epoch 278/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0401 - rmse: 0.0907 - acc: 0.9273 - val_loss: 0.8283 - val_rmse: 1.6564 - val_acc: 0.3615\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00278: acc did not improve from 0.93111\n",
      "Epoch 279/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0404 - rmse: 0.0911 - acc: 0.9284 - val_loss: 0.8250 - val_rmse: 1.6460 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00279: acc did not improve from 0.93111\n",
      "Epoch 280/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0404 - rmse: 0.0915 - acc: 0.9307 - val_loss: 0.8258 - val_rmse: 1.6505 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00280: acc did not improve from 0.93111\n",
      "Epoch 281/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0908 - acc: 0.9306 - val_loss: 0.8269 - val_rmse: 1.6541 - val_acc: 0.3614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00281: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00281: acc did not improve from 0.93111\n",
      "Epoch 282/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0913 - acc: 0.9297 - val_loss: 0.8242 - val_rmse: 1.6451 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00282: acc did not improve from 0.93111\n",
      "Epoch 283/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0406 - rmse: 0.0906 - acc: 0.9309 - val_loss: 0.8231 - val_rmse: 1.6403 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00283: acc did not improve from 0.93111\n",
      "Epoch 284/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0919 - acc: 0.9293 - val_loss: 0.8273 - val_rmse: 1.6539 - val_acc: 0.3634\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00284: acc did not improve from 0.93111\n",
      "Epoch 285/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0406 - rmse: 0.0912 - acc: 0.9303 - val_loss: 0.8272 - val_rmse: 1.6526 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00285: acc did not improve from 0.93111\n",
      "Epoch 286/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0912 - acc: 0.9280 - val_loss: 0.8227 - val_rmse: 1.6424 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00286: acc did not improve from 0.93111\n",
      "Epoch 287/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0404 - rmse: 0.0923 - acc: 0.9304 - val_loss: 0.8219 - val_rmse: 1.6400 - val_acc: 0.3522\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00287: acc did not improve from 0.93111\n",
      "Epoch 288/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0905 - acc: 0.9309 - val_loss: 0.8253 - val_rmse: 1.6495 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00288: acc did not improve from 0.93111\n",
      "Epoch 289/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0906 - acc: 0.9242 - val_loss: 0.8266 - val_rmse: 1.6531 - val_acc: 0.3503\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00289: acc did not improve from 0.93111\n",
      "Epoch 290/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0901 - acc: 0.9282 - val_loss: 0.8253 - val_rmse: 1.6463 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00290: acc did not improve from 0.93111\n",
      "Epoch 291/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0919 - acc: 0.9245 - val_loss: 0.8269 - val_rmse: 1.6492 - val_acc: 0.3523\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00291: acc did not improve from 0.93111\n",
      "Epoch 292/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0405 - rmse: 0.0914 - acc: 0.9287 - val_loss: 0.8298 - val_rmse: 1.6621 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00292: acc did not improve from 0.93111\n",
      "Epoch 293/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0406 - rmse: 0.0908 - acc: 0.9285 - val_loss: 0.8236 - val_rmse: 1.6434 - val_acc: 0.3552\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00293: acc did not improve from 0.93111\n",
      "Epoch 294/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0405 - rmse: 0.0913 - acc: 0.9271 - val_loss: 0.8294 - val_rmse: 1.6591 - val_acc: 0.3522\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00294: acc did not improve from 0.93111\n",
      "Epoch 295/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0399 - rmse: 0.0894 - acc: 0.9291 - val_loss: 0.8287 - val_rmse: 1.6583 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00295: acc did not improve from 0.93111\n",
      "Epoch 296/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0903 - acc: 0.9289 - val_loss: 0.8288 - val_rmse: 1.6592 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00296: acc did not improve from 0.93111\n",
      "Epoch 297/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0399 - rmse: 0.0878 - acc: 0.9282 - val_loss: 0.8246 - val_rmse: 1.6465 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00297: acc did not improve from 0.93111\n",
      "Epoch 298/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0936 - acc: 0.9290 - val_loss: 0.8281 - val_rmse: 1.6588 - val_acc: 0.3598\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00298: acc did not improve from 0.93111\n",
      "Epoch 299/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0407 - rmse: 0.0909 - acc: 0.9274 - val_loss: 0.8271 - val_rmse: 1.6529 - val_acc: 0.3545\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00299: acc did not improve from 0.93111\n",
      "Epoch 300/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0408 - rmse: 0.0917 - acc: 0.9296 - val_loss: 0.8232 - val_rmse: 1.6426 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00300: acc did not improve from 0.93111\n",
      "Epoch 301/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0411 - rmse: 0.0917 - acc: 0.9284 - val_loss: 0.8245 - val_rmse: 1.6472 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00301: acc did not improve from 0.93111\n",
      "Epoch 302/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0917 - acc: 0.9284 - val_loss: 0.8261 - val_rmse: 1.6485 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00302: acc did not improve from 0.93111\n",
      "Epoch 303/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0907 - acc: 0.9296 - val_loss: 0.8295 - val_rmse: 1.6610 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00303: acc did not improve from 0.93111\n",
      "Epoch 304/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0907 - acc: 0.9311 - val_loss: 0.8303 - val_rmse: 1.6613 - val_acc: 0.3548\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00304: acc did not improve from 0.93111\n",
      "Epoch 305/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0906 - acc: 0.9288 - val_loss: 0.8251 - val_rmse: 1.6495 - val_acc: 0.3538\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00305: acc did not improve from 0.93111\n",
      "Epoch 306/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0409 - rmse: 0.0936 - acc: 0.9290 - val_loss: 0.8266 - val_rmse: 1.6538 - val_acc: 0.3563\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00306: acc did not improve from 0.93111\n",
      "Epoch 307/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0917 - acc: 0.9308 - val_loss: 0.8250 - val_rmse: 1.6472 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00307: acc did not improve from 0.93111\n",
      "Epoch 308/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0909 - acc: 0.9328 - val_loss: 0.8253 - val_rmse: 1.6518 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00308: acc improved from 0.93111 to 0.93282, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 309/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0892 - acc: 0.9299 - val_loss: 0.8275 - val_rmse: 1.6574 - val_acc: 0.3574\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00309: acc did not improve from 0.93282\n",
      "Epoch 310/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0399 - rmse: 0.0906 - acc: 0.9293 - val_loss: 0.8254 - val_rmse: 1.6503 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00310: acc did not improve from 0.93282\n",
      "Epoch 311/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0891 - acc: 0.9266 - val_loss: 0.8268 - val_rmse: 1.6526 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00311: acc did not improve from 0.93282\n",
      "Epoch 312/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0391 - rmse: 0.0880 - acc: 0.9299 - val_loss: 0.8249 - val_rmse: 1.6482 - val_acc: 0.3535\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00312: acc did not improve from 0.93282\n",
      "Epoch 313/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0395 - rmse: 0.0907 - acc: 0.9316 - val_loss: 0.8262 - val_rmse: 1.6533 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00313: acc did not improve from 0.93282\n",
      "Epoch 314/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0907 - acc: 0.9296 - val_loss: 0.8254 - val_rmse: 1.6495 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00314: acc did not improve from 0.93282\n",
      "Epoch 315/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0919 - acc: 0.9294 - val_loss: 0.8311 - val_rmse: 1.6631 - val_acc: 0.3544\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00315: acc did not improve from 0.93282\n",
      "Epoch 316/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0890 - acc: 0.9314 - val_loss: 0.8265 - val_rmse: 1.6525 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00316: acc did not improve from 0.93282\n",
      "Epoch 317/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0891 - acc: 0.9297 - val_loss: 0.8289 - val_rmse: 1.6612 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00317: acc did not improve from 0.93282\n",
      "Epoch 318/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0913 - acc: 0.9259 - val_loss: 0.8263 - val_rmse: 1.6537 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00318: acc did not improve from 0.93282\n",
      "Epoch 319/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0905 - acc: 0.9280 - val_loss: 0.8287 - val_rmse: 1.6571 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00319: acc did not improve from 0.93282\n",
      "Epoch 320/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0395 - rmse: 0.0893 - acc: 0.9306 - val_loss: 0.8297 - val_rmse: 1.6600 - val_acc: 0.3485\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00320: acc did not improve from 0.93282\n",
      "Epoch 321/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0401 - rmse: 0.0902 - acc: 0.9309 - val_loss: 0.8252 - val_rmse: 1.6476 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00321: acc did not improve from 0.93282\n",
      "Epoch 322/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0395 - rmse: 0.0882 - acc: 0.9314 - val_loss: 0.8277 - val_rmse: 1.6563 - val_acc: 0.3552\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00322: acc did not improve from 0.93282\n",
      "Epoch 323/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0401 - rmse: 0.0920 - acc: 0.9307 - val_loss: 0.8259 - val_rmse: 1.6491 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00323: acc did not improve from 0.93282\n",
      "Epoch 324/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0909 - acc: 0.9309 - val_loss: 0.8282 - val_rmse: 1.6569 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00324: acc did not improve from 0.93282\n",
      "Epoch 325/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0401 - rmse: 0.0907 - acc: 0.9276 - val_loss: 0.8261 - val_rmse: 1.6506 - val_acc: 0.3563\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00325: acc did not improve from 0.93282\n",
      "Epoch 326/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0399 - rmse: 0.0894 - acc: 0.9275 - val_loss: 0.8251 - val_rmse: 1.6495 - val_acc: 0.3618\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00326: acc did not improve from 0.93282\n",
      "Epoch 327/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0919 - acc: 0.9292 - val_loss: 0.8254 - val_rmse: 1.6515 - val_acc: 0.3598\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00327: acc did not improve from 0.93282\n",
      "Epoch 328/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0898 - acc: 0.9308 - val_loss: 0.8313 - val_rmse: 1.6644 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00328: acc did not improve from 0.93282\n",
      "Epoch 329/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0904 - acc: 0.9329 - val_loss: 0.8292 - val_rmse: 1.6590 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00329: acc improved from 0.93282 to 0.93288, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 330/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0880 - acc: 0.9282 - val_loss: 0.8207 - val_rmse: 1.6378 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00330: acc did not improve from 0.93288\n",
      "Epoch 331/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0913 - acc: 0.9318 - val_loss: 0.8292 - val_rmse: 1.6610 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00331: acc did not improve from 0.93288\n",
      "Epoch 332/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0903 - acc: 0.9267 - val_loss: 0.8302 - val_rmse: 1.6607 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00332: acc did not improve from 0.93288\n",
      "Epoch 333/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0906 - acc: 0.9300 - val_loss: 0.8228 - val_rmse: 1.6424 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00333: acc did not improve from 0.93288\n",
      "Epoch 334/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0884 - acc: 0.9302 - val_loss: 0.8274 - val_rmse: 1.6564 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00334: acc did not improve from 0.93288\n",
      "Epoch 335/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0900 - acc: 0.9281 - val_loss: 0.8240 - val_rmse: 1.6439 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00335: acc did not improve from 0.93288\n",
      "Epoch 336/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0899 - acc: 0.9292 - val_loss: 0.8281 - val_rmse: 1.6577 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00336: acc did not improve from 0.93288\n",
      "Epoch 337/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0396 - rmse: 0.0887 - acc: 0.9296 - val_loss: 0.8345 - val_rmse: 1.6710 - val_acc: 0.3649\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00337: acc did not improve from 0.93288\n",
      "Epoch 338/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0897 - acc: 0.9306 - val_loss: 0.8272 - val_rmse: 1.6532 - val_acc: 0.3647\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00338: acc did not improve from 0.93288\n",
      "Epoch 339/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0403 - rmse: 0.0914 - acc: 0.9313 - val_loss: 0.8249 - val_rmse: 1.6451 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00339: acc did not improve from 0.93288\n",
      "Epoch 340/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0897 - acc: 0.9311 - val_loss: 0.8255 - val_rmse: 1.6479 - val_acc: 0.3599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00340: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00340: acc did not improve from 0.93288\n",
      "Epoch 341/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0396 - rmse: 0.0891 - acc: 0.9328 - val_loss: 0.8240 - val_rmse: 1.6456 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00341: acc did not improve from 0.93288\n",
      "Epoch 342/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0896 - acc: 0.9295 - val_loss: 0.8289 - val_rmse: 1.6576 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00342: acc did not improve from 0.93288\n",
      "Epoch 343/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0877 - acc: 0.9279 - val_loss: 0.8262 - val_rmse: 1.6535 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00343: acc did not improve from 0.93288\n",
      "Epoch 344/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0396 - rmse: 0.0901 - acc: 0.9320 - val_loss: 0.8253 - val_rmse: 1.6472 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00344: acc did not improve from 0.93288\n",
      "Epoch 345/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0901 - acc: 0.9276 - val_loss: 0.8249 - val_rmse: 1.6489 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00345: acc did not improve from 0.93288\n",
      "Epoch 346/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0898 - acc: 0.9296 - val_loss: 0.8273 - val_rmse: 1.6531 - val_acc: 0.3586\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00346: acc did not improve from 0.93288\n",
      "Epoch 347/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0908 - acc: 0.9295 - val_loss: 0.8320 - val_rmse: 1.6667 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00347: acc did not improve from 0.93288\n",
      "Epoch 348/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0924 - acc: 0.9316 - val_loss: 0.8259 - val_rmse: 1.6498 - val_acc: 0.3570\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00348: acc did not improve from 0.93288\n",
      "Epoch 349/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0400 - rmse: 0.0904 - acc: 0.9277 - val_loss: 0.8267 - val_rmse: 1.6551 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00349: acc did not improve from 0.93288\n",
      "Epoch 350/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0395 - rmse: 0.0896 - acc: 0.9299 - val_loss: 0.8291 - val_rmse: 1.6570 - val_acc: 0.3574\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00350: acc did not improve from 0.93288\n",
      "Epoch 351/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0902 - acc: 0.9314 - val_loss: 0.8279 - val_rmse: 1.6547 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00351: acc did not improve from 0.93288\n",
      "Epoch 352/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0396 - rmse: 0.0890 - acc: 0.9290 - val_loss: 0.8230 - val_rmse: 1.6414 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00352: acc did not improve from 0.93288\n",
      "Epoch 353/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0893 - acc: 0.9336 - val_loss: 0.8295 - val_rmse: 1.6575 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00353: acc improved from 0.93288 to 0.93356, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 354/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0399 - rmse: 0.0900 - acc: 0.9318 - val_loss: 0.8282 - val_rmse: 1.6577 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00354: acc did not improve from 0.93356\n",
      "Epoch 355/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0902 - acc: 0.9302 - val_loss: 0.8228 - val_rmse: 1.6396 - val_acc: 0.3579\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00355: acc did not improve from 0.93356\n",
      "Epoch 356/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0896 - acc: 0.9308 - val_loss: 0.8267 - val_rmse: 1.6523 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00356: acc did not improve from 0.93356\n",
      "Epoch 357/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0392 - rmse: 0.0881 - acc: 0.9299 - val_loss: 0.8342 - val_rmse: 1.6731 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00357: acc did not improve from 0.93356\n",
      "Epoch 358/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0883 - acc: 0.9306 - val_loss: 0.8319 - val_rmse: 1.6660 - val_acc: 0.3579\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00358: acc did not improve from 0.93356\n",
      "Epoch 359/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0872 - acc: 0.9266 - val_loss: 0.8243 - val_rmse: 1.6460 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00359: acc did not improve from 0.93356\n",
      "Epoch 360/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0391 - rmse: 0.0872 - acc: 0.9295 - val_loss: 0.8268 - val_rmse: 1.6559 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00360: acc did not improve from 0.93356\n",
      "Epoch 361/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0395 - rmse: 0.0891 - acc: 0.9318 - val_loss: 0.8313 - val_rmse: 1.6637 - val_acc: 0.3574\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00361: acc did not improve from 0.93356\n",
      "Epoch 362/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0883 - acc: 0.9296 - val_loss: 0.8291 - val_rmse: 1.6585 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00362: acc did not improve from 0.93356\n",
      "Epoch 363/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0890 - acc: 0.9329 - val_loss: 0.8265 - val_rmse: 1.6507 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00363: acc did not improve from 0.93356\n",
      "Epoch 364/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0866 - acc: 0.9305 - val_loss: 0.8287 - val_rmse: 1.6552 - val_acc: 0.3647\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00364: acc did not improve from 0.93356\n",
      "Epoch 365/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0396 - rmse: 0.0876 - acc: 0.9279 - val_loss: 0.8305 - val_rmse: 1.6625 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00365: acc did not improve from 0.93356\n",
      "Epoch 366/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0883 - acc: 0.9303 - val_loss: 0.8272 - val_rmse: 1.6540 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00366: acc did not improve from 0.93356\n",
      "Epoch 367/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0883 - acc: 0.9295 - val_loss: 0.8299 - val_rmse: 1.6621 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00367: acc did not improve from 0.93356\n",
      "Epoch 368/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0879 - acc: 0.9317 - val_loss: 0.8279 - val_rmse: 1.6567 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00368: acc did not improve from 0.93356\n",
      "Epoch 369/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0914 - acc: 0.9310 - val_loss: 0.8235 - val_rmse: 1.6451 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00369: acc did not improve from 0.93356\n",
      "Epoch 370/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0892 - acc: 0.9297 - val_loss: 0.8317 - val_rmse: 1.6680 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00370: acc did not improve from 0.93356\n",
      "Epoch 371/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0392 - rmse: 0.0895 - acc: 0.9306 - val_loss: 0.8320 - val_rmse: 1.6697 - val_acc: 0.3644\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00371: acc did not improve from 0.93356\n",
      "Epoch 372/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0885 - acc: 0.9337 - val_loss: 0.8279 - val_rmse: 1.6545 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00372: acc improved from 0.93356 to 0.93368, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 373/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0903 - acc: 0.9285 - val_loss: 0.8272 - val_rmse: 1.6573 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00373: acc did not improve from 0.93368\n",
      "Epoch 374/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0896 - acc: 0.9290 - val_loss: 0.8257 - val_rmse: 1.6511 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00374: acc did not improve from 0.93368\n",
      "Epoch 375/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0386 - rmse: 0.0875 - acc: 0.9298 - val_loss: 0.8252 - val_rmse: 1.6504 - val_acc: 0.3595\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00375: acc did not improve from 0.93368\n",
      "Epoch 376/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0392 - rmse: 0.0885 - acc: 0.9290 - val_loss: 0.8255 - val_rmse: 1.6494 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00376: acc did not improve from 0.93368\n",
      "Epoch 377/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0873 - acc: 0.9315 - val_loss: 0.8297 - val_rmse: 1.6613 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00377: acc did not improve from 0.93368\n",
      "Epoch 378/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0388 - rmse: 0.0884 - acc: 0.9314 - val_loss: 0.8296 - val_rmse: 1.6628 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00378: acc did not improve from 0.93368\n",
      "Epoch 379/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0907 - acc: 0.9299 - val_loss: 0.8276 - val_rmse: 1.6583 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00379: acc did not improve from 0.93368\n",
      "Epoch 380/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0388 - rmse: 0.0876 - acc: 0.9321 - val_loss: 0.8299 - val_rmse: 1.6632 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00380: acc did not improve from 0.93368\n",
      "Epoch 381/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0903 - acc: 0.9290 - val_loss: 0.8271 - val_rmse: 1.6550 - val_acc: 0.3544\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00381: acc did not improve from 0.93368\n",
      "Epoch 382/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0889 - acc: 0.9301 - val_loss: 0.8267 - val_rmse: 1.6503 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00382: acc did not improve from 0.93368\n",
      "Epoch 383/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0896 - acc: 0.9306 - val_loss: 0.8281 - val_rmse: 1.6576 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00383: acc did not improve from 0.93368\n",
      "Epoch 384/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0395 - rmse: 0.0900 - acc: 0.9288 - val_loss: 0.8249 - val_rmse: 1.6499 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00384: acc did not improve from 0.93368\n",
      "Epoch 385/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0388 - rmse: 0.0882 - acc: 0.9284 - val_loss: 0.8244 - val_rmse: 1.6478 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00385: acc did not improve from 0.93368\n",
      "Epoch 386/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0396 - rmse: 0.0885 - acc: 0.9296 - val_loss: 0.8285 - val_rmse: 1.6578 - val_acc: 0.3614\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00386: acc did not improve from 0.93368\n",
      "Epoch 387/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0893 - acc: 0.9309 - val_loss: 0.8245 - val_rmse: 1.6491 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00387: acc did not improve from 0.93368\n",
      "Epoch 388/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0392 - rmse: 0.0897 - acc: 0.9325 - val_loss: 0.8263 - val_rmse: 1.6514 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00388: acc did not improve from 0.93368\n",
      "Epoch 389/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0402 - rmse: 0.0911 - acc: 0.9328 - val_loss: 0.8284 - val_rmse: 1.6584 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00389: acc did not improve from 0.93368\n",
      "Epoch 390/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0891 - acc: 0.9317 - val_loss: 0.8271 - val_rmse: 1.6557 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00390: acc did not improve from 0.93368\n",
      "Epoch 391/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0398 - rmse: 0.0904 - acc: 0.9304 - val_loss: 0.8331 - val_rmse: 1.6694 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00391: acc did not improve from 0.93368\n",
      "Epoch 392/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0880 - acc: 0.9279 - val_loss: 0.8280 - val_rmse: 1.6541 - val_acc: 0.3602\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00392: acc did not improve from 0.93368\n",
      "Epoch 393/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0388 - rmse: 0.0880 - acc: 0.9312 - val_loss: 0.8287 - val_rmse: 1.6598 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00393: acc did not improve from 0.93368\n",
      "Epoch 394/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0890 - acc: 0.9328 - val_loss: 0.8261 - val_rmse: 1.6533 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00394: acc did not improve from 0.93368\n",
      "Epoch 395/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0881 - acc: 0.9329 - val_loss: 0.8261 - val_rmse: 1.6518 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00395: acc did not improve from 0.93368\n",
      "Epoch 396/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0867 - acc: 0.9292 - val_loss: 0.8277 - val_rmse: 1.6594 - val_acc: 0.3653\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00396: acc did not improve from 0.93368\n",
      "Epoch 397/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0392 - rmse: 0.0894 - acc: 0.9324 - val_loss: 0.8318 - val_rmse: 1.6696 - val_acc: 0.3644\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00397: acc did not improve from 0.93368\n",
      "Epoch 398/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0870 - acc: 0.9310 - val_loss: 0.8337 - val_rmse: 1.6709 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00398: acc did not improve from 0.93368\n",
      "Epoch 399/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0899 - acc: 0.9306 - val_loss: 0.8317 - val_rmse: 1.6655 - val_acc: 0.3633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00399: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00399: acc did not improve from 0.93368\n",
      "Epoch 400/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0891 - acc: 0.9299 - val_loss: 0.8286 - val_rmse: 1.6605 - val_acc: 0.3620\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00400: acc did not improve from 0.93368\n",
      "Epoch 401/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0396 - rmse: 0.0905 - acc: 0.9287 - val_loss: 0.8271 - val_rmse: 1.6542 - val_acc: 0.3574\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00401: acc did not improve from 0.93368\n",
      "Epoch 402/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0395 - rmse: 0.0897 - acc: 0.9292 - val_loss: 0.8291 - val_rmse: 1.6599 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00402: acc did not improve from 0.93368\n",
      "Epoch 403/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0883 - acc: 0.9279 - val_loss: 0.8258 - val_rmse: 1.6525 - val_acc: 0.3615\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00403: acc did not improve from 0.93368\n",
      "Epoch 404/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0893 - acc: 0.9329 - val_loss: 0.8296 - val_rmse: 1.6598 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00404: acc did not improve from 0.93368\n",
      "Epoch 405/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0386 - rmse: 0.0861 - acc: 0.9285 - val_loss: 0.8360 - val_rmse: 1.6805 - val_acc: 0.3666\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00405: acc did not improve from 0.93368\n",
      "Epoch 406/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0869 - acc: 0.9327 - val_loss: 0.8307 - val_rmse: 1.6647 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00406: acc did not improve from 0.93368\n",
      "Epoch 407/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0388 - rmse: 0.0888 - acc: 0.9350 - val_loss: 0.8341 - val_rmse: 1.6735 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00407: acc improved from 0.93368 to 0.93503, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 408/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0898 - acc: 0.9321 - val_loss: 0.8315 - val_rmse: 1.6664 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00408: acc did not improve from 0.93503\n",
      "Epoch 409/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0873 - acc: 0.9306 - val_loss: 0.8270 - val_rmse: 1.6539 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00409: acc did not improve from 0.93503\n",
      "Epoch 410/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0386 - rmse: 0.0876 - acc: 0.9291 - val_loss: 0.8321 - val_rmse: 1.6695 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00410: acc did not improve from 0.93503\n",
      "Epoch 411/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0381 - rmse: 0.0854 - acc: 0.9294 - val_loss: 0.8300 - val_rmse: 1.6615 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00411: acc did not improve from 0.93503\n",
      "Epoch 412/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0387 - rmse: 0.0876 - acc: 0.9307 - val_loss: 0.8303 - val_rmse: 1.6629 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00412: acc did not improve from 0.93503\n",
      "Epoch 413/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0870 - acc: 0.9305 - val_loss: 0.8383 - val_rmse: 1.6822 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00413: acc did not improve from 0.93503\n",
      "Epoch 414/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0871 - acc: 0.9334 - val_loss: 0.8279 - val_rmse: 1.6548 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00414: acc did not improve from 0.93503\n",
      "Epoch 415/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0385 - rmse: 0.0872 - acc: 0.9288 - val_loss: 0.8308 - val_rmse: 1.6639 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00415: acc did not improve from 0.93503\n",
      "Epoch 416/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0886 - acc: 0.9329 - val_loss: 0.8329 - val_rmse: 1.6703 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00416: acc did not improve from 0.93503\n",
      "Epoch 417/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0397 - rmse: 0.0909 - acc: 0.9282 - val_loss: 0.8267 - val_rmse: 1.6514 - val_acc: 0.3554\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00417: acc did not improve from 0.93503\n",
      "Epoch 418/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0882 - acc: 0.9310 - val_loss: 0.8315 - val_rmse: 1.6621 - val_acc: 0.3614\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00418: acc did not improve from 0.93503\n",
      "Epoch 419/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0890 - acc: 0.9321 - val_loss: 0.8300 - val_rmse: 1.6612 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00419: acc did not improve from 0.93503\n",
      "Epoch 420/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0855 - acc: 0.9321 - val_loss: 0.8264 - val_rmse: 1.6513 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00420: acc did not improve from 0.93503\n",
      "Epoch 421/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0375 - rmse: 0.0836 - acc: 0.9333 - val_loss: 0.8319 - val_rmse: 1.6668 - val_acc: 0.3609\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00421: acc did not improve from 0.93503\n",
      "Epoch 422/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0387 - rmse: 0.0874 - acc: 0.9318 - val_loss: 0.8272 - val_rmse: 1.6536 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00422: acc did not improve from 0.93503\n",
      "Epoch 423/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0394 - rmse: 0.0904 - acc: 0.9312 - val_loss: 0.8301 - val_rmse: 1.6612 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00423: acc did not improve from 0.93503\n",
      "Epoch 424/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0879 - acc: 0.9293 - val_loss: 0.8284 - val_rmse: 1.6568 - val_acc: 0.3550\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00424: acc did not improve from 0.93503\n",
      "Epoch 425/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0387 - rmse: 0.0876 - acc: 0.9305 - val_loss: 0.8330 - val_rmse: 1.6695 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00425: acc did not improve from 0.93503\n",
      "Epoch 426/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0388 - rmse: 0.0887 - acc: 0.9320 - val_loss: 0.8291 - val_rmse: 1.6585 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00426: acc did not improve from 0.93503\n",
      "Epoch 427/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0381 - rmse: 0.0853 - acc: 0.9345 - val_loss: 0.8303 - val_rmse: 1.6619 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00427: acc did not improve from 0.93503\n",
      "Epoch 428/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0385 - rmse: 0.0866 - acc: 0.9333 - val_loss: 0.8307 - val_rmse: 1.6625 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00428: acc did not improve from 0.93503\n",
      "Epoch 429/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0387 - rmse: 0.0875 - acc: 0.9337 - val_loss: 0.8273 - val_rmse: 1.6544 - val_acc: 0.3649\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00429: acc did not improve from 0.93503\n",
      "Epoch 430/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0393 - rmse: 0.0898 - acc: 0.9315 - val_loss: 0.8270 - val_rmse: 1.6526 - val_acc: 0.3589\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00430: acc did not improve from 0.93503\n",
      "Epoch 431/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0385 - rmse: 0.0855 - acc: 0.9294 - val_loss: 0.8270 - val_rmse: 1.6516 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00431: acc did not improve from 0.93503\n",
      "Epoch 432/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0380 - rmse: 0.0853 - acc: 0.9330 - val_loss: 0.8336 - val_rmse: 1.6721 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00432: acc did not improve from 0.93503\n",
      "Epoch 433/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0386 - rmse: 0.0872 - acc: 0.9303 - val_loss: 0.8296 - val_rmse: 1.6607 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00433: acc did not improve from 0.93503\n",
      "Epoch 434/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0385 - rmse: 0.0884 - acc: 0.9332 - val_loss: 0.8300 - val_rmse: 1.6611 - val_acc: 0.3666\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00434: acc did not improve from 0.93503\n",
      "Epoch 435/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0390 - rmse: 0.0895 - acc: 0.9352 - val_loss: 0.8299 - val_rmse: 1.6619 - val_acc: 0.3634\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00435: acc improved from 0.93503 to 0.93515, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 436/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0386 - rmse: 0.0873 - acc: 0.9310 - val_loss: 0.8334 - val_rmse: 1.6688 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00436: acc did not improve from 0.93515\n",
      "Epoch 437/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0381 - rmse: 0.0850 - acc: 0.9340 - val_loss: 0.8269 - val_rmse: 1.6512 - val_acc: 0.3672\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00437: acc did not improve from 0.93515\n",
      "Epoch 438/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0382 - rmse: 0.0864 - acc: 0.9310 - val_loss: 0.8297 - val_rmse: 1.6595 - val_acc: 0.3668\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00438: acc did not improve from 0.93515\n",
      "Epoch 439/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0387 - rmse: 0.0884 - acc: 0.9326 - val_loss: 0.8302 - val_rmse: 1.6608 - val_acc: 0.3647\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00439: acc did not improve from 0.93515\n",
      "Epoch 440/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0383 - rmse: 0.0857 - acc: 0.9337 - val_loss: 0.8367 - val_rmse: 1.6791 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00440: acc did not improve from 0.93515\n",
      "Epoch 441/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0391 - rmse: 0.0896 - acc: 0.9309 - val_loss: 0.8265 - val_rmse: 1.6502 - val_acc: 0.3614\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00441: acc did not improve from 0.93515\n",
      "Epoch 442/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0381 - rmse: 0.0854 - acc: 0.9343 - val_loss: 0.8290 - val_rmse: 1.6582 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00442: acc did not improve from 0.93515\n",
      "Epoch 443/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0379 - rmse: 0.0852 - acc: 0.9311 - val_loss: 0.8338 - val_rmse: 1.6723 - val_acc: 0.3656\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00443: acc did not improve from 0.93515\n",
      "Epoch 444/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0391 - rmse: 0.0884 - acc: 0.9318 - val_loss: 0.8356 - val_rmse: 1.6774 - val_acc: 0.3681\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00444: acc did not improve from 0.93515\n",
      "Epoch 445/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0382 - rmse: 0.0873 - acc: 0.9287 - val_loss: 0.8261 - val_rmse: 1.6493 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00445: acc did not improve from 0.93515\n",
      "Epoch 446/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0869 - acc: 0.9324 - val_loss: 0.8313 - val_rmse: 1.6647 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00446: acc did not improve from 0.93515\n",
      "Epoch 447/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0386 - rmse: 0.0872 - acc: 0.9325 - val_loss: 0.8317 - val_rmse: 1.6670 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00447: acc did not improve from 0.93515\n",
      "Epoch 448/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0380 - rmse: 0.0857 - acc: 0.9299 - val_loss: 0.8324 - val_rmse: 1.6650 - val_acc: 0.3653\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00448: acc did not improve from 0.93515\n",
      "Epoch 449/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0382 - rmse: 0.0861 - acc: 0.9331 - val_loss: 0.8326 - val_rmse: 1.6666 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00449: acc did not improve from 0.93515\n",
      "Epoch 450/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0872 - acc: 0.9296 - val_loss: 0.8318 - val_rmse: 1.6658 - val_acc: 0.3647\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00450: acc did not improve from 0.93515\n",
      "Epoch 451/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0853 - acc: 0.9303 - val_loss: 0.8341 - val_rmse: 1.6723 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00451: acc did not improve from 0.93515\n",
      "Epoch 452/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0387 - rmse: 0.0873 - acc: 0.9299 - val_loss: 0.8243 - val_rmse: 1.6468 - val_acc: 0.3656\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00452: acc did not improve from 0.93515\n",
      "Epoch 453/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0381 - rmse: 0.0864 - acc: 0.9323 - val_loss: 0.8289 - val_rmse: 1.6591 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00453: acc did not improve from 0.93515\n",
      "Epoch 454/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0389 - rmse: 0.0884 - acc: 0.9318 - val_loss: 0.8309 - val_rmse: 1.6628 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00454: acc did not improve from 0.93515\n",
      "Epoch 455/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0385 - rmse: 0.0867 - acc: 0.9315 - val_loss: 0.8260 - val_rmse: 1.6483 - val_acc: 0.3621\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00455: acc did not improve from 0.93515\n",
      "Epoch 456/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0393 - rmse: 0.0897 - acc: 0.9320 - val_loss: 0.8267 - val_rmse: 1.6532 - val_acc: 0.3685\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00456: acc did not improve from 0.93515\n",
      "Epoch 457/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0384 - rmse: 0.0880 - acc: 0.9349 - val_loss: 0.8359 - val_rmse: 1.6772 - val_acc: 0.3653\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00457: acc did not improve from 0.93515\n",
      "Epoch 458/1000\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.0379 - rmse: 0.0848 - acc: 0.9325 - val_loss: 0.8273 - val_rmse: 1.6521 - val_acc: 0.3606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00458: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00458: acc did not improve from 0.93515\n",
      "Epoch 459/1000\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.0390 - rmse: 0.0885 - acc: 0.9328 - val_loss: 0.8303 - val_rmse: 1.6599 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00459: acc did not improve from 0.93515\n",
      "Epoch 460/1000\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.0388 - rmse: 0.0868 - acc: 0.9301 - val_loss: 0.8297 - val_rmse: 1.6593 - val_acc: 0.3668\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00460: acc did not improve from 0.93515\n",
      "Epoch 461/1000\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.0380 - rmse: 0.0856 - acc: 0.9313 - val_loss: 0.8291 - val_rmse: 1.6580 - val_acc: 0.3666\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00461: acc did not improve from 0.93515\n",
      "Epoch 462/1000\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.0384 - rmse: 0.0861 - acc: 0.9329 - val_loss: 0.8302 - val_rmse: 1.6623 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00462: acc did not improve from 0.93515\n",
      "Epoch 463/1000\n",
      "16330/16330 [==============================] - 50s 3ms/step - loss: 0.0383 - rmse: 0.0867 - acc: 0.9353 - val_loss: 0.8339 - val_rmse: 1.6706 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00463: acc improved from 0.93515 to 0.93527, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 464/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0385 - rmse: 0.0856 - acc: 0.9314 - val_loss: 0.8321 - val_rmse: 1.6663 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00464: acc did not improve from 0.93527\n",
      "Epoch 465/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0387 - rmse: 0.0875 - acc: 0.9315 - val_loss: 0.8311 - val_rmse: 1.6632 - val_acc: 0.3668\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00465: acc did not improve from 0.93527\n",
      "Epoch 466/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0381 - rmse: 0.0848 - acc: 0.9299 - val_loss: 0.8323 - val_rmse: 1.6684 - val_acc: 0.3633\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00466: acc did not improve from 0.93527\n",
      "Epoch 467/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0382 - rmse: 0.0874 - acc: 0.9315 - val_loss: 0.8302 - val_rmse: 1.6630 - val_acc: 0.3713\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00467: acc did not improve from 0.93527\n",
      "Epoch 468/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0384 - rmse: 0.0876 - acc: 0.9356 - val_loss: 0.8283 - val_rmse: 1.6566 - val_acc: 0.3671\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00468: acc improved from 0.93527 to 0.93558, saving model to D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/weights.best.by.accuracy.hdf5\n",
      "Epoch 469/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0376 - rmse: 0.0841 - acc: 0.9310 - val_loss: 0.8256 - val_rmse: 1.6509 - val_acc: 0.3671\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00469: acc did not improve from 0.93558\n",
      "Epoch 470/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0381 - rmse: 0.0867 - acc: 0.9348 - val_loss: 0.8305 - val_rmse: 1.6597 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00470: acc did not improve from 0.93558\n",
      "Epoch 471/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0382 - rmse: 0.0872 - acc: 0.9299 - val_loss: 0.8298 - val_rmse: 1.6602 - val_acc: 0.3592\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00471: acc did not improve from 0.93558\n",
      "Epoch 472/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0379 - rmse: 0.0861 - acc: 0.9332 - val_loss: 0.8284 - val_rmse: 1.6574 - val_acc: 0.3684\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00472: acc did not improve from 0.93558\n",
      "Epoch 473/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0380 - rmse: 0.0851 - acc: 0.9290 - val_loss: 0.8326 - val_rmse: 1.6697 - val_acc: 0.3628\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00473: acc did not improve from 0.93558\n",
      "Epoch 474/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0381 - rmse: 0.0855 - acc: 0.9320 - val_loss: 0.8280 - val_rmse: 1.6566 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00474: acc did not improve from 0.93558\n",
      "Epoch 475/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0385 - rmse: 0.0879 - acc: 0.9334 - val_loss: 0.8300 - val_rmse: 1.6607 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00475: acc did not improve from 0.93558\n",
      "Epoch 476/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0386 - rmse: 0.0879 - acc: 0.9345 - val_loss: 0.8322 - val_rmse: 1.6662 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00476: acc did not improve from 0.93558\n",
      "Epoch 477/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0377 - rmse: 0.0858 - acc: 0.9317 - val_loss: 0.8227 - val_rmse: 1.6403 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00477: acc did not improve from 0.93558\n",
      "Epoch 478/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0389 - rmse: 0.0875 - acc: 0.9280 - val_loss: 0.8319 - val_rmse: 1.6673 - val_acc: 0.3668\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00478: acc did not improve from 0.93558\n",
      "Epoch 479/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0381 - rmse: 0.0856 - acc: 0.9324 - val_loss: 0.8311 - val_rmse: 1.6630 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00479: acc did not improve from 0.93558\n",
      "Epoch 480/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0385 - rmse: 0.0886 - acc: 0.9304 - val_loss: 0.8292 - val_rmse: 1.6605 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00480: acc did not improve from 0.93558\n",
      "Epoch 481/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0383 - rmse: 0.0878 - acc: 0.9328 - val_loss: 0.8254 - val_rmse: 1.6467 - val_acc: 0.3662\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00481: acc did not improve from 0.93558\n",
      "Epoch 482/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0381 - rmse: 0.0857 - acc: 0.9321 - val_loss: 0.8344 - val_rmse: 1.6731 - val_acc: 0.3598\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00482: acc did not improve from 0.93558\n",
      "Epoch 483/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0385 - rmse: 0.0890 - acc: 0.9331 - val_loss: 0.8342 - val_rmse: 1.6707 - val_acc: 0.3655\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00483: acc did not improve from 0.93558\n",
      "Epoch 484/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0376 - rmse: 0.0867 - acc: 0.9334 - val_loss: 0.8358 - val_rmse: 1.6752 - val_acc: 0.3643\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00484: acc did not improve from 0.93558\n",
      "Epoch 485/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0383 - rmse: 0.0871 - acc: 0.9305 - val_loss: 0.8302 - val_rmse: 1.6609 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00485: acc did not improve from 0.93558\n",
      "Epoch 486/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0874 - acc: 0.9325 - val_loss: 0.8285 - val_rmse: 1.6557 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00486: acc did not improve from 0.93558\n",
      "Epoch 487/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0381 - rmse: 0.0874 - acc: 0.9311 - val_loss: 0.8303 - val_rmse: 1.6628 - val_acc: 0.3586\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00487: acc did not improve from 0.93558\n",
      "Epoch 488/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0385 - rmse: 0.0869 - acc: 0.9326 - val_loss: 0.8356 - val_rmse: 1.6749 - val_acc: 0.3583\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00488: acc did not improve from 0.93558\n",
      "Epoch 489/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0384 - rmse: 0.0862 - acc: 0.9346 - val_loss: 0.8293 - val_rmse: 1.6575 - val_acc: 0.3656\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00489: acc did not improve from 0.93558\n",
      "Epoch 490/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0380 - rmse: 0.0847 - acc: 0.9307 - val_loss: 0.8326 - val_rmse: 1.6692 - val_acc: 0.3647\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00490: acc did not improve from 0.93558\n",
      "Epoch 491/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0384 - rmse: 0.0868 - acc: 0.9328 - val_loss: 0.8307 - val_rmse: 1.6651 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00491: acc did not improve from 0.93558\n",
      "Epoch 492/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0383 - rmse: 0.0895 - acc: 0.9313 - val_loss: 0.8300 - val_rmse: 1.6608 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00492: acc did not improve from 0.93558\n",
      "Epoch 493/1000\n",
      "16330/16330 [==============================] - 48s 3ms/step - loss: 0.0378 - rmse: 0.0861 - acc: 0.9333 - val_loss: 0.8316 - val_rmse: 1.6665 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00493: acc did not improve from 0.93558\n",
      "Epoch 494/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0378 - rmse: 0.0859 - acc: 0.9322 - val_loss: 0.8365 - val_rmse: 1.6781 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00494: acc did not improve from 0.93558\n",
      "Epoch 495/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0378 - rmse: 0.0844 - acc: 0.9310 - val_loss: 0.8334 - val_rmse: 1.6715 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00495: acc did not improve from 0.93558\n",
      "Epoch 496/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0380 - rmse: 0.0861 - acc: 0.9326 - val_loss: 0.8318 - val_rmse: 1.6673 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00496: acc did not improve from 0.93558\n",
      "Epoch 497/1000\n",
      "16330/16330 [==============================] - 49s 3ms/step - loss: 0.0382 - rmse: 0.0867 - acc: 0.9334 - val_loss: 0.8335 - val_rmse: 1.6728 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.79738\n",
      "\n",
      "Epoch 00497: acc did not improve from 0.93558\n",
      "Epoch 498/1000\n",
      " 8352/16330 [==============>...............] - ETA: 22s - loss: 0.0386 - rmse: 0.0898 - acc: 0.9326"
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthSiameseVO/model/same-1000-epochs/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthSiameseVO/same-1000-epochs/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando quaternion\n",
    "\n",
    "## Training pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 -0.001i +0.001j +0.000k\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-e37c15a88061>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mquaternion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQuaternion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquaternion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mT_aux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquaternion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mT_train_quaternion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT_aux\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "from pyquaternion import Quaternion\n",
    "\n",
    "T_train_quaternion = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_training_0[name], label_training_1[name]):\n",
    "        transformation = pose_0.dot(np.linalg.inv(pose_1))\n",
    "        t_aux = transformation[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        quaternion = np.array(Quaternion(matrix=transformation))\n",
    "        print(quaternion)\n",
    "        T_aux.append(np.concatenate((quaternion, t),1))\n",
    "    \n",
    "        T_train_quaternion[name] = T_aux    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_poses_transformed_quaternion = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "  \n",
    "    for pose in T_train_quaternion[sequence]:\n",
    "        training_poses_transformed_quaternion.append(pose)\n",
    "\n",
    "print(\"Training > size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(training_r), len(training_l), len(training_poses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_test_quaternion = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_test_0[name], label_test_1[name]):\n",
    "        transformation = pose_0.dot(np.linalg.inv(pose_1))\n",
    "        t_aux = transformation[0:3, 3]        \n",
    "        t = np.zeros((1,3))\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            t[0, i] = t_aux[i]\n",
    "            cont += 1\n",
    "            \n",
    "        quaternion = np.array(Quaternion(matrix=transformation))\n",
    "        \n",
    "        T_aux.append(np.concatenate((quaternion, t),1))\n",
    "    \n",
    "    T_test_quaternion[name] = T_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_poses_transformed_quaternion = []\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for pose in T_test_quaternion[sequence]:\n",
    "            test_poses_transformed_quaternion.append(pose)\n",
    "    \n",
    "print(\"Test > Size right: %s, size left: %s, size label: %s\"%\n",
    "      (len(test_r), len(test_l), len(test_poses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_training = np.reshape(training_poses_transformed_quaternion, (len(training_poses), 6))\n",
    "y_test = np.reshape(test_poses_transformed_quaternion, (len(test_poses), 6))\n",
    "print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 8704)         92672       input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 8704)         0           sequential_5[1][0]               \n",
      "                                                                 sequential_5[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2048)         17827840    lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 2048)         0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2048)         4196352     leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 2048)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 7)            14343       leaky_re_lu_29[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 22,131,207\n",
      "Trainable params: 22,131,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(LeakyReLU(alpha=0.6))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(LeakyReLU(alpha=0.6))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(LeakyReLU(alpha=0.6))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(LeakyReLU(alpha=0.6))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(2048, kernel_initializer='normal')(abs_diff)\n",
    "activation1 = LeakyReLU(alpha=0.6)(dense_layer)\n",
    "#dense_layer1 = Dense(2048, kernel_initializer='normal')(activation1)\n",
    "#activation2 = LeakyReLU(alpha=0.5)(dense_layer1)\n",
    "dense_layer2 = Dense(2048, kernel_initializer='normal')(activation1)\n",
    "activation3 = LeakyReLU(alpha=0.2)(dense_layer2)\n",
    "output = Dense(7, name='predictions', kernel_initializer='normal')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vo_loss2(y_true, y_pred):\n",
    "    loss_value = vo_loss(y_true, y_pred)*100    \n",
    "    return loss_value\n",
    "\n",
    "learning_rate = 0.0001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthSiameseVO/model/3/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [16,6] vs. [16,7]\n\t [[Node: metrics_9/rmse/sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_predictions_target_9_0_3/_1799, predictions_4/BiasAdd)]]\n\t [[Node: metrics_9/rmse/Mean_1/_1949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1308_metrics_9/rmse/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'metrics_9/rmse/sub', defined at:\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-177a879736f4>\", line 7, in <module>\n    model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 936, in compile\n    handle_metrics(output_metrics)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 914, in handle_metrics\n    mask=masks[i])\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"D:\\KITTI\\DepthSiameseVO\\objectives\\VoObjectives.py\", line 7, in rmse\n    rmse = K.sqrt(K.mean(K.square((y_true - y_pred))))\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 979, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 8582, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [16,6] vs. [16,7]\n\t [[Node: metrics_9/rmse/sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_predictions_target_9_0_3/_1799, predictions_4/BiasAdd)]]\n\t [[Node: metrics_9/rmse/Mean_1/_1949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1308_metrics_9/rmse/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [16,6] vs. [16,7]\n\t [[Node: metrics_9/rmse/sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_predictions_target_9_0_3/_1799, predictions_4/BiasAdd)]]\n\t [[Node: metrics_9/rmse/Mean_1/_1949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1308_metrics_9/rmse/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-8d449695d995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n\u001b[1;32m---> 18\u001b[1;33m                              validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [16,6] vs. [16,7]\n\t [[Node: metrics_9/rmse/sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_predictions_target_9_0_3/_1799, predictions_4/BiasAdd)]]\n\t [[Node: metrics_9/rmse/Mean_1/_1949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1308_metrics_9/rmse/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'metrics_9/rmse/sub', defined at:\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-177a879736f4>\", line 7, in <module>\n    model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 936, in compile\n    handle_metrics(output_metrics)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 914, in handle_metrics\n    mask=masks[i])\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"D:\\KITTI\\DepthSiameseVO\\objectives\\VoObjectives.py\", line 7, in rmse\n    rmse = K.sqrt(K.mean(K.square((y_true - y_pred))))\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 979, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 8582, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\vinic\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [16,6] vs. [16,7]\n\t [[Node: metrics_9/rmse/sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_predictions_target_9_0_3/_1799, predictions_4/BiasAdd)]]\n\t [[Node: metrics_9/rmse/Mean_1/_1949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1308_metrics_9/rmse/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthSiameseVO/model/3/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthSiameseVO/3/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudar a função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vo_loss_mod(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]* 0.3\n",
    "    mean_rot = mean[:, 0:3] * 150\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "learning_rate = 0.0001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthSiameseVO/model/4/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthSiameseVO/4/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/3/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/3/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/3/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "    \n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/3/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/3/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/3/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/4/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/4/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/4/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "    \n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthSiameseVO/model/4/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/4/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = Quaternion(element[0:4]).rotation_matrix\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/DepthSiameseVO/Results/4/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Alternando arquiteturas e dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Usando Relu no lugar de Leaky Relu\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 1028)         9041412     input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1028)         0           sequential_6[1][0]               \n",
      "                                                                 sequential_6[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1028)         1057812     lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1028)         0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1028)         1057812     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1028)         0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 64)           65856       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64)           0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            390         activation_7[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 11,223,282\n",
      "Trainable params: 11,223,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(1028)(abs_diff)\n",
    "activation1 = Activation('relu')(dense_layer)\n",
    "dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = Activation('relu')(dense_layer1)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = Activation('relu')(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(3, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados transformados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 1028)         9041412     input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1028)         0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1028)         1057812     lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1028)         0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1028)         1057812     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1028)         0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 64)           65856       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64)           0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            390         activation_14[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 11,223,282\n",
      "Trainable params: 11,223,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(1028)(abs_diff)\n",
    "activation1 = Activation('relu')(dense_layer)\n",
    "dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = Activation('relu')(dense_layer1)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = Activation('relu')(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(3, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "def vo_loss2(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]\n",
    "    mean_rot = mean[:, 0:3] * 50\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt*1000\n",
    "\n",
    "# learning_rate = 0.00001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss2], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 47, 155, 1)\n",
      "(6860, 47, 155, 1)\n",
      "(16330, 6)\n"
     ]
    }
   ],
   "source": [
    "flag_ypr_t = False\n",
    "flag_ypr_t_transformed = True\n",
    "flag_only_rotation = False\n",
    "flag_only_translation = False\n",
    "\n",
    "\n",
    "if(flag_ypr_t):\n",
    "\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_ypr_t_transformed):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_transformed, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses_transformed, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_rotation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_rotation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_rotation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_translation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_translation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_translation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1770.8765 - rmse: 3.1792 - acc: 0.2202 - val_loss: 1464.1236 - val_rmse: 1.5331 - val_acc: 0.2257\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1464.12359, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.22021, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1750.1323 - rmse: 3.1444 - acc: 0.2358 - val_loss: 1466.6845 - val_rmse: 1.5357 - val_acc: 0.1776\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00002: acc improved from 0.22021 to 0.23576, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1683.2949 - rmse: 3.0106 - acc: 0.3831 - val_loss: 1464.6747 - val_rmse: 1.5331 - val_acc: 0.3274\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00003: acc improved from 0.23576 to 0.38310, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1530.5745 - rmse: 2.6571 - acc: 0.4902 - val_loss: 1499.0650 - val_rmse: 1.5882 - val_acc: 0.3751\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00004: acc improved from 0.38310 to 0.49020, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/50\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1383.4566 - rmse: 2.3927 - acc: 0.5729 - val_loss: 1507.7328 - val_rmse: 1.6061 - val_acc: 0.3682\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00005: acc improved from 0.49020 to 0.57287, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1190.0186 - rmse: 2.0424 - acc: 0.6184 - val_loss: 1547.5262 - val_rmse: 1.6654 - val_acc: 0.3669\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00006: acc improved from 0.57287 to 0.61837, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1046.2555 - rmse: 1.7632 - acc: 0.6453 - val_loss: 1523.5935 - val_rmse: 1.6290 - val_acc: 0.3536\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00007: acc improved from 0.61837 to 0.64525, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 939.5176 - rmse: 1.5723 - acc: 0.6608 - val_loss: 1500.3965 - val_rmse: 1.6080 - val_acc: 0.3500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00008: acc improved from 0.64525 to 0.66081, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 848.8850 - rmse: 1.4122 - acc: 0.6776 - val_loss: 1542.3922 - val_rmse: 1.6560 - val_acc: 0.3542\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00009: acc improved from 0.66081 to 0.67759, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/50\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 780.5159 - rmse: 1.2855 - acc: 0.6927 - val_loss: 1515.4497 - val_rmse: 1.6193 - val_acc: 0.3567\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00010: acc improved from 0.67759 to 0.69271, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 11/50\n",
      "16330/16330 [==============================] - 36s 2ms/step - loss: 726.5449 - rmse: 1.1986 - acc: 0.7046 - val_loss: 1505.2816 - val_rmse: 1.6117 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00011: acc improved from 0.69271 to 0.70459, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 12/50\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 675.3440 - rmse: 1.1152 - acc: 0.7222 - val_loss: 1564.3744 - val_rmse: 1.6750 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00012: acc improved from 0.70459 to 0.72217, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/50\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 621.7541 - rmse: 1.0207 - acc: 0.7378 - val_loss: 1513.9421 - val_rmse: 1.6164 - val_acc: 0.3388\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00013: acc improved from 0.72217 to 0.73778, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 580.9795 - rmse: 0.9533 - acc: 0.7537 - val_loss: 1554.2844 - val_rmse: 1.6645 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00014: acc improved from 0.73778 to 0.75370, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 550.9963 - rmse: 0.9162 - acc: 0.7624 - val_loss: 1536.8666 - val_rmse: 1.6444 - val_acc: 0.3469\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00015: acc improved from 0.75370 to 0.76240, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 16/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 508.5212 - rmse: 0.8377 - acc: 0.7712 - val_loss: 1515.0960 - val_rmse: 1.6108 - val_acc: 0.3203\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00016: acc improved from 0.76240 to 0.77116, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 483.0768 - rmse: 0.7985 - acc: 0.7818 - val_loss: 1531.3038 - val_rmse: 1.6375 - val_acc: 0.3417\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00017: acc improved from 0.77116 to 0.78181, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 465.3232 - rmse: 0.7705 - acc: 0.7876 - val_loss: 1529.8259 - val_rmse: 1.6375 - val_acc: 0.3402\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00018: acc improved from 0.78181 to 0.78763, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 440.5053 - rmse: 0.7279 - acc: 0.7859 - val_loss: 1524.0743 - val_rmse: 1.6269 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.78763\n",
      "Epoch 20/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 429.6025 - rmse: 0.7055 - acc: 0.7985 - val_loss: 1526.0918 - val_rmse: 1.6317 - val_acc: 0.3417\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00020: acc improved from 0.78763 to 0.79847, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 21/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 408.6779 - rmse: 0.6683 - acc: 0.7934 - val_loss: 1518.3150 - val_rmse: 1.6217 - val_acc: 0.3414\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.79847\n",
      "Epoch 22/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 397.4020 - rmse: 0.6510 - acc: 0.8004 - val_loss: 1526.6829 - val_rmse: 1.6310 - val_acc: 0.3334\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00022: acc improved from 0.79847 to 0.80043, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 384.3175 - rmse: 0.6251 - acc: 0.8055 - val_loss: 1544.8945 - val_rmse: 1.6532 - val_acc: 0.3430\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00023: acc improved from 0.80043 to 0.80545, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 24/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 370.0128 - rmse: 0.6065 - acc: 0.8102 - val_loss: 1515.7957 - val_rmse: 1.6193 - val_acc: 0.3513\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00024: acc improved from 0.80545 to 0.81017, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 25/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 361.5176 - rmse: 0.5836 - acc: 0.8063 - val_loss: 1528.9068 - val_rmse: 1.6378 - val_acc: 0.3509\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.81017\n",
      "Epoch 26/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 356.5253 - rmse: 0.5734 - acc: 0.8157 - val_loss: 1512.8379 - val_rmse: 1.6089 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00026: acc improved from 0.81017 to 0.81574, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 27/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 343.4561 - rmse: 0.5553 - acc: 0.8183 - val_loss: 1544.5864 - val_rmse: 1.6525 - val_acc: 0.3423\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00027: acc improved from 0.81574 to 0.81831, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 28/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 339.7992 - rmse: 0.5510 - acc: 0.8209 - val_loss: 1497.8553 - val_rmse: 1.5958 - val_acc: 0.3424\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00028: acc improved from 0.81831 to 0.82088, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 29/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 329.9061 - rmse: 0.5303 - acc: 0.8230 - val_loss: 1523.2808 - val_rmse: 1.6277 - val_acc: 0.3520\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00029: acc improved from 0.82088 to 0.82303, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 30/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 320.9908 - rmse: 0.5158 - acc: 0.8296 - val_loss: 1505.1924 - val_rmse: 1.6065 - val_acc: 0.3516\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00030: acc improved from 0.82303 to 0.82958, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 31/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 312.1928 - rmse: 0.4991 - acc: 0.8303 - val_loss: 1514.9813 - val_rmse: 1.6187 - val_acc: 0.3427\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00031: acc improved from 0.82958 to 0.83025, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 32/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 310.3024 - rmse: 0.4956 - acc: 0.8302 - val_loss: 1522.2406 - val_rmse: 1.6268 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.83025\n",
      "Epoch 33/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 301.8396 - rmse: 0.4833 - acc: 0.8333 - val_loss: 1513.9233 - val_rmse: 1.6162 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00033: acc improved from 0.83025 to 0.83331, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 34/50\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 302.4553 - rmse: 0.4894 - acc: 0.8366 - val_loss: 1505.9049 - val_rmse: 1.6079 - val_acc: 0.3446\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00034: acc improved from 0.83331 to 0.83662, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 35/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 289.5986 - rmse: 0.4581 - acc: 0.8348 - val_loss: 1516.1467 - val_rmse: 1.6196 - val_acc: 0.3525\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00035: acc did not improve from 0.83662\n",
      "Epoch 36/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 291.7071 - rmse: 0.4686 - acc: 0.8328 - val_loss: 1500.3112 - val_rmse: 1.6009 - val_acc: 0.3453\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00036: acc did not improve from 0.83662\n",
      "Epoch 37/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 281.7469 - rmse: 0.4491 - acc: 0.8415 - val_loss: 1515.2219 - val_rmse: 1.6216 - val_acc: 0.3506\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00037: acc improved from 0.83662 to 0.84146, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 38/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 279.2315 - rmse: 0.4518 - acc: 0.8369 - val_loss: 1514.6516 - val_rmse: 1.6152 - val_acc: 0.3500\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.84146\n",
      "Epoch 39/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 272.2873 - rmse: 0.4352 - acc: 0.8441 - val_loss: 1498.9584 - val_rmse: 1.5988 - val_acc: 0.3439\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00039: acc improved from 0.84146 to 0.84409, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 40/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 264.9660 - rmse: 0.4195 - acc: 0.8434 - val_loss: 1529.1158 - val_rmse: 1.6367 - val_acc: 0.3494\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00040: acc did not improve from 0.84409\n",
      "Epoch 41/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 262.2113 - rmse: 0.4166 - acc: 0.8426 - val_loss: 1500.1909 - val_rmse: 1.5993 - val_acc: 0.3528\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.84409\n",
      "Epoch 42/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 260.7134 - rmse: 0.4174 - acc: 0.8487 - val_loss: 1495.6616 - val_rmse: 1.5919 - val_acc: 0.3408\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00042: acc improved from 0.84409 to 0.84868, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 43/50\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 254.9449 - rmse: 0.4053 - acc: 0.8470 - val_loss: 1507.2139 - val_rmse: 1.6106 - val_acc: 0.3531\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.84868\n",
      "Epoch 44/50\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 251.6069 - rmse: 0.4010 - acc: 0.8491 - val_loss: 1506.9812 - val_rmse: 1.6117 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00044: acc improved from 0.84868 to 0.84905, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 45/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 247.6231 - rmse: 0.3966 - acc: 0.8489 - val_loss: 1495.4041 - val_rmse: 1.5963 - val_acc: 0.3586\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00045: acc did not improve from 0.84905\n",
      "Epoch 46/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 246.6293 - rmse: 0.3927 - acc: 0.8476 - val_loss: 1507.0549 - val_rmse: 1.6092 - val_acc: 0.3576\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00046: acc did not improve from 0.84905\n",
      "Epoch 47/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 241.1511 - rmse: 0.3863 - acc: 0.8562 - val_loss: 1491.2617 - val_rmse: 1.5909 - val_acc: 0.3493\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00047: acc improved from 0.84905 to 0.85622, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 48/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 239.0144 - rmse: 0.3844 - acc: 0.8576 - val_loss: 1516.3737 - val_rmse: 1.6216 - val_acc: 0.3606\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00048: acc improved from 0.85622 to 0.85762, saving model to D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 49/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 236.1006 - rmse: 0.3762 - acc: 0.8562 - val_loss: 1499.3103 - val_rmse: 1.6000 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00049: acc did not improve from 0.85762\n",
      "Epoch 50/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 230.1850 - rmse: 0.3665 - acc: 0.8574 - val_loss: 1515.2370 - val_rmse: 1.6166 - val_acc: 0.3525\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1464.12359\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.85762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253e9880a90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_RELU_transformed/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_RELU_transformed', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=50, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_RELU_transformed/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/fifth/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/fifth/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mesmos resultados que com a LeakyRelu\n",
    "\n",
    "## Diminuindo a quantidade de Fully connect layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados transformados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 1028)         9041412     input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1028)         0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 64)           65856       lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64)           0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            390         activation_31[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,107,658\n",
      "Trainable params: 9,107,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "#dense_layer = Dense(1028)(abs_diff)\n",
    "#activation1 = Activation('relu')(dense_layer)\n",
    "#dense_layer1 = Dense(1028)(activation1)\n",
    "#activation2 = Activation('relu')(dense_layer1)\n",
    "dense_layer2 = Dense(64)(abs_diff)\n",
    "activation3 = Activation('relu')(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(3, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "def vo_loss2(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]\n",
    "    mean_rot = mean[:, 0:3] * 50\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt*1000\n",
    "\n",
    "# learning_rate = 0.00001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss2], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 47, 155, 1)\n",
      "(6860, 47, 155, 1)\n",
      "(16330, 6)\n"
     ]
    }
   ],
   "source": [
    "flag_ypr_t = False\n",
    "flag_ypr_t_transformed = True\n",
    "flag_only_rotation = False\n",
    "flag_only_translation = False\n",
    "\n",
    "\n",
    "if(flag_ypr_t):\n",
    "\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_ypr_t_transformed):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_transformed, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses_transformed, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_rotation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_rotation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_rotation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_translation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_translation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_translation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1787.1150 - rmse: 3.1751 - acc: 0.2375 - val_loss: 1454.4293 - val_rmse: 1.5252 - val_acc: 0.2362\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1454.42932, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.23754, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1763.3797 - rmse: 3.1683 - acc: 0.2566 - val_loss: 1454.7221 - val_rmse: 1.5256 - val_acc: 0.2376\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00002: acc improved from 0.23754 to 0.25664, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1761.4831 - rmse: 3.1829 - acc: 0.2592 - val_loss: 1455.2870 - val_rmse: 1.5263 - val_acc: 0.2376\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00003: acc improved from 0.25664 to 0.25915, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1760.4473 - rmse: 3.1626 - acc: 0.2588 - val_loss: 1455.9648 - val_rmse: 1.5270 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.25915\n",
      "Epoch 5/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.8039 - rmse: 3.1522 - acc: 0.2593 - val_loss: 1456.5299 - val_rmse: 1.5277 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00005: acc improved from 0.25915 to 0.25928, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1759.2615 - rmse: 3.1550 - acc: 0.2589 - val_loss: 1457.1468 - val_rmse: 1.5283 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.25928\n",
      "Epoch 7/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1759.1466 - rmse: 3.1680 - acc: 0.2592 - val_loss: 1457.6635 - val_rmse: 1.5288 - val_acc: 0.2399\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.25928\n",
      "Epoch 8/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1758.7263 - rmse: 3.1842 - acc: 0.2582 - val_loss: 1459.9760 - val_rmse: 1.5293 - val_acc: 0.2407\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.25928\n",
      "Epoch 9/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1758.3372 - rmse: 3.1722 - acc: 0.2581 - val_loss: 1458.4243 - val_rmse: 1.5295 - val_acc: 0.2399\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.25928\n",
      "Epoch 10/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1757.8826 - rmse: 3.1744 - acc: 0.2585 - val_loss: 1458.7475 - val_rmse: 1.5298 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.25928\n",
      "Epoch 11/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1757.3698 - rmse: 3.1687 - acc: 0.2582 - val_loss: 1458.8695 - val_rmse: 1.5300 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.25928\n",
      "Epoch 12/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1756.9754 - rmse: 3.1620 - acc: 0.2580 - val_loss: 1459.0580 - val_rmse: 1.5300 - val_acc: 0.2404\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.25928\n",
      "Epoch 13/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1754.9220 - rmse: 3.1454 - acc: 0.2625 - val_loss: 1459.0280 - val_rmse: 1.5299 - val_acc: 0.2436\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00013: acc improved from 0.25928 to 0.26252, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1744.8214 - rmse: 3.1179 - acc: 0.2714 - val_loss: 1481.5343 - val_rmse: 1.5773 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00014: acc improved from 0.26252 to 0.27140, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 15/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1717.3441 - rmse: 3.0554 - acc: 0.2756 - val_loss: 1468.8737 - val_rmse: 1.5536 - val_acc: 0.2536\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00015: acc improved from 0.27140 to 0.27563, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 16/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1677.6199 - rmse: 2.9196 - acc: 0.2798 - val_loss: 1475.1976 - val_rmse: 1.5680 - val_acc: 0.2506\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00016: acc improved from 0.27563 to 0.27979, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 17/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1641.9052 - rmse: 2.8603 - acc: 0.2850 - val_loss: 1484.6424 - val_rmse: 1.5993 - val_acc: 0.2532\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00017: acc improved from 0.27979 to 0.28500, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 18/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1616.8806 - rmse: 2.7847 - acc: 0.2885 - val_loss: 1481.6873 - val_rmse: 1.5876 - val_acc: 0.2589\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00018: acc improved from 0.28500 to 0.28855, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 19/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1594.5511 - rmse: 2.7258 - acc: 0.2889 - val_loss: 1504.3527 - val_rmse: 1.6502 - val_acc: 0.2615\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00019: acc improved from 0.28855 to 0.28892, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1580.6301 - rmse: 2.7000 - acc: 0.2930 - val_loss: 1476.8391 - val_rmse: 1.5814 - val_acc: 0.2550\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00020: acc improved from 0.28892 to 0.29296, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 21/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1568.9037 - rmse: 2.6613 - acc: 0.2933 - val_loss: 1500.0702 - val_rmse: 1.6291 - val_acc: 0.2701\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00021: acc improved from 0.29296 to 0.29326, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 22/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1541.9843 - rmse: 2.6039 - acc: 0.2941 - val_loss: 1487.2059 - val_rmse: 1.6062 - val_acc: 0.2583\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00022: acc improved from 0.29326 to 0.29412, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1527.4456 - rmse: 2.5676 - acc: 0.2941 - val_loss: 1494.3904 - val_rmse: 1.6251 - val_acc: 0.2580\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.29412\n",
      "Epoch 24/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1515.0441 - rmse: 2.5317 - acc: 0.2966 - val_loss: 1480.0606 - val_rmse: 1.5905 - val_acc: 0.2606\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00024: acc improved from 0.29412 to 0.29663, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 25/50\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1514.4351 - rmse: 2.5341 - acc: 0.2976 - val_loss: 1490.9350 - val_rmse: 1.6124 - val_acc: 0.2567\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00025: acc improved from 0.29663 to 0.29761, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 26/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1490.5731 - rmse: 2.4995 - acc: 0.2998 - val_loss: 1516.0493 - val_rmse: 1.6633 - val_acc: 0.2596\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00026: acc improved from 0.29761 to 0.29976, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 27/50\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1488.6824 - rmse: 2.4725 - acc: 0.3001 - val_loss: 1500.8509 - val_rmse: 1.6272 - val_acc: 0.2595\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00027: acc improved from 0.29976 to 0.30012, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 28/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1472.5625 - rmse: 2.4318 - acc: 0.3003 - val_loss: 1513.1028 - val_rmse: 1.6543 - val_acc: 0.2643\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00028: acc improved from 0.30012 to 0.30031, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 29/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1468.0065 - rmse: 2.4321 - acc: 0.3006 - val_loss: 1514.1747 - val_rmse: 1.6592 - val_acc: 0.2567\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00029: acc improved from 0.30031 to 0.30061, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 30/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1460.0967 - rmse: 2.4210 - acc: 0.3006 - val_loss: 1528.9994 - val_rmse: 1.6872 - val_acc: 0.2665\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00030: acc improved from 0.30061 to 0.30061, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 31/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1453.4432 - rmse: 2.3960 - acc: 0.3010 - val_loss: 1505.3527 - val_rmse: 1.6441 - val_acc: 0.2625\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00031: acc improved from 0.30061 to 0.30104, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 32/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1448.3950 - rmse: 2.3937 - acc: 0.3012 - val_loss: 1529.3031 - val_rmse: 1.6941 - val_acc: 0.2682\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00032: acc improved from 0.30104 to 0.30116, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 33/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1442.7412 - rmse: 2.3741 - acc: 0.3024 - val_loss: 1538.9819 - val_rmse: 1.7116 - val_acc: 0.2606\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00033: acc improved from 0.30116 to 0.30245, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 34/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1436.3609 - rmse: 2.3559 - acc: 0.3033 - val_loss: 1526.5145 - val_rmse: 1.6801 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00034: acc improved from 0.30245 to 0.30331, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 35/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1426.0829 - rmse: 2.3375 - acc: 0.3043 - val_loss: 1519.5176 - val_rmse: 1.6676 - val_acc: 0.2669\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00035: acc improved from 0.30331 to 0.30435, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 36/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1421.6131 - rmse: 2.3404 - acc: 0.3045 - val_loss: 1528.8554 - val_rmse: 1.6847 - val_acc: 0.2638\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00036: acc improved from 0.30435 to 0.30453, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 37/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1414.2897 - rmse: 2.3103 - acc: 0.3059 - val_loss: 1555.7524 - val_rmse: 1.7426 - val_acc: 0.2694\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00037: acc improved from 0.30453 to 0.30588, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 38/50\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1415.3372 - rmse: 2.3169 - acc: 0.3051 - val_loss: 1538.5762 - val_rmse: 1.6999 - val_acc: 0.2690\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.30588\n",
      "Epoch 39/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1399.4472 - rmse: 2.2880 - acc: 0.3061 - val_loss: 1546.1396 - val_rmse: 1.7258 - val_acc: 0.2694\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00039: acc improved from 0.30588 to 0.30606, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 40/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1399.8651 - rmse: 2.2947 - acc: 0.3075 - val_loss: 1537.9305 - val_rmse: 1.6971 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00040: acc improved from 0.30606 to 0.30753, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 41/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1393.8426 - rmse: 2.2703 - acc: 0.3065 - val_loss: 1533.7042 - val_rmse: 1.6907 - val_acc: 0.2652\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.30753\n",
      "Epoch 42/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1391.6652 - rmse: 2.2711 - acc: 0.3074 - val_loss: 1547.1008 - val_rmse: 1.7212 - val_acc: 0.2649\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00042: acc did not improve from 0.30753\n",
      "Epoch 43/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1386.4761 - rmse: 2.2633 - acc: 0.3075 - val_loss: 1540.6656 - val_rmse: 1.7192 - val_acc: 0.2697\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.30753\n",
      "Epoch 44/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1381.9762 - rmse: 2.2578 - acc: 0.3081 - val_loss: 1523.2235 - val_rmse: 1.6744 - val_acc: 0.2666\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00044: acc improved from 0.30753 to 0.30814, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 45/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1372.0616 - rmse: 2.2413 - acc: 0.3096 - val_loss: 1553.0046 - val_rmse: 1.7394 - val_acc: 0.2660\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00045: acc improved from 0.30814 to 0.30961, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 46/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1376.9202 - rmse: 2.2487 - acc: 0.3095 - val_loss: 1526.6473 - val_rmse: 1.6864 - val_acc: 0.2627\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00046: acc did not improve from 0.30961\n",
      "Epoch 47/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1367.2305 - rmse: 2.2136 - acc: 0.3097 - val_loss: 1551.7206 - val_rmse: 1.7310 - val_acc: 0.2662\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00047: acc improved from 0.30961 to 0.30968, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 48/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1364.0859 - rmse: 2.2078 - acc: 0.3110 - val_loss: 1539.3226 - val_rmse: 1.7127 - val_acc: 0.2707\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00048: acc improved from 0.30968 to 0.31096, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 49/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1361.6258 - rmse: 2.2102 - acc: 0.3134 - val_loss: 1567.8793 - val_rmse: 1.7680 - val_acc: 0.2749\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00049: acc improved from 0.31096 to 0.31341, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 50/50\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1354.5472 - rmse: 2.2054 - acc: 0.3141 - val_loss: 1520.9196 - val_rmse: 1.6663 - val_acc: 0.2624\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1454.42932\n",
      "\n",
      "Epoch 00050: acc improved from 0.31341 to 0.31408, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253eb1de9e8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_Fully_Connected_transformed', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=50, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/eighth/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/eighth/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "## Usando concatenate no lugar de get_abs_diff\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados transformados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_18 (Sequential)      (None, 1028)         9041412     input_35[0][0]                   \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2056)         0           sequential_18[1][0]              \n",
      "                                                                 sequential_18[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 1028)         2114596     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1028)         0           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 1028)         1057812     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 1028)         0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 64)           65856       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 64)           0           dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            390         activation_83[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12,280,066\n",
      "Trainable params: 12,280,066\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "dense_layer = Dense(1028)(concatenetion_layer)\n",
    "activation1 = Activation('relu')(dense_layer)\n",
    "dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = Activation('relu')(dense_layer1)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = Activation('relu')(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(3, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "def vo_loss2(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]\n",
    "    mean_rot = mean[:, 0:3] * 50\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt*1000\n",
    "\n",
    "# learning_rate = 0.00001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss2], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 47, 155, 1)\n",
      "(6860, 47, 155, 1)\n",
      "(16330, 6)\n"
     ]
    }
   ],
   "source": [
    "flag_ypr_t = False\n",
    "flag_ypr_t_transformed = True\n",
    "flag_only_rotation = False\n",
    "flag_only_translation = False\n",
    "\n",
    "\n",
    "if(flag_ypr_t):\n",
    "\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_ypr_t_transformed):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_transformed, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses_transformed, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_rotation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_rotation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_rotation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_translation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_translation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_translation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVO_concatenate_transformed/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1788.8493 - rmse: 3.1523 - acc: 0.2100 - val_loss: 1454.0441 - val_rmse: 1.5251 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1454.04411, saving model to D:/KITTI/Graph/DepthVO_concatenate_transformed/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.20998, saving model to D:/KITTI/Graph/DepthVO_concatenate_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1763.9305 - rmse: 3.1649 - acc: 0.2592 - val_loss: 1454.3986 - val_rmse: 1.5255 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00002: acc improved from 0.20998 to 0.25922, saving model to D:/KITTI/Graph/DepthVO_concatenate_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1761.5767 - rmse: 3.1594 - acc: 0.2600 - val_loss: 1455.0427 - val_rmse: 1.5262 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00003: acc improved from 0.25922 to 0.26001, saving model to D:/KITTI/Graph/DepthVO_concatenate_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1760.6378 - rmse: 3.1837 - acc: 0.2600 - val_loss: 1455.7775 - val_rmse: 1.5269 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00004: acc improved from 0.26001 to 0.26001, saving model to D:/KITTI/Graph/DepthVO_concatenate_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1760.0657 - rmse: 3.1598 - acc: 0.2600 - val_loss: 1456.4779 - val_rmse: 1.5276 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00005: acc improved from 0.26001 to 0.26001, saving model to D:/KITTI/Graph/DepthVO_concatenate_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.7250 - rmse: 3.1766 - acc: 0.2600 - val_loss: 1457.1031 - val_rmse: 1.5283 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.26001\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.5261 - rmse: 3.1539 - acc: 0.2600 - val_loss: 1457.6505 - val_rmse: 1.5288 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.26001\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.4118 - rmse: 3.1552 - acc: 0.2600 - val_loss: 1458.0938 - val_rmse: 1.5292 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.26001\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.3461 - rmse: 3.1866 - acc: 0.2600 - val_loss: 1458.4355 - val_rmse: 1.5296 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.26001\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.3109 - rmse: 3.1759 - acc: 0.2600 - val_loss: 1458.6796 - val_rmse: 1.5298 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.26001\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2921 - rmse: 3.1649 - acc: 0.2600 - val_loss: 1458.8572 - val_rmse: 1.5300 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.26001\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2792 - rmse: 3.1729 - acc: 0.2600 - val_loss: 1459.0282 - val_rmse: 1.5301 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.26001\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2726 - rmse: 3.1691 - acc: 0.2600 - val_loss: 1459.1317 - val_rmse: 1.5303 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.26001\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2679 - rmse: 3.1625 - acc: 0.2600 - val_loss: 1459.2348 - val_rmse: 1.5304 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.26001\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2651 - rmse: 3.1588 - acc: 0.2600 - val_loss: 1459.3014 - val_rmse: 1.5304 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.26001\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2655 - rmse: 3.1678 - acc: 0.2600 - val_loss: 1459.3539 - val_rmse: 1.5305 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.26001\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2627 - rmse: 3.1651 - acc: 0.2600 - val_loss: 1459.4283 - val_rmse: 1.5305 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.26001\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2618 - rmse: 3.1564 - acc: 0.2600 - val_loss: 1459.4258 - val_rmse: 1.5305 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.26001\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2629 - rmse: 3.1607 - acc: 0.2600 - val_loss: 1459.4470 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.26001\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1759.2650 - rmse: 3.1579 - acc: 0.2600 - val_loss: 1459.4744 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.26001\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2627 - rmse: 3.1697 - acc: 0.2600 - val_loss: 1459.4719 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.26001\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2636 - rmse: 3.1598 - acc: 0.2600 - val_loss: 1459.4804 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.26001\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 1759.2622 - rmse: 3.1664 - acc: 0.2600 - val_loss: 1459.4839 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.26001\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 1759.2623 - rmse: 3.1569 - acc: 0.2600 - val_loss: 1459.5227 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.26001\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 37s 2ms/step - loss: 1759.2641 - rmse: 3.1722 - acc: 0.2600 - val_loss: 1459.4933 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1454.04411\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.26001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253ec836550>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_concatenate_transformed/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_concatenate_transformed', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_concatenate_transformed/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/eleventh/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/eleventh/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diminuindo a quantidade de Fully connect layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados transformados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_21 (Sequential)      (None, 1028)         9041412     input_41[0][0]                   \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2056)         0           sequential_21[1][0]              \n",
      "                                                                 sequential_21[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 64)           131648      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 64)           0           dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            390         activation_100[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 9,173,450\n",
      "Trainable params: 9,173,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "#dense_layer = Dense(1028)(abs_diff)\n",
    "#activation1 = Activation('relu')(dense_layer)\n",
    "#dense_layer1 = Dense(1028)(activation1)\n",
    "#activation2 = Activation('relu')(dense_layer1)\n",
    "dense_layer2 = Dense(64)(concatenetion_layer)\n",
    "activation3 = Activation('relu')(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(3, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "def vo_loss2(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]\n",
    "    mean_rot = mean[:, 0:3] * 50\n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt*1000\n",
    "\n",
    "# learning_rate = 0.00001\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss2], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 47, 155, 1)\n",
      "(6860, 47, 155, 1)\n",
      "(16330, 6)\n"
     ]
    }
   ],
   "source": [
    "flag_ypr_t = False\n",
    "flag_ypr_t_transformed = True\n",
    "flag_only_rotation = False\n",
    "flag_only_translation = False\n",
    "\n",
    "\n",
    "if(flag_ypr_t):\n",
    "\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_ypr_t_transformed):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_transformed, (len(training_poses), 6))\n",
    "    y_test = np.reshape(test_poses_transformed, (len(test_poses), 6))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_rotation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_rotation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_rotation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))\n",
    "    \n",
    "elif(flag_only_translation):\n",
    "    training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "    training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "    print(np.shape(training_r))\n",
    "\n",
    "    test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "    test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "    print(np.shape(test_r))\n",
    "\n",
    "    y_training = np.reshape(training_poses_translation, (len(training_poses), 3))\n",
    "    y_test = np.reshape(test_poses_translation, (len(test_poses), 3))\n",
    "    print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1814.8221 - rmse: 3.1878 - acc: 0.2516 - val_loss: 1454.0738 - val_rmse: 1.5252 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1454.07380, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.25156, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1763.2194 - rmse: 3.1514 - acc: 0.2600 - val_loss: 1454.4035 - val_rmse: 1.5255 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00002: acc improved from 0.25156 to 0.25995, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1761.6215 - rmse: 3.1623 - acc: 0.2600 - val_loss: 1455.0255 - val_rmse: 1.5262 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00003: acc improved from 0.25995 to 0.25995, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1760.6926 - rmse: 3.1707 - acc: 0.2596 - val_loss: 1455.7540 - val_rmse: 1.5269 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.25995\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1760.2810 - rmse: 3.1561 - acc: 0.2600 - val_loss: 1456.4441 - val_rmse: 1.5276 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00005: acc improved from 0.25995 to 0.25995, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.7572 - rmse: 3.1676 - acc: 0.2600 - val_loss: 1457.0536 - val_rmse: 1.5282 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00006: acc improved from 0.25995 to 0.26001, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.5531 - rmse: 3.1723 - acc: 0.2600 - val_loss: 1457.5762 - val_rmse: 1.5287 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.26001\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.4310 - rmse: 3.1670 - acc: 0.2600 - val_loss: 1458.0233 - val_rmse: 1.5292 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.26001\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1759.3593 - rmse: 3.1596 - acc: 0.2600 - val_loss: 1458.4065 - val_rmse: 1.5295 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.26001\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1759.3188 - rmse: 3.1777 - acc: 0.2600 - val_loss: 1458.6282 - val_rmse: 1.5298 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.26001\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1759.2948 - rmse: 3.1746 - acc: 0.2600 - val_loss: 1458.8363 - val_rmse: 1.5300 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.26001\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1759.2807 - rmse: 3.1687 - acc: 0.2600 - val_loss: 1458.9867 - val_rmse: 1.5301 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00012: acc improved from 0.26001 to 0.26001, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 1759.2749 - rmse: 3.1662 - acc: 0.2600 - val_loss: 1459.1141 - val_rmse: 1.5302 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.26001\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.2700 - rmse: 3.1389 - acc: 0.2600 - val_loss: 1459.2266 - val_rmse: 1.5303 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.26001\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.2651 - rmse: 3.1531 - acc: 0.2600 - val_loss: 1459.2885 - val_rmse: 1.5304 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.26001\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.2650 - rmse: 3.1665 - acc: 0.2600 - val_loss: 1459.3346 - val_rmse: 1.5304 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.26001\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.2643 - rmse: 3.1694 - acc: 0.2600 - val_loss: 1459.3832 - val_rmse: 1.5305 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.26001\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 1759.2635 - rmse: 3.1584 - acc: 0.2600 - val_loss: 1459.4498 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.26001\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.2640 - rmse: 3.1686 - acc: 0.2600 - val_loss: 1459.4570 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.26001\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.2643 - rmse: 3.1645 - acc: 0.2600 - val_loss: 1459.4593 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.26001\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1759.2627 - rmse: 3.1699 - acc: 0.2600 - val_loss: 1459.4931 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.26001\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1759.2633 - rmse: 3.1572 - acc: 0.2600 - val_loss: 1459.4984 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.26001\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1759.2625 - rmse: 3.1653 - acc: 0.2600 - val_loss: 1459.5082 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.26001\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 1759.2639 - rmse: 3.1651 - acc: 0.2600 - val_loss: 1459.4985 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.26001\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 31s 2ms/step - loss: 1759.2619 - rmse: 3.1750 - acc: 0.2600 - val_loss: 1459.4909 - val_rmse: 1.5306 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1454.07380\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.26001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253ed7cc278>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_transformed/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "        \n",
    "\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/fourteenth/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    aux_list = []\n",
    "    aux_list.append(init_mat)\n",
    "    \n",
    "    for element in prediction:\n",
    "        matrix = rb.rpy2tr(element[0:3])\n",
    "                \n",
    "        for i in range(3):\n",
    "            translation = element[3:6]\n",
    "            matrix[0, 3] = translation[0]\n",
    "            matrix[1, 3] = translation[1]\n",
    "            matrix[2, 3] = translation[2]\n",
    "            \n",
    "        # output = matrix[0:3,:].flatten()\n",
    "        #print(np.shape(output))\n",
    "        # sequence_GT[cont, :] = output\n",
    "        aux_list.append(matrix)\n",
    "        \n",
    "        \n",
    "    prediction_aux = aux_list\n",
    "    pose_ant = np.identity(4)\n",
    "    \n",
    "    cont = 1\n",
    "    \n",
    "    for transformation in prediction_aux[1:]:\n",
    "        inv_transformation = pose_ant.dot(transformation)\n",
    "        output = inv_transformation[0:3,:].flatten()\n",
    "        sequence_GT[cont, :] = output\n",
    "        cont += 1\n",
    "        pose_ant = inv_transformation\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/fourteenth/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform training pose (of thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_training_thesis_0 = {}\n",
    "label_training_thesis_1 = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_training_thesis_0[name] = label_aux[:-1]\n",
    "    label_training_thesis_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540\n",
      "1100\n",
      "4660\n",
      "800\n",
      "270\n",
      "2760\n",
      "1100\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "from math import asin, atan2, sqrt\n",
    "\n",
    "T_train_thesis = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_training_thesis_0[name], label_training_thesis_1[name]):\n",
    "        \n",
    "        Tx = pose_1[0][3]\n",
    "        Tz = pose_1[2][3]\n",
    "        Tx_ant = pose_0[0][3]\n",
    "        Tz_ant = pose_0[2][3]\n",
    "\n",
    "        Ri_1 = pose_1[0][0]\n",
    "        Ri_3 = pose_1[0][2]    \n",
    "        Ri_1_ant = pose_0[0][0]\n",
    "        Ri_3_ant = pose_0[0][2]\n",
    "        \n",
    "        Ti = [Tx, Tz]\n",
    "        Ti_ant = [Tx_ant, Tz_ant]\n",
    "\n",
    "        displacement = sqrt(sum([(a - b) ** 2 for a, b in zip(Ti, Ti_ant)]))\n",
    "        delta_Theta = atan2(Ri_3, Ri_1) - atan2(Ri_3_ant, Ri_1_ant)\n",
    "    \n",
    "        T_aux.append([delta_Theta, displacement])\n",
    "    \n",
    "    T_train_thesis[name] = T_aux\n",
    "    print(len(T_train_thesis[name]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform test pose (of thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_test_thesis_0 = {}\n",
    "label_test_thesis_1 = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_test_thesis_0[name] = label_aux[:-1]\n",
    "    label_test_thesis_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_test_thesis = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_test_thesis_0[name], label_test_thesis_1[name]):\n",
    "        \n",
    "        Tx = pose_1[0][3]\n",
    "        Tz = pose_1[2][3]\n",
    "        Tx_last = pose_0[0][3]\n",
    "        Tz_last = pose_0[2][3]\n",
    "\n",
    "        Ri_1 = pose_1[0][0]\n",
    "        Ri_3 = pose_1[0][2]    \n",
    "        Ri_1_last = pose_0[0][0]\n",
    "        Ri_3_last = pose_0[0][2]\n",
    "        \n",
    "        Ti = [Tx, Tz]\n",
    "        Ti_last = [Tx_last, Tz_last]\n",
    "\n",
    "        displacement = sqrt(sum([(a - b) ** 2 for a, b in zip(Ti, Ti_last)]))\n",
    "        delta_Theta = atan2(Ri_3, Ri_1) - atan2(Ri_3_last, Ri_1_last)\n",
    "    \n",
    "        T_aux.append([delta_Theta, displacement])\n",
    "    \n",
    "    T_test_thesis[name] = T_aux\n",
    "    # print(T_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_poses_transformed_thesis = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "  \n",
    "    for pose in T_train_thesis[sequence]:\n",
    "        training_poses_transformed_thesis.append(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_poses_transformed_thesis = []\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for pose in T_test_thesis[sequence]:\n",
    "            test_poses_transformed_thesis.append(pose)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 2)\n"
     ]
    }
   ],
   "source": [
    "y_training = np.reshape(training_poses_transformed_thesis, (len(training_poses_transformed_thesis), 2))\n",
    "y_test = np.reshape(test_poses_transformed_thesis, (len(test_poses_transformed_thesis), 2))\n",
    "print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Usando Leaky Relu\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1028)         9041412     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1028)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1028)         1057812     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 1028)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1028)         1057812     leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 1028)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           65856       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 11,223,022\n",
      "Trainable params: 11,223,022\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(1028)(abs_diff)\n",
    "activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.5)(dense_layer1)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.2)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 37s 2ms/step - loss: 0.1346 - rmse: 0.3275 - acc: 0.9979 - val_loss: 0.0849 - val_rmse: 0.2197 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08495, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99792, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0656 - rmse: 0.2184 - acc: 0.9989 - val_loss: 0.0734 - val_rmse: 0.1969 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08495 to 0.07337, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99792 to 0.99890, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 37s 2ms/step - loss: 0.0516 - rmse: 0.1844 - acc: 0.9986 - val_loss: 0.0754 - val_rmse: 0.1981 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07337\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99890\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 37s 2ms/step - loss: 0.0427 - rmse: 0.1605 - acc: 0.9988 - val_loss: 0.0693 - val_rmse: 0.1873 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07337 to 0.06928, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99890\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 37s 2ms/step - loss: 0.0372 - rmse: 0.1477 - acc: 0.9986 - val_loss: 0.0722 - val_rmse: 0.1933 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99890\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0373 - rmse: 0.1535 - acc: 0.9985 - val_loss: 0.0749 - val_rmse: 0.1990 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99890\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 37s 2ms/step - loss: 0.0325 - rmse: 0.1413 - acc: 0.9987 - val_loss: 0.0717 - val_rmse: 0.1937 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99890\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0307 - rmse: 0.1330 - acc: 0.9990 - val_loss: 0.0730 - val_rmse: 0.1912 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00008: acc improved from 0.99890 to 0.99896, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0316 - rmse: 0.1363 - acc: 0.9986 - val_loss: 0.0718 - val_rmse: 0.1929 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99896\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 36s 2ms/step - loss: 0.0231 - rmse: 0.1144 - acc: 0.9984 - val_loss: 0.0706 - val_rmse: 0.1907 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99896\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 36s 2ms/step - loss: 0.0179 - rmse: 0.0996 - acc: 0.9979 - val_loss: 0.0698 - val_rmse: 0.1857 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99896\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0175 - rmse: 0.0927 - acc: 0.9981 - val_loss: 0.0702 - val_rmse: 0.1899 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99896\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0187 - rmse: 0.0992 - acc: 0.9976 - val_loss: 0.0716 - val_rmse: 0.1929 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99896\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0181 - rmse: 0.0968 - acc: 0.9976 - val_loss: 0.0686 - val_rmse: 0.1850 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06928 to 0.06857, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99896\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0176 - rmse: 0.0928 - acc: 0.9972 - val_loss: 0.0686 - val_rmse: 0.1843 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06857 to 0.06856, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99896\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0137 - rmse: 0.0894 - acc: 0.9958 - val_loss: 0.0696 - val_rmse: 0.1883 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06856\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99896\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0143 - rmse: 0.0896 - acc: 0.9976 - val_loss: 0.0733 - val_rmse: 0.2004 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06856\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99896\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0157 - rmse: 0.0882 - acc: 0.9964 - val_loss: 0.0665 - val_rmse: 0.1762 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06856 to 0.06645, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99896\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0123 - rmse: 0.0772 - acc: 0.9967 - val_loss: 0.0688 - val_rmse: 0.1818 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06645\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99896\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0160 - rmse: 0.0842 - acc: 0.9968 - val_loss: 0.0679 - val_rmse: 0.1798 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06645\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99896\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0141 - rmse: 0.0781 - acc: 0.9964 - val_loss: 0.0675 - val_rmse: 0.1799 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06645\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99896\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0172 - rmse: 0.0873 - acc: 0.9972 - val_loss: 0.0691 - val_rmse: 0.1831 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06645\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99896\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0123 - rmse: 0.0777 - acc: 0.9964 - val_loss: 0.0678 - val_rmse: 0.1790 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06645\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99896\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0152 - rmse: 0.0770 - acc: 0.9968 - val_loss: 0.0681 - val_rmse: 0.1795 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06645\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99896\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0144 - rmse: 0.0698 - acc: 0.9964 - val_loss: 0.0686 - val_rmse: 0.1861 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06645\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253f3e84ac8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_RELU_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_RELU_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_RELU_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-1/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-1/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mesmos resultados que com a LeakyRelu\n",
    "\n",
    "## Diminuindo a quantidade de Fully connect layers:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1028)         9041412     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1028)         0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1028)         0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           65856       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,107,398\n",
      "Trainable params: 9,107,398\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "#dense_layer = Dense(1028)(abs_diff)\n",
    "#activation1 = Activation('relu')(dense_layer)\n",
    "#dense_layer1 = Dense(1028)(activation1)\n",
    "#activation2 = Activation('relu')(dense_layer1)\n",
    "\n",
    "activation2 = LeakyReLU(alpha=0.5)(abs_diff)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.2)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.1776 - rmse: 0.3841 - acc: 0.9955 - val_loss: 0.0870 - val_rmse: 0.2368 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08696, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99553, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0692 - rmse: 0.2293 - acc: 0.9985 - val_loss: 0.0813 - val_rmse: 0.2209 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08696 to 0.08128, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99553 to 0.99847, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0484 - rmse: 0.1823 - acc: 0.9983 - val_loss: 0.0761 - val_rmse: 0.2103 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08128 to 0.07611, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99847\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0416 - rmse: 0.1663 - acc: 0.9984 - val_loss: 0.0751 - val_rmse: 0.2075 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07611 to 0.07512, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99847\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0357 - rmse: 0.1538 - acc: 0.9985 - val_loss: 0.0792 - val_rmse: 0.2138 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07512\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99847\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0328 - rmse: 0.1492 - acc: 0.9988 - val_loss: 0.0728 - val_rmse: 0.2023 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07512 to 0.07285, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.99847 to 0.99884, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0253 - rmse: 0.1366 - acc: 0.9983 - val_loss: 0.0705 - val_rmse: 0.1948 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07285 to 0.07051, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99884\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0220 - rmse: 0.1298 - acc: 0.9987 - val_loss: 0.0746 - val_rmse: 0.2070 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07051\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99884\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0177 - rmse: 0.1187 - acc: 0.9991 - val_loss: 0.0692 - val_rmse: 0.1913 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07051 to 0.06924, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00009: acc improved from 0.99884 to 0.99908, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0132 - rmse: 0.1031 - acc: 0.9985 - val_loss: 0.0694 - val_rmse: 0.1913 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06924\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99908\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0123 - rmse: 0.0999 - acc: 0.9988 - val_loss: 0.0712 - val_rmse: 0.1956 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06924\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99908\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0121 - rmse: 0.0965 - acc: 0.9988 - val_loss: 0.0723 - val_rmse: 0.1987 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06924\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99908\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 0.0113 - rmse: 0.0936 - acc: 0.9984 - val_loss: 0.0674 - val_rmse: 0.1848 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06924 to 0.06742, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99908\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0102 - rmse: 0.0895 - acc: 0.9984 - val_loss: 0.0686 - val_rmse: 0.1895 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06742\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99908\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0100 - rmse: 0.0878 - acc: 0.9985 - val_loss: 0.0684 - val_rmse: 0.1852 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06742\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99908\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0096 - rmse: 0.0861 - acc: 0.9988 - val_loss: 0.0659 - val_rmse: 0.1810 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06742 to 0.06589, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99908\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0095 - rmse: 0.0819 - acc: 0.9981 - val_loss: 0.0665 - val_rmse: 0.1815 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99908\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0086 - rmse: 0.0777 - acc: 0.9984 - val_loss: 0.0667 - val_rmse: 0.1814 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99908\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0101 - rmse: 0.0799 - acc: 0.9991 - val_loss: 0.0707 - val_rmse: 0.1902 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00019: acc improved from 0.99908 to 0.99914, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0098 - rmse: 0.0799 - acc: 0.9982 - val_loss: 0.0674 - val_rmse: 0.1835 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99914\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0068 - rmse: 0.0723 - acc: 0.9983 - val_loss: 0.0662 - val_rmse: 0.1803 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99914\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 0.0065 - rmse: 0.0681 - acc: 0.9983 - val_loss: 0.0680 - val_rmse: 0.1846 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99914\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0083 - rmse: 0.0762 - acc: 0.9983 - val_loss: 0.0664 - val_rmse: 0.1812 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99914\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0068 - rmse: 0.0656 - acc: 0.9980 - val_loss: 0.0680 - val_rmse: 0.1836 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99914\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 0.0072 - rmse: 0.0678 - acc: 0.9982 - val_loss: 0.0673 - val_rmse: 0.1819 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253f2771dd8>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_Fully_Connected_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-2/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-2/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Usando concatenate no lugar de get_abs_diff\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 1028)         9041412     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2056)         0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1028)         2114596     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1028)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1028)         1057812     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 1028)         0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           65856       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12,279,806\n",
      "Trainable params: 12,279,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "dense_layer = Dense(1028)(concatenetion_layer)\n",
    "activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.5)(dense_layer1)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.2)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.2516 - rmse: 0.2567 - acc: 0.9885 - val_loss: 0.0831 - val_rmse: 0.2074 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08315, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.98855, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0459 - rmse: 0.1678 - acc: 0.9968 - val_loss: 0.0725 - val_rmse: 0.1872 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08315 to 0.07247, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.98855 to 0.99675, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0385 - rmse: 0.1453 - acc: 0.9966 - val_loss: 0.0701 - val_rmse: 0.1846 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07247 to 0.07008, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99675\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0344 - rmse: 0.1304 - acc: 0.9953 - val_loss: 0.0706 - val_rmse: 0.1848 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07008\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99675\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0318 - rmse: 0.1209 - acc: 0.9956 - val_loss: 0.0685 - val_rmse: 0.1804 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07008 to 0.06855, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99675\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0297 - rmse: 0.1181 - acc: 0.9949 - val_loss: 0.0704 - val_rmse: 0.1860 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99675\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0264 - rmse: 0.1101 - acc: 0.9946 - val_loss: 0.0709 - val_rmse: 0.1871 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99675\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0245 - rmse: 0.1092 - acc: 0.9949 - val_loss: 0.0710 - val_rmse: 0.1893 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99675\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0269 - rmse: 0.1083 - acc: 0.9964 - val_loss: 0.0702 - val_rmse: 0.1885 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99675\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0199 - rmse: 0.0903 - acc: 0.9951 - val_loss: 0.0769 - val_rmse: 0.2052 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99675\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0265 - rmse: 0.1121 - acc: 0.9966 - val_loss: 0.0695 - val_rmse: 0.1847 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99675\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0264 - rmse: 0.1103 - acc: 0.9960 - val_loss: 0.0714 - val_rmse: 0.1904 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99675\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0225 - rmse: 0.0955 - acc: 0.9977 - val_loss: 0.0700 - val_rmse: 0.1847 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00013: acc improved from 0.99675 to 0.99773, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0156 - rmse: 0.0790 - acc: 0.9965 - val_loss: 0.0699 - val_rmse: 0.1835 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99773\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0171 - rmse: 0.0908 - acc: 0.9966 - val_loss: 0.0705 - val_rmse: 0.1859 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99773\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0187 - rmse: 0.0913 - acc: 0.9972 - val_loss: 0.0720 - val_rmse: 0.1960 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99773\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0208 - rmse: 0.0905 - acc: 0.9968 - val_loss: 0.0703 - val_rmse: 0.1851 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99773\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 40s 2ms/step - loss: 0.0143 - rmse: 0.0828 - acc: 0.9957 - val_loss: 0.0685 - val_rmse: 0.1810 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06855 to 0.06846, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99773\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0200 - rmse: 0.0853 - acc: 0.9969 - val_loss: 0.0715 - val_rmse: 0.1891 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99773\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0182 - rmse: 0.0828 - acc: 0.9965 - val_loss: 0.0717 - val_rmse: 0.1917 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99773\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0161 - rmse: 0.0862 - acc: 0.9958 - val_loss: 0.0714 - val_rmse: 0.1869 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99773\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0150 - rmse: 0.0721 - acc: 0.9960 - val_loss: 0.0713 - val_rmse: 0.1865 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99773\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0211 - rmse: 0.0849 - acc: 0.9971 - val_loss: 0.0689 - val_rmse: 0.1791 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99773\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0145 - rmse: 0.0782 - acc: 0.9968 - val_loss: 0.0705 - val_rmse: 0.1835 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99773\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0105 - rmse: 0.0711 - acc: 0.9976 - val_loss: 0.0719 - val_rmse: 0.1855 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253f2af8518>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_concatenate_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_concatenate_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-3/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-3/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mesmos resultados que com a LeakyRelu\n",
    "\n",
    "## Diminuindo a quantidade de Fully connect layers:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 1028)         9041412     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2056)         0           sequential_4[1][0]               \n",
      "                                                                 sequential_4[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 2056)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           131648      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 64)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_10[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 9,173,190\n",
      "Trainable params: 9,173,190\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(32, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(1028))\n",
    "    seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "#dense_layer = Dense(1028)(abs_diff)\n",
    "#activation1 = Activation('relu')(dense_layer)\n",
    "#dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.5)(concatenetion_layer)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.2)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.1909 - rmse: 0.2796 - acc: 0.9873 - val_loss: 0.0820 - val_rmse: 0.2205 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08203, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.98732, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 0.0532 - rmse: 0.1898 - acc: 0.9976 - val_loss: 0.0817 - val_rmse: 0.2075 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08203 to 0.08175, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.98732 to 0.99755, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 0.0435 - rmse: 0.1628 - acc: 0.9977 - val_loss: 0.0818 - val_rmse: 0.2192 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08175\n",
      "\n",
      "Epoch 00003: acc improved from 0.99755 to 0.99773, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0380 - rmse: 0.1462 - acc: 0.9980 - val_loss: 0.0772 - val_rmse: 0.1965 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08175 to 0.07724, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc improved from 0.99773 to 0.99804, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0339 - rmse: 0.1341 - acc: 0.9967 - val_loss: 0.0688 - val_rmse: 0.1797 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07724 to 0.06878, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99804\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0309 - rmse: 0.1241 - acc: 0.9958 - val_loss: 0.0712 - val_rmse: 0.1887 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99804\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0274 - rmse: 0.1165 - acc: 0.9950 - val_loss: 0.0695 - val_rmse: 0.1840 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99804\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0246 - rmse: 0.1077 - acc: 0.9949 - val_loss: 0.0688 - val_rmse: 0.1817 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99804\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0209 - rmse: 0.1000 - acc: 0.9944 - val_loss: 0.0705 - val_rmse: 0.1874 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99804\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0189 - rmse: 0.0982 - acc: 0.9945 - val_loss: 0.0712 - val_rmse: 0.1880 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99804\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0171 - rmse: 0.0936 - acc: 0.9950 - val_loss: 0.0722 - val_rmse: 0.1934 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99804\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0150 - rmse: 0.0925 - acc: 0.9947 - val_loss: 0.0708 - val_rmse: 0.1906 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99804\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0097 - rmse: 0.0796 - acc: 0.9950 - val_loss: 0.0699 - val_rmse: 0.1867 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99804\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0110 - rmse: 0.0800 - acc: 0.9952 - val_loss: 0.0705 - val_rmse: 0.1894 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99804\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0118 - rmse: 0.0787 - acc: 0.9956 - val_loss: 0.0684 - val_rmse: 0.1814 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06878 to 0.06843, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99804\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0108 - rmse: 0.0733 - acc: 0.9960 - val_loss: 0.0679 - val_rmse: 0.1807 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06843 to 0.06792, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99804\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0109 - rmse: 0.0711 - acc: 0.9948 - val_loss: 0.0674 - val_rmse: 0.1780 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06792 to 0.06740, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99804\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0047 - rmse: 0.0510 - acc: 0.9959 - val_loss: 0.0667 - val_rmse: 0.1755 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06740 to 0.06675, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99804\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0068 - rmse: 0.0617 - acc: 0.9955 - val_loss: 0.0686 - val_rmse: 0.1799 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99804\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0056 - rmse: 0.0538 - acc: 0.9959 - val_loss: 0.0674 - val_rmse: 0.1774 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99804\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0069 - rmse: 0.0611 - acc: 0.9955 - val_loss: 0.0671 - val_rmse: 0.1761 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99804\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0052 - rmse: 0.0528 - acc: 0.9957 - val_loss: 0.0675 - val_rmse: 0.1775 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99804\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0060 - rmse: 0.0543 - acc: 0.9958 - val_loss: 0.0679 - val_rmse: 0.1775 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99804\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0035 - rmse: 0.0459 - acc: 0.9950 - val_loss: 0.0667 - val_rmse: 0.1746 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06675 to 0.06670, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99804\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0050 - rmse: 0.0506 - acc: 0.9958 - val_loss: 0.0692 - val_rmse: 0.1823 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06670\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1224fa630>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-4/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-4/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding network size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Usando Leaky Relu\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 50688)        1918848     input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 50688)        0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           3244096     lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 64)           0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_22[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,163,074\n",
      "Trainable params: 5,163,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer1)\n",
    "dense_layer2 = Dense(32)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "def vo_loss_mod(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * 150\n",
    "    mean_trasl = mean[:, 1]* 0.3    \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 0.1651 - rmse: 0.3688 - acc: 0.9945 - val_loss: 0.0836 - val_rmse: 0.2249 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08360, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99449, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.0669 - rmse: 0.2231 - acc: 0.9944 - val_loss: 0.0697 - val_rmse: 0.1876 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08360 to 0.06970, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.99449\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.0513 - rmse: 0.1859 - acc: 0.9968 - val_loss: 0.0752 - val_rmse: 0.2008 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06970\n",
      "\n",
      "Epoch 00003: acc improved from 0.99449 to 0.99675, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.0436 - rmse: 0.1670 - acc: 0.9979 - val_loss: 0.0757 - val_rmse: 0.2019 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06970\n",
      "\n",
      "Epoch 00004: acc improved from 0.99675 to 0.99786, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.0384 - rmse: 0.1534 - acc: 0.9976 - val_loss: 0.0707 - val_rmse: 0.1911 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06970\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99786\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.0347 - rmse: 0.1455 - acc: 0.9986 - val_loss: 0.0649 - val_rmse: 0.1788 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06970 to 0.06491, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.99786 to 0.99859, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.0308 - rmse: 0.1361 - acc: 0.9989 - val_loss: 0.0664 - val_rmse: 0.1820 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00007: acc improved from 0.99859 to 0.99890, saving model to D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.0272 - rmse: 0.1274 - acc: 0.9985 - val_loss: 0.0712 - val_rmse: 0.1948 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99890\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.0242 - rmse: 0.1206 - acc: 0.9987 - val_loss: 0.0750 - val_rmse: 0.2033 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99890\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.0207 - rmse: 0.1147 - acc: 0.9987 - val_loss: 0.0672 - val_rmse: 0.1853 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99890\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 0.0182 - rmse: 0.1081 - acc: 0.9983 - val_loss: 0.0760 - val_rmse: 0.2079 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99890\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.0155 - rmse: 0.1028 - acc: 0.9983 - val_loss: 0.0743 - val_rmse: 0.2058 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99890\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 0.0134 - rmse: 0.0978 - acc: 0.9979 - val_loss: 0.0748 - val_rmse: 0.2069 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99890\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.0112 - rmse: 0.0915 - acc: 0.9980 - val_loss: 0.0712 - val_rmse: 0.1997 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99890\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.0095 - rmse: 0.0853 - acc: 0.9979 - val_loss: 0.0730 - val_rmse: 0.2037 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06491\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99890\n",
      "Epoch 16/25\n",
      "14384/16330 [=========================>....] - ETA: 32s - loss: 0.0086 - rmse: 0.0824 - acc: 0.9977"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-dacc4ef46ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n\u001b[1;32m---> 18\u001b[1;33m                              validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-1-expanded/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-1-expanded/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 50688)        1918848     input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 50688)        0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 64)           3244096     lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 64)           0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_24[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,163,074\n",
      "Trainable params: 5,163,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer1)\n",
    "dense_layer2 = Dense(32)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * 150\n",
    "    mean_trasl = mean[:, 1]* 0.3    \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.5510 - rmse: 0.4912 - acc: 0.9963 - val_loss: 0.6227 - val_rmse: 0.3154 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62267, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99626, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.5079 - rmse: 0.4222 - acc: 0.9994 - val_loss: 0.6055 - val_rmse: 0.2927 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62267 to 0.60548, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99626 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4678 - rmse: 0.3506 - acc: 0.9991 - val_loss: 0.5680 - val_rmse: 0.2427 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60548 to 0.56803, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99939\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4200 - rmse: 0.2649 - acc: 0.9987 - val_loss: 0.5575 - val_rmse: 0.2144 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56803 to 0.55754, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99939\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3916 - rmse: 0.2212 - acc: 0.9979 - val_loss: 0.5325 - val_rmse: 0.1855 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55754 to 0.53249, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99939\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3764 - rmse: 0.2043 - acc: 0.9982 - val_loss: 0.5445 - val_rmse: 0.1810 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53249\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99939\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.3663 - rmse: 0.1931 - acc: 0.9985 - val_loss: 0.5311 - val_rmse: 0.1800 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.53249 to 0.53110, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99939\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3500 - rmse: 0.1820 - acc: 0.9988 - val_loss: 0.5329 - val_rmse: 0.1666 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.53110\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99939\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3501 - rmse: 0.1744 - acc: 0.9988 - val_loss: 0.5257 - val_rmse: 0.1651 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53110 to 0.52568, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99939\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.3458 - rmse: 0.1684 - acc: 0.9989 - val_loss: 0.5199 - val_rmse: 0.1667 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52568 to 0.51995, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99939\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3410 - rmse: 0.1632 - acc: 0.9989 - val_loss: 0.5197 - val_rmse: 0.1581 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.51995 to 0.51968, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99939\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3367 - rmse: 0.1567 - acc: 0.9990 - val_loss: 0.5241 - val_rmse: 0.1681 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.51968\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99939\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3253 - rmse: 0.1510 - acc: 0.9993 - val_loss: 0.5178 - val_rmse: 0.1590 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.51968 to 0.51784, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99939\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3304 - rmse: 0.1481 - acc: 0.9993 - val_loss: 0.5177 - val_rmse: 0.1588 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51784 to 0.51774, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99939\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3272 - rmse: 0.1440 - acc: 0.9991 - val_loss: 0.5152 - val_rmse: 0.1543 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.51774 to 0.51523, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99939\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3254 - rmse: 0.1414 - acc: 0.9993 - val_loss: 0.5166 - val_rmse: 0.1559 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51523\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99939\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3224 - rmse: 0.1371 - acc: 0.9993 - val_loss: 0.5157 - val_rmse: 0.1576 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51523\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99939\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3210 - rmse: 0.1350 - acc: 0.9993 - val_loss: 0.5129 - val_rmse: 0.1523 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.51523 to 0.51288, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99939\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3185 - rmse: 0.1318 - acc: 0.9993 - val_loss: 0.5224 - val_rmse: 0.1677 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99939\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3171 - rmse: 0.1285 - acc: 0.9993 - val_loss: 0.5131 - val_rmse: 0.1516 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99939\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3158 - rmse: 0.1264 - acc: 0.9993 - val_loss: 0.5136 - val_rmse: 0.1518 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99939\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3131 - rmse: 0.1239 - acc: 0.9994 - val_loss: 0.5131 - val_rmse: 0.1501 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 00022: acc improved from 0.99939 to 0.99945, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3117 - rmse: 0.1212 - acc: 0.9993 - val_loss: 0.5159 - val_rmse: 0.1519 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99945\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3101 - rmse: 0.1191 - acc: 0.9994 - val_loss: 0.5142 - val_rmse: 0.1486 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99945\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.3088 - rmse: 0.1165 - acc: 0.9994 - val_loss: 0.5207 - val_rmse: 0.1557 - val_acc: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c196a77a20>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/1/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-2-expanded/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-2-expanded/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar mil épocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_14 (Sequential)      (None, 50688)        1918848     input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 50688)        0           sequential_14[1][0]              \n",
      "                                                                 sequential_14[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 64)           3244096     lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 64)           0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_26[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,163,074\n",
      "Trainable params: 5,163,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer1)\n",
    "dense_layer2 = Dense(32)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * 150\n",
    "    mean_trasl = mean[:, 1]* 0.3    \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/500\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 0.5569 - rmse: 0.4921 - acc: 0.9953 - val_loss: 0.6132 - val_rmse: 0.3140 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61316, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99535, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/500\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.5003 - rmse: 0.4112 - acc: 0.9994 - val_loss: 0.5889 - val_rmse: 0.2837 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61316 to 0.58892, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99535 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.4518 - rmse: 0.3262 - acc: 0.9992 - val_loss: 0.5652 - val_rmse: 0.2484 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58892 to 0.56522, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99939\n",
      "Epoch 4/500\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.4137 - rmse: 0.2612 - acc: 0.9975 - val_loss: 0.5629 - val_rmse: 0.2187 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56522 to 0.56290, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99939\n",
      "Epoch 5/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3900 - rmse: 0.2262 - acc: 0.9960 - val_loss: 0.5350 - val_rmse: 0.1901 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56290 to 0.53497, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99939\n",
      "Epoch 6/500\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.3743 - rmse: 0.2054 - acc: 0.9960 - val_loss: 0.5361 - val_rmse: 0.1847 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53497\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99939\n",
      "Epoch 7/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3562 - rmse: 0.1925 - acc: 0.9960 - val_loss: 0.5235 - val_rmse: 0.1756 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.53497 to 0.52353, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99939\n",
      "Epoch 8/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3567 - rmse: 0.1837 - acc: 0.9969 - val_loss: 0.5288 - val_rmse: 0.1840 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.52353\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99939\n",
      "Epoch 9/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3482 - rmse: 0.1729 - acc: 0.9977 - val_loss: 0.5208 - val_rmse: 0.1692 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52353 to 0.52078, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99939\n",
      "Epoch 10/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3349 - rmse: 0.1652 - acc: 0.9976 - val_loss: 0.5199 - val_rmse: 0.1679 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52078 to 0.51990, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99939\n",
      "Epoch 11/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3393 - rmse: 0.1601 - acc: 0.9977 - val_loss: 0.5157 - val_rmse: 0.1619 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.51990 to 0.51573, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99939\n",
      "Epoch 12/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3352 - rmse: 0.1547 - acc: 0.9979 - val_loss: 0.5135 - val_rmse: 0.1590 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.51573 to 0.51350, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99939\n",
      "Epoch 13/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3235 - rmse: 0.1485 - acc: 0.9980 - val_loss: 0.5142 - val_rmse: 0.1598 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.51350\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99939\n",
      "Epoch 14/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3280 - rmse: 0.1451 - acc: 0.9983 - val_loss: 0.5208 - val_rmse: 0.1611 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.51350\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99939\n",
      "Epoch 15/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3268 - rmse: 0.1423 - acc: 0.9983 - val_loss: 0.5122 - val_rmse: 0.1559 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.51350 to 0.51218, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99939\n",
      "Epoch 16/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3233 - rmse: 0.1384 - acc: 0.9984 - val_loss: 0.5133 - val_rmse: 0.1559 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99939\n",
      "Epoch 17/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3214 - rmse: 0.1352 - acc: 0.9983 - val_loss: 0.5150 - val_rmse: 0.1621 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99939\n",
      "Epoch 18/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3196 - rmse: 0.1329 - acc: 0.9986 - val_loss: 0.5163 - val_rmse: 0.1590 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99939\n",
      "Epoch 19/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3182 - rmse: 0.1306 - acc: 0.9985 - val_loss: 0.5122 - val_rmse: 0.1527 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99939\n",
      "Epoch 20/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3153 - rmse: 0.1264 - acc: 0.9984 - val_loss: 0.5183 - val_rmse: 0.1675 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99939\n",
      "Epoch 21/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3142 - rmse: 0.1244 - acc: 0.9987 - val_loss: 0.5132 - val_rmse: 0.1578 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99939\n",
      "Epoch 22/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3124 - rmse: 0.1210 - acc: 0.9987 - val_loss: 0.5102 - val_rmse: 0.1500 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.51218 to 0.51017, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99939\n",
      "Epoch 23/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3110 - rmse: 0.1193 - acc: 0.9988 - val_loss: 0.5114 - val_rmse: 0.1566 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51017\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99939\n",
      "Epoch 24/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3084 - rmse: 0.1166 - acc: 0.9987 - val_loss: 0.5136 - val_rmse: 0.1533 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51017\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99939\n",
      "Epoch 25/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3079 - rmse: 0.1142 - acc: 0.9988 - val_loss: 0.5093 - val_rmse: 0.1502 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51017 to 0.50933, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2982 - rmse: 0.1113 - acc: 0.9988 - val_loss: 0.5107 - val_rmse: 0.1479 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00026: acc did not improve from 0.99939\n",
      "Epoch 27/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3044 - rmse: 0.1101 - acc: 0.9988 - val_loss: 0.5106 - val_rmse: 0.1482 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00027: acc did not improve from 0.99939\n",
      "Epoch 28/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3025 - rmse: 0.1060 - acc: 0.9988 - val_loss: 0.5115 - val_rmse: 0.1528 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00028: acc did not improve from 0.99939\n",
      "Epoch 29/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2986 - rmse: 0.1050 - acc: 0.9987 - val_loss: 0.5107 - val_rmse: 0.1479 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00029: acc did not improve from 0.99939\n",
      "Epoch 30/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2992 - rmse: 0.1025 - acc: 0.9989 - val_loss: 0.5106 - val_rmse: 0.1478 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00030: acc did not improve from 0.99939\n",
      "Epoch 31/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2990 - rmse: 0.1012 - acc: 0.9989 - val_loss: 0.5159 - val_rmse: 0.1523 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00031: acc did not improve from 0.99939\n",
      "Epoch 32/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2898 - rmse: 0.0987 - acc: 0.9989 - val_loss: 0.5116 - val_rmse: 0.1466 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.99939\n",
      "Epoch 33/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2959 - rmse: 0.0975 - acc: 0.9989 - val_loss: 0.5098 - val_rmse: 0.1464 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00033: acc did not improve from 0.99939\n",
      "Epoch 34/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2948 - rmse: 0.0955 - acc: 0.9990 - val_loss: 0.5107 - val_rmse: 0.1473 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00034: acc did not improve from 0.99939\n",
      "Epoch 35/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2939 - rmse: 0.0946 - acc: 0.9988 - val_loss: 0.5226 - val_rmse: 0.1593 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00035: acc did not improve from 0.99939\n",
      "Epoch 36/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2916 - rmse: 0.0923 - acc: 0.9988 - val_loss: 0.5148 - val_rmse: 0.1487 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00036: acc did not improve from 0.99939\n",
      "Epoch 37/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2909 - rmse: 0.0915 - acc: 0.9990 - val_loss: 0.5157 - val_rmse: 0.1515 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00037: acc did not improve from 0.99939\n",
      "Epoch 38/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2815 - rmse: 0.0884 - acc: 0.9987 - val_loss: 0.5149 - val_rmse: 0.1476 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.99939\n",
      "Epoch 39/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2805 - rmse: 0.0880 - acc: 0.9990 - val_loss: 0.5118 - val_rmse: 0.1465 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.99939\n",
      "Epoch 40/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2855 - rmse: 0.0875 - acc: 0.9989 - val_loss: 0.5164 - val_rmse: 0.1470 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00040: acc did not improve from 0.99939\n",
      "Epoch 41/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2845 - rmse: 0.0858 - acc: 0.9988 - val_loss: 0.5141 - val_rmse: 0.1474 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.99939\n",
      "Epoch 42/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2815 - rmse: 0.0839 - acc: 0.9990 - val_loss: 0.5135 - val_rmse: 0.1454 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00042: acc did not improve from 0.99939\n",
      "Epoch 43/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2726 - rmse: 0.0830 - acc: 0.9991 - val_loss: 0.5145 - val_rmse: 0.1451 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.99939\n",
      "Epoch 44/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2778 - rmse: 0.0828 - acc: 0.9992 - val_loss: 0.5167 - val_rmse: 0.1473 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00044: acc did not improve from 0.99939\n",
      "Epoch 45/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2755 - rmse: 0.0807 - acc: 0.9991 - val_loss: 0.5234 - val_rmse: 0.1510 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00045: acc did not improve from 0.99939\n",
      "Epoch 46/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2737 - rmse: 0.0806 - acc: 0.9991 - val_loss: 0.5292 - val_rmse: 0.1530 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00046: acc did not improve from 0.99939\n",
      "Epoch 47/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2722 - rmse: 0.0804 - acc: 0.9990 - val_loss: 0.5275 - val_rmse: 0.1541 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00047: acc did not improve from 0.99939\n",
      "Epoch 48/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2685 - rmse: 0.0794 - acc: 0.9990 - val_loss: 0.5346 - val_rmse: 0.1738 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00048: acc did not improve from 0.99939\n",
      "Epoch 49/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2673 - rmse: 0.0785 - acc: 0.9993 - val_loss: 0.5246 - val_rmse: 0.1465 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00049: acc did not improve from 0.99939\n",
      "Epoch 50/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2633 - rmse: 0.0774 - acc: 0.9990 - val_loss: 0.5242 - val_rmse: 0.1455 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.99939\n",
      "Epoch 51/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2601 - rmse: 0.0765 - acc: 0.9993 - val_loss: 0.5357 - val_rmse: 0.1543 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00051: acc did not improve from 0.99939\n",
      "Epoch 52/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2620 - rmse: 0.0804 - acc: 0.9989 - val_loss: 0.5383 - val_rmse: 0.1519 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00052: acc did not improve from 0.99939\n",
      "Epoch 53/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2537 - rmse: 0.0762 - acc: 0.9991 - val_loss: 0.5310 - val_rmse: 0.1475 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00053: acc did not improve from 0.99939\n",
      "Epoch 54/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2473 - rmse: 0.0759 - acc: 0.9987 - val_loss: 0.5506 - val_rmse: 0.1565 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00054: acc did not improve from 0.99939\n",
      "Epoch 55/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2484 - rmse: 0.0757 - acc: 0.9989 - val_loss: 0.5502 - val_rmse: 0.1540 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00055: acc did not improve from 0.99939\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2433 - rmse: 0.0758 - acc: 0.9988 - val_loss: 0.5449 - val_rmse: 0.1552 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00056: acc did not improve from 0.99939\n",
      "Epoch 57/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2315 - rmse: 0.0770 - acc: 0.9988 - val_loss: 0.5497 - val_rmse: 0.1526 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00057: acc did not improve from 0.99939\n",
      "Epoch 58/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2335 - rmse: 0.0773 - acc: 0.9991 - val_loss: 0.5875 - val_rmse: 0.1814 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00058: acc did not improve from 0.99939\n",
      "Epoch 59/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2352 - rmse: 0.0846 - acc: 0.9985 - val_loss: 0.5538 - val_rmse: 0.1520 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00059: acc did not improve from 0.99939\n",
      "Epoch 60/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2234 - rmse: 0.0832 - acc: 0.9986 - val_loss: 0.5566 - val_rmse: 0.1522 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00060: acc did not improve from 0.99939\n",
      "Epoch 61/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2231 - rmse: 0.0901 - acc: 0.9989 - val_loss: 0.6018 - val_rmse: 0.1743 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00061: acc did not improve from 0.99939\n",
      "Epoch 62/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2085 - rmse: 0.0794 - acc: 0.9985 - val_loss: 0.5838 - val_rmse: 0.1636 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00062: acc did not improve from 0.99939\n",
      "Epoch 63/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2094 - rmse: 0.0871 - acc: 0.9985 - val_loss: 0.6253 - val_rmse: 0.2013 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00063: acc did not improve from 0.99939\n",
      "Epoch 64/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2046 - rmse: 0.0874 - acc: 0.9986 - val_loss: 0.5795 - val_rmse: 0.1563 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00064: acc did not improve from 0.99939\n",
      "Epoch 65/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1944 - rmse: 0.0804 - acc: 0.9985 - val_loss: 0.5985 - val_rmse: 0.1594 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00065: acc did not improve from 0.99939\n",
      "Epoch 66/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1962 - rmse: 0.0870 - acc: 0.9984 - val_loss: 0.5934 - val_rmse: 0.1551 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00066: acc did not improve from 0.99939\n",
      "Epoch 67/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1879 - rmse: 0.0861 - acc: 0.9987 - val_loss: 0.5832 - val_rmse: 0.1600 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00067: acc did not improve from 0.99939\n",
      "Epoch 68/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1761 - rmse: 0.0788 - acc: 0.9988 - val_loss: 0.6185 - val_rmse: 0.1696 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00068: acc did not improve from 0.99939\n",
      "Epoch 69/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1904 - rmse: 0.0888 - acc: 0.9984 - val_loss: 0.5850 - val_rmse: 0.1642 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00069: acc did not improve from 0.99939\n",
      "Epoch 70/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1737 - rmse: 0.0783 - acc: 0.9988 - val_loss: 0.6164 - val_rmse: 0.2369 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00070: acc did not improve from 0.99939\n",
      "Epoch 71/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1836 - rmse: 0.0849 - acc: 0.9994 - val_loss: 0.6004 - val_rmse: 0.1602 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00071: acc did not improve from 0.99939\n",
      "Epoch 72/500\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.1638 - rmse: 0.0757 - acc: 0.9988 - val_loss: 0.5990 - val_rmse: 0.1618 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00072: acc did not improve from 0.99939\n",
      "Epoch 73/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.1706 - rmse: 0.0847 - acc: 0.9988 - val_loss: 0.5984 - val_rmse: 0.1661 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00073: acc did not improve from 0.99939\n",
      "Epoch 74/500\n",
      " 8912/16330 [===============>..............] - ETA: 2:03 - loss: 0.1833 - rmse: 0.0874 - acc: 0.9988"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-8f6fa639b1ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n\u001b[1;32m---> 18\u001b[1;33m                              validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/1/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserir dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_51 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_26 (Sequential)      (None, 50688)        1918848     input_51[0][0]                   \n",
      "                                                                 input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 50688)        0           sequential_26[1][0]              \n",
      "                                                                 sequential_26[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 64)           3244096     lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 64)           0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,163,074\n",
      "Trainable params: 5,163,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer1)\n",
    "dropout = Dropout(0.5)(activation2)\n",
    "\n",
    "dense_layer2 = Dense(32)(dropout)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer)\n",
    "dropout1 = Dropout(0.5)(activation3)\n",
    "\n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(dropout1)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(dropout1)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * 150\n",
    "    mean_trasl = mean[:, 1]* 0.3    \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVOExpanded_Dropout/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/100\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 0.6061 - rmse: 0.5903 - acc: 0.9936 - val_loss: 0.6054 - val_rmse: 0.3153 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60544, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99357, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.5690 - rmse: 0.5251 - acc: 0.9994 - val_loss: 0.5870 - val_rmse: 0.2839 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60544 to 0.58704, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99357 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.5444 - rmse: 0.4856 - acc: 0.9994 - val_loss: 0.5730 - val_rmse: 0.2611 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58704 to 0.57301, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99939\n",
      "Epoch 4/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.5190 - rmse: 0.4347 - acc: 0.9994 - val_loss: 0.5593 - val_rmse: 0.2346 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57301 to 0.55928, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99939\n",
      "Epoch 5/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4952 - rmse: 0.3893 - acc: 0.9993 - val_loss: 0.5515 - val_rmse: 0.2130 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55928 to 0.55154, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99939\n",
      "Epoch 6/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4759 - rmse: 0.3580 - acc: 0.9993 - val_loss: 0.5384 - val_rmse: 0.2014 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.55154 to 0.53839, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99939\n",
      "Epoch 7/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4630 - rmse: 0.3407 - acc: 0.9993 - val_loss: 0.5455 - val_rmse: 0.2036 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.53839\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99939\n",
      "Epoch 8/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4544 - rmse: 0.3318 - acc: 0.9993 - val_loss: 0.5313 - val_rmse: 0.1904 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.53839 to 0.53126, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99939\n",
      "Epoch 9/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4463 - rmse: 0.3195 - acc: 0.9991 - val_loss: 0.5329 - val_rmse: 0.1920 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.53126\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99939\n",
      "Epoch 10/100\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.4361 - rmse: 0.3049 - acc: 0.9993 - val_loss: 0.5319 - val_rmse: 0.1856 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53126\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99939\n",
      "Epoch 11/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4300 - rmse: 0.2969 - acc: 0.9990 - val_loss: 0.5234 - val_rmse: 0.1705 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.53126 to 0.52338, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99939\n",
      "Epoch 12/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4224 - rmse: 0.2906 - acc: 0.9991 - val_loss: 0.5217 - val_rmse: 0.1712 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.52338 to 0.52167, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99939\n",
      "Epoch 13/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4153 - rmse: 0.2738 - acc: 0.9993 - val_loss: 0.5150 - val_rmse: 0.1643 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.52167 to 0.51497, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99939\n",
      "Epoch 14/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4045 - rmse: 0.2703 - acc: 0.9993 - val_loss: 0.5200 - val_rmse: 0.1736 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.51497\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99939\n",
      "Epoch 15/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4059 - rmse: 0.2630 - acc: 0.9991 - val_loss: 0.5204 - val_rmse: 0.1684 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.51497\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99939\n",
      "Epoch 16/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4033 - rmse: 0.2600 - acc: 0.9993 - val_loss: 0.5116 - val_rmse: 0.1585 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.51497 to 0.51160, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99939\n",
      "Epoch 17/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.4001 - rmse: 0.2544 - acc: 0.9993 - val_loss: 0.5128 - val_rmse: 0.1596 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51160\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99939\n",
      "Epoch 18/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3973 - rmse: 0.2509 - acc: 0.9990 - val_loss: 0.5158 - val_rmse: 0.1675 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51160\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99939\n",
      "Epoch 19/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3940 - rmse: 0.2468 - acc: 0.9991 - val_loss: 0.5113 - val_rmse: 0.1585 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51160 to 0.51135, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99939\n",
      "Epoch 20/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3907 - rmse: 0.2407 - acc: 0.9993 - val_loss: 0.5119 - val_rmse: 0.1598 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51135\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99939\n",
      "Epoch 21/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3894 - rmse: 0.2392 - acc: 0.9992 - val_loss: 0.5144 - val_rmse: 0.1645 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51135\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99939\n",
      "Epoch 22/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3865 - rmse: 0.2353 - acc: 0.9992 - val_loss: 0.5104 - val_rmse: 0.1588 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.51135 to 0.51045, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99939\n",
      "Epoch 23/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3850 - rmse: 0.2338 - acc: 0.9993 - val_loss: 0.5120 - val_rmse: 0.1634 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99939\n",
      "Epoch 24/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3824 - rmse: 0.2297 - acc: 0.9990 - val_loss: 0.5106 - val_rmse: 0.1595 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99939\n",
      "Epoch 25/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3807 - rmse: 0.2272 - acc: 0.9993 - val_loss: 0.5150 - val_rmse: 0.1681 - val_acc: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99939\n",
      "Epoch 26/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3796 - rmse: 0.2244 - acc: 0.9990 - val_loss: 0.5124 - val_rmse: 0.1585 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00026: acc did not improve from 0.99939\n",
      "Epoch 27/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3772 - rmse: 0.2224 - acc: 0.9993 - val_loss: 0.5057 - val_rmse: 0.1511 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.51045 to 0.50570, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00027: acc did not improve from 0.99939\n",
      "Epoch 28/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3760 - rmse: 0.2195 - acc: 0.9988 - val_loss: 0.5112 - val_rmse: 0.1555 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00028: acc did not improve from 0.99939\n",
      "Epoch 29/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3740 - rmse: 0.2164 - acc: 0.9991 - val_loss: 0.5074 - val_rmse: 0.1546 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00029: acc did not improve from 0.99939\n",
      "Epoch 30/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3723 - rmse: 0.2151 - acc: 0.9990 - val_loss: 0.5077 - val_rmse: 0.1546 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00030: acc did not improve from 0.99939\n",
      "Epoch 31/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3716 - rmse: 0.2137 - acc: 0.9989 - val_loss: 0.5061 - val_rmse: 0.1524 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00031: acc did not improve from 0.99939\n",
      "Epoch 32/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3690 - rmse: 0.2084 - acc: 0.9990 - val_loss: 0.5129 - val_rmse: 0.1613 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.99939\n",
      "Epoch 33/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3678 - rmse: 0.2083 - acc: 0.9991 - val_loss: 0.5067 - val_rmse: 0.1519 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00033: acc did not improve from 0.99939\n",
      "Epoch 34/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3674 - rmse: 0.2073 - acc: 0.9990 - val_loss: 0.5078 - val_rmse: 0.1529 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00034: acc did not improve from 0.99939\n",
      "Epoch 35/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3652 - rmse: 0.2042 - acc: 0.9990 - val_loss: 0.5094 - val_rmse: 0.1578 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.50570\n",
      "\n",
      "Epoch 00035: acc did not improve from 0.99939\n",
      "Epoch 36/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3645 - rmse: 0.2027 - acc: 0.9989 - val_loss: 0.5047 - val_rmse: 0.1491 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.50570 to 0.50470, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00036: acc did not improve from 0.99939\n",
      "Epoch 37/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3634 - rmse: 0.2021 - acc: 0.9989 - val_loss: 0.5050 - val_rmse: 0.1480 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50470\n",
      "\n",
      "Epoch 00037: acc did not improve from 0.99939\n",
      "Epoch 38/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3549 - rmse: 0.2007 - acc: 0.9990 - val_loss: 0.5038 - val_rmse: 0.1479 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.50470 to 0.50380, saving model to D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.99939\n",
      "Epoch 39/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3617 - rmse: 0.1989 - acc: 0.9988 - val_loss: 0.5067 - val_rmse: 0.1533 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.99939\n",
      "Epoch 40/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3607 - rmse: 0.1973 - acc: 0.9989 - val_loss: 0.5097 - val_rmse: 0.1567 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00040: acc did not improve from 0.99939\n",
      "Epoch 41/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3580 - rmse: 0.1932 - acc: 0.9988 - val_loss: 0.5040 - val_rmse: 0.1474 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.99939\n",
      "Epoch 42/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3557 - rmse: 0.1916 - acc: 0.9989 - val_loss: 0.5076 - val_rmse: 0.1506 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00042: acc did not improve from 0.99939\n",
      "Epoch 43/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3550 - rmse: 0.1915 - acc: 0.9987 - val_loss: 0.5099 - val_rmse: 0.1526 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.99939\n",
      "Epoch 44/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3535 - rmse: 0.1886 - acc: 0.9987 - val_loss: 0.5072 - val_rmse: 0.1511 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00044: acc did not improve from 0.99939\n",
      "Epoch 45/100\n",
      "16330/16330 [==============================] - 305s 19ms/step - loss: 0.3533 - rmse: 0.1879 - acc: 0.9990 - val_loss: 0.5116 - val_rmse: 0.1500 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00045: acc did not improve from 0.99939\n",
      "Epoch 46/100\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.3530 - rmse: 0.1860 - acc: 0.9986 - val_loss: 0.5066 - val_rmse: 0.1478 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00046: acc did not improve from 0.99939\n",
      "Epoch 47/100\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3522 - rmse: 0.1860 - acc: 0.9987 - val_loss: 0.5061 - val_rmse: 0.1483 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00047: acc did not improve from 0.99939\n",
      "Epoch 48/100\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.3429 - rmse: 0.1837 - acc: 0.9987 - val_loss: 0.5081 - val_rmse: 0.1479 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00048: acc did not improve from 0.99939\n",
      "Epoch 49/100\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.3488 - rmse: 0.1839 - acc: 0.9985 - val_loss: 0.5062 - val_rmse: 0.1499 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00049: acc did not improve from 0.99939\n",
      "Epoch 50/100\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3497 - rmse: 0.1812 - acc: 0.9985 - val_loss: 0.5050 - val_rmse: 0.1467 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.99939\n",
      "Epoch 51/100\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.3470 - rmse: 0.1809 - acc: 0.9985 - val_loss: 0.5091 - val_rmse: 0.1487 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00051: acc did not improve from 0.99939\n",
      "Epoch 52/100\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3456 - rmse: 0.1771 - acc: 0.9985 - val_loss: 0.5101 - val_rmse: 0.1483 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00052: acc did not improve from 0.99939\n",
      "Epoch 53/100\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3456 - rmse: 0.1775 - acc: 0.9984 - val_loss: 0.5104 - val_rmse: 0.1544 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00053: acc did not improve from 0.99939\n",
      "Epoch 54/100\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.3424 - rmse: 0.1745 - acc: 0.9985 - val_loss: 0.5109 - val_rmse: 0.1494 - val_acc: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00054: acc did not improve from 0.99939\n",
      "Epoch 55/100\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3260 - rmse: 0.1730 - acc: 0.9985 - val_loss: 0.5088 - val_rmse: 0.1493 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00055: acc did not improve from 0.99939\n",
      "Epoch 56/100\n",
      "16330/16330 [==============================] - 326s 20ms/step - loss: 0.3410 - rmse: 0.1745 - acc: 0.9985 - val_loss: 0.5085 - val_rmse: 0.1487 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00056: acc did not improve from 0.99939\n",
      "Epoch 57/100\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3393 - rmse: 0.1727 - acc: 0.9981 - val_loss: 0.5169 - val_rmse: 0.1551 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00057: acc did not improve from 0.99939\n",
      "Epoch 58/100\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3387 - rmse: 0.1719 - acc: 0.9984 - val_loss: 0.5094 - val_rmse: 0.1507 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00058: acc did not improve from 0.99939\n",
      "Epoch 59/100\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3360 - rmse: 0.1699 - acc: 0.9983 - val_loss: 0.5079 - val_rmse: 0.1471 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00059: acc did not improve from 0.99939\n",
      "Epoch 60/100\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.3353 - rmse: 0.1698 - acc: 0.9980 - val_loss: 0.5086 - val_rmse: 0.1471 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00060: acc did not improve from 0.99939\n",
      "Epoch 61/100\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.3281 - rmse: 0.1658 - acc: 0.9983 - val_loss: 0.5100 - val_rmse: 0.1503 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00061: acc did not improve from 0.99939\n",
      "Epoch 62/100\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.3308 - rmse: 0.1640 - acc: 0.9982 - val_loss: 0.5155 - val_rmse: 0.1501 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00062: acc did not improve from 0.99939\n",
      "Epoch 63/100\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3308 - rmse: 0.1640 - acc: 0.9982 - val_loss: 0.5167 - val_rmse: 0.1537 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00063: acc did not improve from 0.99939\n",
      "Epoch 64/100\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.3285 - rmse: 0.1643 - acc: 0.9979 - val_loss: 0.5122 - val_rmse: 0.1478 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00064: acc did not improve from 0.99939\n",
      "Epoch 65/100\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.3291 - rmse: 0.1616 - acc: 0.9985 - val_loss: 0.5107 - val_rmse: 0.1468 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00065: acc did not improve from 0.99939\n",
      "Epoch 66/100\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.3265 - rmse: 0.1608 - acc: 0.9983 - val_loss: 0.5138 - val_rmse: 0.1485 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00066: acc did not improve from 0.99939\n",
      "Epoch 67/100\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3228 - rmse: 0.1603 - acc: 0.9981 - val_loss: 0.5191 - val_rmse: 0.1477 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.50380\n",
      "\n",
      "Epoch 00067: acc did not improve from 0.99939\n",
      "Epoch 68/100\n",
      " 8960/16330 [===============>..............] - ETA: 2:03 - loss: 0.2745 - rmse: 0.1567 - acc: 0.9978"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-d2eaf6d4a24d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n\u001b[1;32m---> 18\u001b[1;33m                              validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Dropout/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.val_loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVOExpanded_Dropout/1/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Dropout/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Dropout/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_Dropout/model/weights.best.val_loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Dropout/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Dropout/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudar parâmetro beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_28 (Sequential)      (None, 50688)        1918848     input_55[0][0]                   \n",
      "                                                                 input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 50688)        0           sequential_28[1][0]              \n",
      "                                                                 sequential_28[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 64)           3244096     lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 64)           0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_28[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,163,074\n",
      "Trainable params: 5,163,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer1)\n",
    "dense_layer2 = Dense(32)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "alpha  = 1\n",
    "beta = 300\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    alpha\n",
    "    mean_rot = mean[:, 0] * beta\n",
    "    mean_trasl = mean[:, 1]* alpha   \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "def mean_loss(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_trasl = mean[:, 3:6]\n",
    "    mean_rot = mean[:, 0:3]\n",
    "    #mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt_trasl = K.sqrt(K.mean(mean_rot, axis=-1))\n",
    "    sqrt_rot = K.sqrt(K.mean(mean_trasl, axis=-1))\n",
    "    return (sqrt_rot/sqrt_trasl)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, mean_loss, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVOExpanded_beta_300/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/50\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.8926 - rmse: 0.4890 - mean_loss: nan - acc: 0.9988 - val_loss: 0.9369 - val_rmse: 0.3245 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93686, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99884, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.7857 - rmse: 0.4035 - mean_loss: nan - acc: 0.9994 - val_loss: 0.8961 - val_rmse: 0.2938 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93686 to 0.89610, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99884 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/50\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.6781 - rmse: 0.3026 - mean_loss: nan - acc: 0.9987 - val_loss: 0.8275 - val_rmse: 0.2178 - val_mean_loss: nan - val_acc: 0.9987\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.89610 to 0.82754, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99939\n",
      "Epoch 4/50\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.6125 - rmse: 0.2426 - mean_loss: nan - acc: 0.9980 - val_loss: 0.8018 - val_rmse: 0.1926 - val_mean_loss: nan - val_acc: 0.9985\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.82754 to 0.80182, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99939\n",
      "Epoch 5/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.5855 - rmse: 0.2136 - mean_loss: nan - acc: 0.9980 - val_loss: 0.7763 - val_rmse: 0.1753 - val_mean_loss: nan - val_acc: 0.9985\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.80182 to 0.77626, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99939\n",
      "Epoch 6/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.5629 - rmse: 0.1987 - mean_loss: nan - acc: 0.9985 - val_loss: 0.7849 - val_rmse: 0.1689 - val_mean_loss: nan - val_acc: 0.9987\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.77626\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99939\n",
      "Epoch 7/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.5477 - rmse: 0.1890 - mean_loss: nan - acc: 0.9984 - val_loss: 0.7648 - val_rmse: 0.1649 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.77626 to 0.76477, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99939\n",
      "Epoch 8/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.5351 - rmse: 0.1792 - mean_loss: nan - acc: 0.9989 - val_loss: 0.7756 - val_rmse: 0.1783 - val_mean_loss: nan - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.76477\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99939\n",
      "Epoch 9/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.5230 - rmse: 0.1699 - mean_loss: nan - acc: 0.9989 - val_loss: 0.7638 - val_rmse: 0.1638 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.76477 to 0.76378, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99939\n",
      "Epoch 10/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.5134 - rmse: 0.1619 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7605 - val_rmse: 0.1591 - val_mean_loss: nan - val_acc: 0.9988\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.76378 to 0.76054, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99939\n",
      "Epoch 11/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.4947 - rmse: 0.1552 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7552 - val_rmse: 0.1572 - val_mean_loss: nan - val_acc: 0.9988\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.76054 to 0.75521, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99939\n",
      "Epoch 12/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.5018 - rmse: 0.1527 - mean_loss: nan - acc: 0.9990 - val_loss: 0.7533 - val_rmse: 0.1567 - val_mean_loss: nan - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.75521 to 0.75326, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99939\n",
      "Epoch 13/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4934 - rmse: 0.1457 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7523 - val_rmse: 0.1549 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.75326 to 0.75230, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99939\n",
      "Epoch 14/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4887 - rmse: 0.1413 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7546 - val_rmse: 0.1575 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.75230\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99939\n",
      "Epoch 15/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4832 - rmse: 0.1370 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7525 - val_rmse: 0.1536 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.75230\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99939\n",
      "Epoch 16/50\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.4813 - rmse: 0.1348 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7537 - val_rmse: 0.1536 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.75230\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99939\n",
      "Epoch 17/50\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.4765 - rmse: 0.1316 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7552 - val_rmse: 0.1548 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.75230\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99939\n",
      "Epoch 18/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4735 - rmse: 0.1280 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7652 - val_rmse: 0.1703 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.75230\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99939\n",
      "Epoch 19/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.4690 - rmse: 0.1249 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7478 - val_rmse: 0.1504 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.75230 to 0.74784, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99939\n",
      "Epoch 20/50\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.4662 - rmse: 0.1220 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7484 - val_rmse: 0.1515 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.74784\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99939\n",
      "Epoch 21/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.4634 - rmse: 0.1199 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7460 - val_rmse: 0.1482 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.74784 to 0.74601, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99939\n",
      "Epoch 22/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.4610 - rmse: 0.1168 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7463 - val_rmse: 0.1469 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.74601\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99939\n",
      "Epoch 23/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4574 - rmse: 0.1141 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7477 - val_rmse: 0.1483 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.74601\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99939\n",
      "Epoch 24/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4557 - rmse: 0.1122 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7453 - val_rmse: 0.1473 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.74601 to 0.74531, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99939\n",
      "Epoch 25/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4527 - rmse: 0.1101 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7474 - val_rmse: 0.1476 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.74531\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99939\n",
      "Epoch 26/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4499 - rmse: 0.1080 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7481 - val_rmse: 0.1441 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.74531\n",
      "\n",
      "Epoch 00026: acc did not improve from 0.99939\n",
      "Epoch 27/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4361 - rmse: 0.1046 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7464 - val_rmse: 0.1441 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.74531\n",
      "\n",
      "Epoch 00027: acc did not improve from 0.99939\n",
      "Epoch 28/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4456 - rmse: 0.1043 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7431 - val_rmse: 0.1453 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.74531 to 0.74309, saving model to D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5\n",
      "\n",
      "Epoch 00028: acc did not improve from 0.99939\n",
      "Epoch 29/50\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.4425 - rmse: 0.1018 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7505 - val_rmse: 0.1512 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00029: acc did not improve from 0.99939\n",
      "Epoch 30/50\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.4388 - rmse: 0.0992 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7463 - val_rmse: 0.1459 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00030: acc did not improve from 0.99939\n",
      "Epoch 31/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.4376 - rmse: 0.0979 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7456 - val_rmse: 0.1437 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00031: acc did not improve from 0.99939\n",
      "Epoch 32/50\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 0.4352 - rmse: 0.0957 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7463 - val_rmse: 0.1433 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.99939\n",
      "Epoch 33/50\n",
      "16330/16330 [==============================] - 317s 19ms/step - loss: 0.4329 - rmse: 0.0951 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7527 - val_rmse: 0.1484 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00033: acc did not improve from 0.99939\n",
      "Epoch 34/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4304 - rmse: 0.0922 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7482 - val_rmse: 0.1426 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00034: acc did not improve from 0.99939\n",
      "Epoch 35/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4281 - rmse: 0.0918 - mean_loss: nan - acc: 0.9994 - val_loss: 0.7532 - val_rmse: 0.1476 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00035: acc did not improve from 0.99939\n",
      "Epoch 36/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4238 - rmse: 0.0894 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7562 - val_rmse: 0.1490 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00036: acc did not improve from 0.99939\n",
      "Epoch 37/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4215 - rmse: 0.0876 - mean_loss: nan - acc: 0.9994 - val_loss: 0.7525 - val_rmse: 0.1440 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00037: acc did not improve from 0.99939\n",
      "Epoch 38/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4155 - rmse: 0.0859 - mean_loss: nan - acc: 0.9990 - val_loss: 0.7553 - val_rmse: 0.1469 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.99939\n",
      "Epoch 39/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4172 - rmse: 0.0863 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7490 - val_rmse: 0.1430 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.99939\n",
      "Epoch 40/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4117 - rmse: 0.0834 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7518 - val_rmse: 0.1421 - val_mean_loss: nan - val_acc: 0.9990\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00040: acc did not improve from 0.99939\n",
      "Epoch 41/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4091 - rmse: 0.0820 - mean_loss: nan - acc: 0.9992 - val_loss: 0.7610 - val_rmse: 0.1460 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.99939\n",
      "Epoch 42/50\n",
      "16330/16330 [==============================] - 315s 19ms/step - loss: 0.4083 - rmse: 0.0824 - mean_loss: nan - acc: 0.9993 - val_loss: 0.7551 - val_rmse: 0.1434 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00042: acc did not improve from 0.99939\n",
      "Epoch 43/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.4034 - rmse: 0.0802 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7578 - val_rmse: 0.1447 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.99939\n",
      "Epoch 44/50\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3997 - rmse: 0.0790 - mean_loss: nan - acc: 0.9989 - val_loss: 0.7568 - val_rmse: 0.1426 - val_mean_loss: nan - val_acc: 0.9990\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00044: acc did not improve from 0.99939\n",
      "Epoch 45/50\n",
      "16330/16330 [==============================] - 316s 19ms/step - loss: 0.3963 - rmse: 0.0785 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7563 - val_rmse: 0.1415 - val_mean_loss: nan - val_acc: 0.9988\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00045: acc did not improve from 0.99939\n",
      "Epoch 46/50\n",
      "16330/16330 [==============================] - 318s 19ms/step - loss: 0.3933 - rmse: 0.0782 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7615 - val_rmse: 0.1422 - val_mean_loss: nan - val_acc: 0.9990\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00046: acc did not improve from 0.99939\n",
      "Epoch 47/50\n",
      "16330/16330 [==============================] - 314s 19ms/step - loss: 0.3873 - rmse: 0.0752 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7651 - val_rmse: 0.1464 - val_mean_loss: nan - val_acc: 0.9991\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00047: acc did not improve from 0.99939\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.3857 - rmse: 0.0765 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7800 - val_rmse: 0.1520 - val_mean_loss: nan - val_acc: 0.9990\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00048: acc did not improve from 0.99939\n",
      "Epoch 49/50\n",
      "16330/16330 [==============================] - 312s 19ms/step - loss: 0.3715 - rmse: 0.0747 - mean_loss: nan - acc: 0.9991 - val_loss: 0.7757 - val_rmse: 0.1470 - val_mean_loss: nan - val_acc: 0.9990\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00049: acc did not improve from 0.99939\n",
      "Epoch 50/50\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3748 - rmse: 0.0750 - mean_loss: nan - acc: 0.9989 - val_loss: 0.7844 - val_rmse: 0.1453 - val_mean_loss: nan - val_acc: 0.9988\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.74309\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.99939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26666395e10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_beta_300/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVOExpanded_beta_300/1/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_beta_300/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_beta_300/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_beta_300/model/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_beta_300/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_beta_300/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform training pose (of thesis) with Ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_training_thesis_0 = {}\n",
    "label_training_thesis_1 = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_training_thesis_0[name] = label_aux[:-1]\n",
    "    label_training_thesis_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540\n",
      "1100\n",
      "4660\n",
      "800\n",
      "270\n",
      "2760\n",
      "1100\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "from math import asin, atan2, sqrt\n",
    "\n",
    "T_train_thesis = {}\n",
    "\n",
    "for directory in training_seqs:    \n",
    "    curr_sequence = training_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_training_thesis_0[name], label_training_thesis_1[name]):\n",
    "        \n",
    "        Tx = pose_1[0][3]\n",
    "        Ty = pose_1[1][3]\n",
    "        Tz = pose_1[2][3]\n",
    "        \n",
    "        Tx_ant = pose_0[0][3]\n",
    "        Ty_ant = pose_0[1][3]\n",
    "        Tz_ant = pose_0[2][3]\n",
    "\n",
    "        Ri_1 = pose_1[0][0]\n",
    "        Ri_3 = pose_1[0][2]    \n",
    "        Ri_1_ant = pose_0[0][0]\n",
    "        Ri_3_ant = pose_0[0][2]\n",
    "        \n",
    "        Ti = [Tx, Ty, Tz]\n",
    "        Ti_ant = [Tx_ant, Ty_ant, Tz_ant]\n",
    "\n",
    "        displacement = sqrt(sum([(a - b) ** 2 for a, b in zip(Ti, Ti_ant)]))\n",
    "        delta_Theta = atan2(Ri_3, Ri_1) - atan2(Ri_3_ant, Ri_1_ant)\n",
    "    \n",
    "        T_aux.append([delta_Theta, displacement])\n",
    "    \n",
    "    T_train_thesis[name] = T_aux\n",
    "    print(len(T_train_thesis[name]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform test pose (of thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = 0\n",
    "label_test_thesis_0 = {}\n",
    "label_test_thesis_1 = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    labels = curr_sequence.get_labels()\n",
    "    name = curr_sequence.get_dir()\n",
    "    label_aux = []\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix = np.reshape(label, (3, 4))\n",
    "        homogeneous = np.array([[0, 0, 0, 1]])\n",
    "        matrix = np.vstack((matrix, homogeneous))   \n",
    "\n",
    "        label_aux.append(matrix)\n",
    "        \n",
    "        \n",
    "    label_test_thesis_0[name] = label_aux[:-1]\n",
    "    label_test_thesis_1[name] = label_aux[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_test_thesis = {}\n",
    "\n",
    "for directory in test_seqs:    \n",
    "    curr_sequence = test_seqs[directory]\n",
    "    name = curr_sequence.get_dir()\n",
    "    T_aux = []\n",
    "    \n",
    "    for pose_0, pose_1 in zip(label_test_thesis_0[name], label_test_thesis_1[name]):\n",
    "        \n",
    "        Tx = pose_1[0][3]\n",
    "        Ty = pose_1[1][3]\n",
    "        Tz = pose_1[2][3]\n",
    "        \n",
    "        Tx_ant = pose_0[0][3]\n",
    "        Ty_ant = pose_0[1][3]\n",
    "        Tz_ant = pose_0[2][3]\n",
    "\n",
    "        Ri_1 = pose_1[0][0]\n",
    "        Ri_3 = pose_1[0][2]    \n",
    "        Ri_1_ant = pose_0[0][0]\n",
    "        Ri_3_ant = pose_0[0][2]\n",
    "        \n",
    "        Ti = [Tx, Ty, Tz]\n",
    "        Ti_ant = [Tx_ant, Ty_ant, Tz_ant]\n",
    "\n",
    "        displacement = sqrt(sum([(a - b) ** 2 for a, b in zip(Ti, Ti_ant)]))\n",
    "        delta_Theta = atan2(Ri_3, Ri_1) - atan2(Ri_1_ant, Ri_3_ant)\n",
    "    \n",
    "        T_aux.append([delta_Theta, displacement])\n",
    "    \n",
    "    T_test_thesis[name] = T_aux\n",
    "    # print(T_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_poses_transformed_thesis = []\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "  \n",
    "    for pose in T_train_thesis[sequence]:\n",
    "        training_poses_transformed_thesis.append(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_poses_transformed_thesis = []\n",
    "\n",
    "for sequence in kitti_test_dirs:    \n",
    "        for pose in T_test_thesis[sequence]:\n",
    "            test_poses_transformed_thesis.append(pose)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a entrada para o padrão Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 47, 155, 1)\n",
      "(6860, 47, 155, 1)\n"
     ]
    }
   ],
   "source": [
    "training_r = np.reshape(training_r, (len(training_r), input_height, input_width, 1))\n",
    "training_l = np.reshape(training_l, (len(training_l), input_height, input_width, 1))\n",
    "\n",
    "print(np.shape(training_r))\n",
    "\n",
    "test_r = np.reshape(test_r, (len(test_r), input_height, input_width, 1))\n",
    "test_l = np.reshape(test_l, (len(test_l), input_height, input_width, 1))\n",
    "print(np.shape(test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16330, 2)\n"
     ]
    }
   ],
   "source": [
    "y_training = np.reshape(training_poses_transformed_thesis, (len(training_poses_transformed_thesis), 2))\n",
    "y_test = np.reshape(test_poses_transformed_thesis, (len(test_poses_transformed_thesis), 2))\n",
    "print(np.shape(y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Usando Leaky Relu\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 50688)        1918848     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50688)        0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           3244096     lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,163,074\n",
      "Trainable params: 5,163,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer)\n",
    "dense_layer2 = Dense(32)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "num_epochs = 50\n",
    "\n",
    "def vo_loss_mod(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * 150\n",
    "    mean_trasl = mean[:, 1]* 0.3    \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/50\n",
      "16330/16330 [==============================] - 319s 20ms/step - loss: 0.5986 - rmse: 0.5444 - acc: 0.9892 - val_loss: 13.8803 - val_rmse: 1.2114 - val_acc: 0.5602\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 13.88031, saving model to D:/KITTI/Graph/DepthVO_with_Ty/model/weights.best.val.loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.98916, saving model to D:/KITTI/Graph/DepthVO_with_Ty/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/50\n",
      "16330/16330 [==============================] - 313s 19ms/step - loss: 0.5358 - rmse: 0.4648 - acc: 0.9994 - val_loss: 13.8623 - val_rmse: 1.2013 - val_acc: 0.5602\n",
      "\n",
      "Epoch 00002: val_loss improved from 13.88031 to 13.86229, saving model to D:/KITTI/Graph/DepthVO_with_Ty/model/weights.best.val.loss.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.98916 to 0.99939, saving model to D:/KITTI/Graph/DepthVO_with_Ty/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/50\n",
      " 9392/16330 [================>.............] - ETA: 1:55 - loss: 0.4932 - rmse: 0.4325 - acc: 0.9995"
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_with_Ty/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_with_Ty/1/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_RELU_thesis_expanded_network/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-1-expanded/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-1-expanded/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserindo recorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a7fe56a36797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0minput_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mprocessed_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[0mprocessed_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_uid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[1;31m# (num_samples * timesteps, ...)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_learning_phase'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0muses_learning_phase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2084\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2085\u001b[1;33m             \u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[1;34m(self, inputs, masks)\u001b[0m\n\u001b[0;32m   2233\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[1;34m'mask'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2234\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2235\u001b[1;33m                             \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2236\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[0;32m   2237\u001b[0m                                                               computed_mask)\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3339\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3340\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3341\u001b[1;33m         data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         data_format=data_format)\n\u001b[0m\u001b[0;32m    780\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NC\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0minput_channels_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_spatial_dims\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mspatial_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Reshape \n",
    "from keras.layers import Conv2D, add, concatenate, LeakyReLU, LSTM, CuDNNGRU, Bidirectional, TimeDistributed\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "\n",
    "activation1 = LeakyReLU(alpha=0.2)(dense_layer)\n",
    "\n",
    "dense_layer1 = TimeDistributed(Dense(32))(activation1)\n",
    "recurrency = CuDNNGRU(512)(dense_layer1)\n",
    "\n",
    "activation2 = LeakyReLU(alpha=0.1)(recurrency)\n",
    "\n",
    "#modifiquei a entrada aqui estava errado\n",
    "\n",
    "\n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation2)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation2)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "def vo_loss_mod_thesis(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * 150\n",
    "    mean_trasl = mean[:, 1]* 0.3    \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss_mod_thesis], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/\n",
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/500\n",
      "16330/16330 [==============================] - 310s 19ms/step - loss: 0.5569 - rmse: 0.4921 - acc: 0.9953 - val_loss: 0.6132 - val_rmse: 0.3140 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61316, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99535, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/500\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.5003 - rmse: 0.4112 - acc: 0.9994 - val_loss: 0.5889 - val_rmse: 0.2837 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61316 to 0.58892, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99535 to 0.99939, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.4518 - rmse: 0.3262 - acc: 0.9992 - val_loss: 0.5652 - val_rmse: 0.2484 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58892 to 0.56522, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99939\n",
      "Epoch 4/500\n",
      "16330/16330 [==============================] - 311s 19ms/step - loss: 0.4137 - rmse: 0.2612 - acc: 0.9975 - val_loss: 0.5629 - val_rmse: 0.2187 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56522 to 0.56290, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99939\n",
      "Epoch 5/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3900 - rmse: 0.2262 - acc: 0.9960 - val_loss: 0.5350 - val_rmse: 0.1901 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56290 to 0.53497, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99939\n",
      "Epoch 6/500\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.3743 - rmse: 0.2054 - acc: 0.9960 - val_loss: 0.5361 - val_rmse: 0.1847 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53497\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99939\n",
      "Epoch 7/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3562 - rmse: 0.1925 - acc: 0.9960 - val_loss: 0.5235 - val_rmse: 0.1756 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.53497 to 0.52353, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99939\n",
      "Epoch 8/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3567 - rmse: 0.1837 - acc: 0.9969 - val_loss: 0.5288 - val_rmse: 0.1840 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.52353\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99939\n",
      "Epoch 9/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3482 - rmse: 0.1729 - acc: 0.9977 - val_loss: 0.5208 - val_rmse: 0.1692 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52353 to 0.52078, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99939\n",
      "Epoch 10/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3349 - rmse: 0.1652 - acc: 0.9976 - val_loss: 0.5199 - val_rmse: 0.1679 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52078 to 0.51990, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99939\n",
      "Epoch 11/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3393 - rmse: 0.1601 - acc: 0.9977 - val_loss: 0.5157 - val_rmse: 0.1619 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.51990 to 0.51573, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99939\n",
      "Epoch 12/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3352 - rmse: 0.1547 - acc: 0.9979 - val_loss: 0.5135 - val_rmse: 0.1590 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.51573 to 0.51350, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99939\n",
      "Epoch 13/500\n",
      "16330/16330 [==============================] - 307s 19ms/step - loss: 0.3235 - rmse: 0.1485 - acc: 0.9980 - val_loss: 0.5142 - val_rmse: 0.1598 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.51350\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99939\n",
      "Epoch 14/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3280 - rmse: 0.1451 - acc: 0.9983 - val_loss: 0.5208 - val_rmse: 0.1611 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.51350\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99939\n",
      "Epoch 15/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3268 - rmse: 0.1423 - acc: 0.9983 - val_loss: 0.5122 - val_rmse: 0.1559 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.51350 to 0.51218, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99939\n",
      "Epoch 16/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.3233 - rmse: 0.1384 - acc: 0.9984 - val_loss: 0.5133 - val_rmse: 0.1559 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99939\n",
      "Epoch 17/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3214 - rmse: 0.1352 - acc: 0.9983 - val_loss: 0.5150 - val_rmse: 0.1621 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99939\n",
      "Epoch 18/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3196 - rmse: 0.1329 - acc: 0.9986 - val_loss: 0.5163 - val_rmse: 0.1590 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99939\n",
      "Epoch 19/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3182 - rmse: 0.1306 - acc: 0.9985 - val_loss: 0.5122 - val_rmse: 0.1527 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99939\n",
      "Epoch 20/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3153 - rmse: 0.1264 - acc: 0.9984 - val_loss: 0.5183 - val_rmse: 0.1675 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99939\n",
      "Epoch 21/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3142 - rmse: 0.1244 - acc: 0.9987 - val_loss: 0.5132 - val_rmse: 0.1578 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51218\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99939\n",
      "Epoch 22/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3124 - rmse: 0.1210 - acc: 0.9987 - val_loss: 0.5102 - val_rmse: 0.1500 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.51218 to 0.51017, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99939\n",
      "Epoch 23/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3110 - rmse: 0.1193 - acc: 0.9988 - val_loss: 0.5114 - val_rmse: 0.1566 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51017\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99939\n",
      "Epoch 24/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3084 - rmse: 0.1166 - acc: 0.9987 - val_loss: 0.5136 - val_rmse: 0.1533 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51017\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99939\n",
      "Epoch 25/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3079 - rmse: 0.1142 - acc: 0.9988 - val_loss: 0.5093 - val_rmse: 0.1502 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51017 to 0.50933, saving model to D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2982 - rmse: 0.1113 - acc: 0.9988 - val_loss: 0.5107 - val_rmse: 0.1479 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00026: acc did not improve from 0.99939\n",
      "Epoch 27/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3044 - rmse: 0.1101 - acc: 0.9988 - val_loss: 0.5106 - val_rmse: 0.1482 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00027: acc did not improve from 0.99939\n",
      "Epoch 28/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.3025 - rmse: 0.1060 - acc: 0.9988 - val_loss: 0.5115 - val_rmse: 0.1528 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00028: acc did not improve from 0.99939\n",
      "Epoch 29/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2986 - rmse: 0.1050 - acc: 0.9987 - val_loss: 0.5107 - val_rmse: 0.1479 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00029: acc did not improve from 0.99939\n",
      "Epoch 30/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2992 - rmse: 0.1025 - acc: 0.9989 - val_loss: 0.5106 - val_rmse: 0.1478 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00030: acc did not improve from 0.99939\n",
      "Epoch 31/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2990 - rmse: 0.1012 - acc: 0.9989 - val_loss: 0.5159 - val_rmse: 0.1523 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00031: acc did not improve from 0.99939\n",
      "Epoch 32/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2898 - rmse: 0.0987 - acc: 0.9989 - val_loss: 0.5116 - val_rmse: 0.1466 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.99939\n",
      "Epoch 33/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2959 - rmse: 0.0975 - acc: 0.9989 - val_loss: 0.5098 - val_rmse: 0.1464 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00033: acc did not improve from 0.99939\n",
      "Epoch 34/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2948 - rmse: 0.0955 - acc: 0.9990 - val_loss: 0.5107 - val_rmse: 0.1473 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00034: acc did not improve from 0.99939\n",
      "Epoch 35/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2939 - rmse: 0.0946 - acc: 0.9988 - val_loss: 0.5226 - val_rmse: 0.1593 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00035: acc did not improve from 0.99939\n",
      "Epoch 36/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2916 - rmse: 0.0923 - acc: 0.9988 - val_loss: 0.5148 - val_rmse: 0.1487 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00036: acc did not improve from 0.99939\n",
      "Epoch 37/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2909 - rmse: 0.0915 - acc: 0.9990 - val_loss: 0.5157 - val_rmse: 0.1515 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00037: acc did not improve from 0.99939\n",
      "Epoch 38/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2815 - rmse: 0.0884 - acc: 0.9987 - val_loss: 0.5149 - val_rmse: 0.1476 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.99939\n",
      "Epoch 39/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2805 - rmse: 0.0880 - acc: 0.9990 - val_loss: 0.5118 - val_rmse: 0.1465 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.99939\n",
      "Epoch 40/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2855 - rmse: 0.0875 - acc: 0.9989 - val_loss: 0.5164 - val_rmse: 0.1470 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00040: acc did not improve from 0.99939\n",
      "Epoch 41/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2845 - rmse: 0.0858 - acc: 0.9988 - val_loss: 0.5141 - val_rmse: 0.1474 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.99939\n",
      "Epoch 42/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2815 - rmse: 0.0839 - acc: 0.9990 - val_loss: 0.5135 - val_rmse: 0.1454 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00042: acc did not improve from 0.99939\n",
      "Epoch 43/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2726 - rmse: 0.0830 - acc: 0.9991 - val_loss: 0.5145 - val_rmse: 0.1451 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.99939\n",
      "Epoch 44/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2778 - rmse: 0.0828 - acc: 0.9992 - val_loss: 0.5167 - val_rmse: 0.1473 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00044: acc did not improve from 0.99939\n",
      "Epoch 45/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2755 - rmse: 0.0807 - acc: 0.9991 - val_loss: 0.5234 - val_rmse: 0.1510 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00045: acc did not improve from 0.99939\n",
      "Epoch 46/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2737 - rmse: 0.0806 - acc: 0.9991 - val_loss: 0.5292 - val_rmse: 0.1530 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00046: acc did not improve from 0.99939\n",
      "Epoch 47/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2722 - rmse: 0.0804 - acc: 0.9990 - val_loss: 0.5275 - val_rmse: 0.1541 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00047: acc did not improve from 0.99939\n",
      "Epoch 48/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2685 - rmse: 0.0794 - acc: 0.9990 - val_loss: 0.5346 - val_rmse: 0.1738 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00048: acc did not improve from 0.99939\n",
      "Epoch 49/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2673 - rmse: 0.0785 - acc: 0.9993 - val_loss: 0.5246 - val_rmse: 0.1465 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00049: acc did not improve from 0.99939\n",
      "Epoch 50/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2633 - rmse: 0.0774 - acc: 0.9990 - val_loss: 0.5242 - val_rmse: 0.1455 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.99939\n",
      "Epoch 51/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2601 - rmse: 0.0765 - acc: 0.9993 - val_loss: 0.5357 - val_rmse: 0.1543 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00051: acc did not improve from 0.99939\n",
      "Epoch 52/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2620 - rmse: 0.0804 - acc: 0.9989 - val_loss: 0.5383 - val_rmse: 0.1519 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00052: acc did not improve from 0.99939\n",
      "Epoch 53/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2537 - rmse: 0.0762 - acc: 0.9991 - val_loss: 0.5310 - val_rmse: 0.1475 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00053: acc did not improve from 0.99939\n",
      "Epoch 54/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2473 - rmse: 0.0759 - acc: 0.9987 - val_loss: 0.5506 - val_rmse: 0.1565 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00054: acc did not improve from 0.99939\n",
      "Epoch 55/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2484 - rmse: 0.0757 - acc: 0.9989 - val_loss: 0.5502 - val_rmse: 0.1540 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00055: acc did not improve from 0.99939\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2433 - rmse: 0.0758 - acc: 0.9988 - val_loss: 0.5449 - val_rmse: 0.1552 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00056: acc did not improve from 0.99939\n",
      "Epoch 57/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2315 - rmse: 0.0770 - acc: 0.9988 - val_loss: 0.5497 - val_rmse: 0.1526 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00057: acc did not improve from 0.99939\n",
      "Epoch 58/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2335 - rmse: 0.0773 - acc: 0.9991 - val_loss: 0.5875 - val_rmse: 0.1814 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00058: acc did not improve from 0.99939\n",
      "Epoch 59/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2352 - rmse: 0.0846 - acc: 0.9985 - val_loss: 0.5538 - val_rmse: 0.1520 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00059: acc did not improve from 0.99939\n",
      "Epoch 60/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2234 - rmse: 0.0832 - acc: 0.9986 - val_loss: 0.5566 - val_rmse: 0.1522 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00060: acc did not improve from 0.99939\n",
      "Epoch 61/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2231 - rmse: 0.0901 - acc: 0.9989 - val_loss: 0.6018 - val_rmse: 0.1743 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00061: acc did not improve from 0.99939\n",
      "Epoch 62/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2085 - rmse: 0.0794 - acc: 0.9985 - val_loss: 0.5838 - val_rmse: 0.1636 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00062: acc did not improve from 0.99939\n",
      "Epoch 63/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2094 - rmse: 0.0871 - acc: 0.9985 - val_loss: 0.6253 - val_rmse: 0.2013 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00063: acc did not improve from 0.99939\n",
      "Epoch 64/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.2046 - rmse: 0.0874 - acc: 0.9986 - val_loss: 0.5795 - val_rmse: 0.1563 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00064: acc did not improve from 0.99939\n",
      "Epoch 65/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1944 - rmse: 0.0804 - acc: 0.9985 - val_loss: 0.5985 - val_rmse: 0.1594 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00065: acc did not improve from 0.99939\n",
      "Epoch 66/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1962 - rmse: 0.0870 - acc: 0.9984 - val_loss: 0.5934 - val_rmse: 0.1551 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00066: acc did not improve from 0.99939\n",
      "Epoch 67/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1879 - rmse: 0.0861 - acc: 0.9987 - val_loss: 0.5832 - val_rmse: 0.1600 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00067: acc did not improve from 0.99939\n",
      "Epoch 68/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1761 - rmse: 0.0788 - acc: 0.9988 - val_loss: 0.6185 - val_rmse: 0.1696 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00068: acc did not improve from 0.99939\n",
      "Epoch 69/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1904 - rmse: 0.0888 - acc: 0.9984 - val_loss: 0.5850 - val_rmse: 0.1642 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00069: acc did not improve from 0.99939\n",
      "Epoch 70/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1737 - rmse: 0.0783 - acc: 0.9988 - val_loss: 0.6164 - val_rmse: 0.2369 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00070: acc did not improve from 0.99939\n",
      "Epoch 71/500\n",
      "16330/16330 [==============================] - 306s 19ms/step - loss: 0.1836 - rmse: 0.0849 - acc: 0.9994 - val_loss: 0.6004 - val_rmse: 0.1602 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00071: acc did not improve from 0.99939\n",
      "Epoch 72/500\n",
      "16330/16330 [==============================] - 309s 19ms/step - loss: 0.1638 - rmse: 0.0757 - acc: 0.9988 - val_loss: 0.5990 - val_rmse: 0.1618 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00072: acc did not improve from 0.99939\n",
      "Epoch 73/500\n",
      "16330/16330 [==============================] - 308s 19ms/step - loss: 0.1706 - rmse: 0.0847 - acc: 0.9988 - val_loss: 0.5984 - val_rmse: 0.1661 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.50933\n",
      "\n",
      "Epoch 00073: acc did not improve from 0.99939\n",
      "Epoch 74/500\n",
      " 8912/16330 [===============>..............] - ETA: 2:03 - loss: 0.1833 - rmse: 0.0874 - acc: 0.9988"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-8f6fa639b1ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n\u001b[1;32m---> 18\u001b[1;33m                              validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/1/', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=num_epochs, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos, pi\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVOExpanded_Mod_Loss_500/model/weights.best.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()\n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVOExpanded_Mod_Loss_500/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mesmos resultados que com a LeakyRelu\n",
    "\n",
    "## Diminuindo a quantidade de Fully connect layers:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1028)         9041412     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1028)         0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1028)         0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           65856       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,107,398\n",
      "Trainable params: 9,107,398\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    \n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(1028, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "#dense_layer = Dense(1028)(abs_diff)\n",
    "#activation1 = Activation('relu')(dense_layer)\n",
    "#dense_layer1 = Dense(1028)(activation1)\n",
    "#activation2 = Activation('relu')(dense_layer1)\n",
    "\n",
    "activation2 = LeakyReLU(alpha=0.2)(abs_diff)\n",
    "dense_layer2 = Dense(1024)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.1776 - rmse: 0.3841 - acc: 0.9955 - val_loss: 0.0870 - val_rmse: 0.2368 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08696, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99553, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0692 - rmse: 0.2293 - acc: 0.9985 - val_loss: 0.0813 - val_rmse: 0.2209 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08696 to 0.08128, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.99553 to 0.99847, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0484 - rmse: 0.1823 - acc: 0.9983 - val_loss: 0.0761 - val_rmse: 0.2103 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08128 to 0.07611, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99847\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0416 - rmse: 0.1663 - acc: 0.9984 - val_loss: 0.0751 - val_rmse: 0.2075 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07611 to 0.07512, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99847\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0357 - rmse: 0.1538 - acc: 0.9985 - val_loss: 0.0792 - val_rmse: 0.2138 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07512\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99847\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0328 - rmse: 0.1492 - acc: 0.9988 - val_loss: 0.0728 - val_rmse: 0.2023 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07512 to 0.07285, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.99847 to 0.99884, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0253 - rmse: 0.1366 - acc: 0.9983 - val_loss: 0.0705 - val_rmse: 0.1948 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07285 to 0.07051, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99884\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0220 - rmse: 0.1298 - acc: 0.9987 - val_loss: 0.0746 - val_rmse: 0.2070 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07051\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99884\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0177 - rmse: 0.1187 - acc: 0.9991 - val_loss: 0.0692 - val_rmse: 0.1913 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07051 to 0.06924, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00009: acc improved from 0.99884 to 0.99908, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0132 - rmse: 0.1031 - acc: 0.9985 - val_loss: 0.0694 - val_rmse: 0.1913 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06924\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99908\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0123 - rmse: 0.0999 - acc: 0.9988 - val_loss: 0.0712 - val_rmse: 0.1956 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06924\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99908\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.0121 - rmse: 0.0965 - acc: 0.9988 - val_loss: 0.0723 - val_rmse: 0.1987 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06924\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99908\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 0.0113 - rmse: 0.0936 - acc: 0.9984 - val_loss: 0.0674 - val_rmse: 0.1848 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06924 to 0.06742, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99908\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0102 - rmse: 0.0895 - acc: 0.9984 - val_loss: 0.0686 - val_rmse: 0.1895 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06742\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99908\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0100 - rmse: 0.0878 - acc: 0.9985 - val_loss: 0.0684 - val_rmse: 0.1852 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06742\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99908\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0096 - rmse: 0.0861 - acc: 0.9988 - val_loss: 0.0659 - val_rmse: 0.1810 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06742 to 0.06589, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99908\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0095 - rmse: 0.0819 - acc: 0.9981 - val_loss: 0.0665 - val_rmse: 0.1815 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99908\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 35s 2ms/step - loss: 0.0086 - rmse: 0.0777 - acc: 0.9984 - val_loss: 0.0667 - val_rmse: 0.1814 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99908\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0101 - rmse: 0.0799 - acc: 0.9991 - val_loss: 0.0707 - val_rmse: 0.1902 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00019: acc improved from 0.99908 to 0.99914, saving model to D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0098 - rmse: 0.0799 - acc: 0.9982 - val_loss: 0.0674 - val_rmse: 0.1835 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99914\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0068 - rmse: 0.0723 - acc: 0.9983 - val_loss: 0.0662 - val_rmse: 0.1803 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99914\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 0.0065 - rmse: 0.0681 - acc: 0.9983 - val_loss: 0.0680 - val_rmse: 0.1846 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99914\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0083 - rmse: 0.0762 - acc: 0.9983 - val_loss: 0.0664 - val_rmse: 0.1812 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99914\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 34s 2ms/step - loss: 0.0068 - rmse: 0.0656 - acc: 0.9980 - val_loss: 0.0680 - val_rmse: 0.1836 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99914\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 33s 2ms/step - loss: 0.0072 - rmse: 0.0678 - acc: 0.9982 - val_loss: 0.0673 - val_rmse: 0.1819 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06589\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253f2771dd8>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_Fully_Connected_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-2/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-2/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Usando concatenate no lugar de get_abs_diff\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 1028)         9041412     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2056)         0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1028)         2114596     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1028)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1028)         1057812     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 1028)         0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           65856       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12,279,806\n",
      "Trainable params: 12,279,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(1028, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "dense_layer = Dense(1024)(concatenetion_layer)\n",
    "activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "dense_layer1 = Dense(1024)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer1)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.2516 - rmse: 0.2567 - acc: 0.9885 - val_loss: 0.0831 - val_rmse: 0.2074 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08315, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.98855, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0459 - rmse: 0.1678 - acc: 0.9968 - val_loss: 0.0725 - val_rmse: 0.1872 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08315 to 0.07247, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.98855 to 0.99675, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0385 - rmse: 0.1453 - acc: 0.9966 - val_loss: 0.0701 - val_rmse: 0.1846 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07247 to 0.07008, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.99675\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0344 - rmse: 0.1304 - acc: 0.9953 - val_loss: 0.0706 - val_rmse: 0.1848 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07008\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.99675\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0318 - rmse: 0.1209 - acc: 0.9956 - val_loss: 0.0685 - val_rmse: 0.1804 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07008 to 0.06855, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99675\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0297 - rmse: 0.1181 - acc: 0.9949 - val_loss: 0.0704 - val_rmse: 0.1860 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99675\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0264 - rmse: 0.1101 - acc: 0.9946 - val_loss: 0.0709 - val_rmse: 0.1871 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99675\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0245 - rmse: 0.1092 - acc: 0.9949 - val_loss: 0.0710 - val_rmse: 0.1893 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99675\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0269 - rmse: 0.1083 - acc: 0.9964 - val_loss: 0.0702 - val_rmse: 0.1885 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99675\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0199 - rmse: 0.0903 - acc: 0.9951 - val_loss: 0.0769 - val_rmse: 0.2052 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99675\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0265 - rmse: 0.1121 - acc: 0.9966 - val_loss: 0.0695 - val_rmse: 0.1847 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99675\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0264 - rmse: 0.1103 - acc: 0.9960 - val_loss: 0.0714 - val_rmse: 0.1904 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99675\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0225 - rmse: 0.0955 - acc: 0.9977 - val_loss: 0.0700 - val_rmse: 0.1847 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00013: acc improved from 0.99675 to 0.99773, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0156 - rmse: 0.0790 - acc: 0.9965 - val_loss: 0.0699 - val_rmse: 0.1835 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99773\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0171 - rmse: 0.0908 - acc: 0.9966 - val_loss: 0.0705 - val_rmse: 0.1859 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99773\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0187 - rmse: 0.0913 - acc: 0.9972 - val_loss: 0.0720 - val_rmse: 0.1960 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99773\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0208 - rmse: 0.0905 - acc: 0.9968 - val_loss: 0.0703 - val_rmse: 0.1851 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06855\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99773\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 40s 2ms/step - loss: 0.0143 - rmse: 0.0828 - acc: 0.9957 - val_loss: 0.0685 - val_rmse: 0.1810 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06855 to 0.06846, saving model to D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99773\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0200 - rmse: 0.0853 - acc: 0.9969 - val_loss: 0.0715 - val_rmse: 0.1891 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99773\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0182 - rmse: 0.0828 - acc: 0.9965 - val_loss: 0.0717 - val_rmse: 0.1917 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99773\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0161 - rmse: 0.0862 - acc: 0.9958 - val_loss: 0.0714 - val_rmse: 0.1869 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99773\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0150 - rmse: 0.0721 - acc: 0.9960 - val_loss: 0.0713 - val_rmse: 0.1865 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99773\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0211 - rmse: 0.0849 - acc: 0.9971 - val_loss: 0.0689 - val_rmse: 0.1791 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99773\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 38s 2ms/step - loss: 0.0145 - rmse: 0.0782 - acc: 0.9968 - val_loss: 0.0705 - val_rmse: 0.1835 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99773\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 39s 2ms/step - loss: 0.0105 - rmse: 0.0711 - acc: 0.9976 - val_loss: 0.0719 - val_rmse: 0.1855 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06846\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253f2af8518>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_concatenate_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_concatenate_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_concatenate_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-3/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-3/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mesmos resultados que com a LeakyRelu\n",
    "\n",
    "## Diminuindo a quantidade de Fully connect layers:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 1028)         9041412     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2056)         0           sequential_4[1][0]               \n",
      "                                                                 sequential_4[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 2056)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           131648      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 64)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            130         leaky_re_lu_10[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 9,173,190\n",
      "Trainable params: 9,173,190\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = False\n",
    "flag_3_outputs = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(512, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(1028, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "#dense_layer = Dense(1028)(abs_diff)\n",
    "#activation1 = Activation('relu')(dense_layer)\n",
    "#dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(concatenetion_layer)\n",
    "dense_layer2 = Dense(1024)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      "16330/16330 [==============================] - 32s 2ms/step - loss: 0.1909 - rmse: 0.2796 - acc: 0.9873 - val_loss: 0.0820 - val_rmse: 0.2205 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08203, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.98732, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 2/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 0.0532 - rmse: 0.1898 - acc: 0.9976 - val_loss: 0.0817 - val_rmse: 0.2075 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08203 to 0.08175, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.98732 to 0.99755, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 3/25\n",
      "16330/16330 [==============================] - 30s 2ms/step - loss: 0.0435 - rmse: 0.1628 - acc: 0.9977 - val_loss: 0.0818 - val_rmse: 0.2192 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08175\n",
      "\n",
      "Epoch 00003: acc improved from 0.99755 to 0.99773, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 4/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0380 - rmse: 0.1462 - acc: 0.9980 - val_loss: 0.0772 - val_rmse: 0.1965 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08175 to 0.07724, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00004: acc improved from 0.99773 to 0.99804, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5\n",
      "Epoch 5/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0339 - rmse: 0.1341 - acc: 0.9967 - val_loss: 0.0688 - val_rmse: 0.1797 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07724 to 0.06878, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.99804\n",
      "Epoch 6/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0309 - rmse: 0.1241 - acc: 0.9958 - val_loss: 0.0712 - val_rmse: 0.1887 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.99804\n",
      "Epoch 7/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0274 - rmse: 0.1165 - acc: 0.9950 - val_loss: 0.0695 - val_rmse: 0.1840 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.99804\n",
      "Epoch 8/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0246 - rmse: 0.1077 - acc: 0.9949 - val_loss: 0.0688 - val_rmse: 0.1817 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.99804\n",
      "Epoch 9/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0209 - rmse: 0.1000 - acc: 0.9944 - val_loss: 0.0705 - val_rmse: 0.1874 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.99804\n",
      "Epoch 10/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0189 - rmse: 0.0982 - acc: 0.9945 - val_loss: 0.0712 - val_rmse: 0.1880 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.99804\n",
      "Epoch 11/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0171 - rmse: 0.0936 - acc: 0.9950 - val_loss: 0.0722 - val_rmse: 0.1934 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.99804\n",
      "Epoch 12/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0150 - rmse: 0.0925 - acc: 0.9947 - val_loss: 0.0708 - val_rmse: 0.1906 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.99804\n",
      "Epoch 13/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0097 - rmse: 0.0796 - acc: 0.9950 - val_loss: 0.0699 - val_rmse: 0.1867 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.99804\n",
      "Epoch 14/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0110 - rmse: 0.0800 - acc: 0.9952 - val_loss: 0.0705 - val_rmse: 0.1894 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06878\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99804\n",
      "Epoch 15/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0118 - rmse: 0.0787 - acc: 0.9956 - val_loss: 0.0684 - val_rmse: 0.1814 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06878 to 0.06843, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99804\n",
      "Epoch 16/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0108 - rmse: 0.0733 - acc: 0.9960 - val_loss: 0.0679 - val_rmse: 0.1807 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06843 to 0.06792, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.99804\n",
      "Epoch 17/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0109 - rmse: 0.0711 - acc: 0.9948 - val_loss: 0.0674 - val_rmse: 0.1780 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06792 to 0.06740, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.99804\n",
      "Epoch 18/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0047 - rmse: 0.0510 - acc: 0.9959 - val_loss: 0.0667 - val_rmse: 0.1755 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06740 to 0.06675, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.99804\n",
      "Epoch 19/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0068 - rmse: 0.0617 - acc: 0.9955 - val_loss: 0.0686 - val_rmse: 0.1799 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.99804\n",
      "Epoch 20/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0056 - rmse: 0.0538 - acc: 0.9959 - val_loss: 0.0674 - val_rmse: 0.1774 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99804\n",
      "Epoch 21/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0069 - rmse: 0.0611 - acc: 0.9955 - val_loss: 0.0671 - val_rmse: 0.1761 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.99804\n",
      "Epoch 22/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0052 - rmse: 0.0528 - acc: 0.9957 - val_loss: 0.0675 - val_rmse: 0.1775 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.99804\n",
      "Epoch 23/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0060 - rmse: 0.0543 - acc: 0.9958 - val_loss: 0.0679 - val_rmse: 0.1775 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06675\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.99804\n",
      "Epoch 24/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0035 - rmse: 0.0459 - acc: 0.9950 - val_loss: 0.0667 - val_rmse: 0.1746 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06675 to 0.06670, saving model to D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.hdf5\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.99804\n",
      "Epoch 25/25\n",
      "16330/16330 [==============================] - 29s 2ms/step - loss: 0.0050 - rmse: 0.0506 - acc: 0.9958 - val_loss: 0.0692 - val_rmse: 0.1823 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06670\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.99804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1224fa630>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 00:\n",
      "Sequence 01:\n",
      "Sequence 02:\n",
      "Sequence 03:\n",
      "Sequence 04:\n",
      "Sequence 05:\n",
      "Sequence 06:\n",
      "Sequence 07:\n",
      "Sequence 08:\n",
      "Sequence 09:\n",
      "Sequence 10:\n"
     ]
    }
   ],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-4/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/thesis-4/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando as 6-DOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mesmos resultados que com a LeakyRelu\n",
    "\n",
    "## Diminuindo a quantidade de Fully connect layers:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 50688)        1918848     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 50688)        0           sequential_5[1][0]               \n",
      "                                                                 sequential_5[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           3244096     lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            390         leaky_re_lu_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,163,334\n",
      "Trainable params: 5,163,334\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    #seq.add(Dense(1028))\n",
    "    #seq.add(Activation('relu'))\n",
    "    # seq.add(Dropout(0.5))\n",
    "    # seq.add(Dense(32))\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape=abs_diff_output_shape)([processed_a, processed_b])\n",
    "dense_layer = Dense(64)(abs_diff)\n",
    "#activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "#dense_layer1 = Dense(64)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer)\n",
    "dense_layer2 = Dense(32)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 50\n",
    "\n",
    "def vo_loss_mod(y_true, y_pred):\n",
    "    mean = K.square(y_pred - y_true)\n",
    "    mean_rot = mean[:, 0] * 150\n",
    "    mean_trasl = mean[:, 1]* 0.3    \n",
    "    mean = K.concatenate([mean_rot, mean_trasl])\n",
    "    sqrt = K.sqrt(K.mean(mean, axis=-1))\n",
    "    return sqrt\n",
    "\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss=[vo_loss], optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16330 samples, validate on 6860 samples\n",
      "Epoch 1/25\n",
      " 1088/16330 [>.............................] - ETA: 4:14 - loss: 1.7629 - rmse: 3.2127 - acc: 0.1057"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-101e20f19243>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n\u001b[1;32m---> 18\u001b[1;33m                              validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_6DOF/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_6DOF', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_6DOF/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_6DOF/model/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF/val_loss%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura\n",
    "***\n",
    "\n",
    "### Usando concatenate no lugar de get_abs_diff\n",
    "\n",
    "* Dados originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 47, 155, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 50688)        1918848     input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 101376)       0           sequential_6[1][0]               \n",
      "                                                                 sequential_6[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         103810048   concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1024)         1049600     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 1024)         0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           65600       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 6)            390         leaky_re_lu_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 106,844,486\n",
      "Trainable params: 106,844,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "dense_layer = Dense(1024)(concatenetion_layer)\n",
    "activation1 = LeakyReLU(alpha=0.5)(dense_layer)\n",
    "dense_layer1 = Dense(1024)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(dense_layer1)\n",
    "dense_layer2 = Dense(64)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_6DOF_concatenate_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_6DOF_concatenate_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_6DOF_concatenate_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_thesis/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_thesis/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_6DOF_concatenate_thesis/model/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_thesis/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_thesis/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mesmos resultados que com a LeakyRelu\n",
    "\n",
    "## Diminuindo a quantidade de Fully connect layers:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints e treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from objectives.VoObjectives import vo_loss, rmse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, MaxPooling2D, merge, Conv2D, add, concatenate, LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import backend as K\n",
    "from keras import optimizers as optm\n",
    "from keras import losses\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "flag_6_outputs = True\n",
    "flag_3_outputs = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_cnn_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "\n",
    "        seq = Sequential()\n",
    "    seq.add(Conv2D(64, (3, 3), input_shape=input_dim))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Conv2D(64, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(128, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    #seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    seq.add(Conv2D(256, (3, 3)))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "\n",
    "    return seq\n",
    "\n",
    "input_shape = (input_height, input_width, 1)\n",
    "base_network = create_cnn_network(input_shape)\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "concatenetion_layer = concatenate([processed_a, processed_b])\n",
    "#dense_layer = Dense(1028)(abs_diff)\n",
    "#activation1 = Activation('relu')(dense_layer)\n",
    "#dense_layer1 = Dense(1028)(activation1)\n",
    "activation2 = LeakyReLU(alpha=0.2)(concatenetion_layer)\n",
    "dense_layer2 = Dense(1024)(activation2)\n",
    "activation3 = LeakyReLU(alpha=0.1)(dense_layer2)\n",
    "    \n",
    "if(flag_6_outputs):\n",
    "    output = Dense(6, name='predictions')(activation3)\n",
    "    \n",
    "elif(flag_3_outputs):\n",
    "    output = Dense(2, name='predictions')(activation3)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "opt = optm.Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse, 'acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"D:/KITTI/Graph/DepthVO_6DOF_concatenate_Fully_Connected_thesis/model/\"\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "        print (model_path)\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "filepath=model_path+\"weights.best.by.val.loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='D:/KITTI/Graph/DepthVO_6DOF_concatenate_Fully_Connected_thesis', histogram_freq=0, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "filepath2=model_path+\"weights.best.by.accuracy.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, checkpoint2, tbCallBack]\n",
    "\n",
    "model.fit([training_r, training_l], y_training, batch_size=16, epochs=25, \n",
    "                             validation_data=([test_r, test_l], y_test), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_6DOF_concatenate_Fully_Connected_thesis/model/weights.best.by.accuracy.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_Fully_Connected_thesis/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_Fully_Connected_thesis/acc/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import degrees, sin, cos\n",
    "\n",
    "for sequence in kitti_train_dirs:\n",
    "    \n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    cont = 1\n",
    "    data_training_r = np.array(dataset_training_all_r[sequence])\n",
    "    data_training_l = np.array(dataset_training_all_l[sequence]) \n",
    "    \n",
    "   \n",
    "    model.load_weights(filepath='D:/KITTI/Graph/DepthVO_6DOF_concatenate_Fully_Connected_thesis/model/weights.best.by.val.loss.hdf5')    \n",
    "    prediction = model.predict([data_training_r.reshape((len(data_training_r), input_height, input_width, 1)), \n",
    "                               data_training_l.reshape((len(data_training_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_training_r)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_Fully_Connected_thesis/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')\n",
    "    \n",
    "for sequence in kitti_test_dirs:\n",
    "    cont = 1\n",
    "    print(\"Sequence %s:\"%(sequence))\n",
    "    data_test_r = np.array(dataset_test_all_r[sequence])\n",
    "    data_test_l = np.array(dataset_test_all_l[sequence])\n",
    "    \n",
    "    prediction = model.predict([data_test_r.reshape((len(data_test_r), input_height, input_width, 1)), \n",
    "                               data_test_l.reshape((len(data_test_l), input_height, input_width, 1))])\n",
    "    \n",
    "    sequence_GT = np.zeros((len(data_test_l)+1, 12))\n",
    "    \n",
    "    init_mat = np.identity(4)\n",
    "    sequence_GT[0, :] = init_mat[0:3,:].flatten()    \n",
    "    \n",
    "    position_X = 0\n",
    "    position_Z = 0\n",
    "    angle_total = pi/2\n",
    "    \n",
    "    for element in prediction:\n",
    "        angle = element[0]\n",
    "        displacement = element[1]\n",
    "        \n",
    "        angle_total = angle_total - angle\n",
    "        \n",
    "        position_X = position_X + displacement*cos(angle_total)\n",
    "        position_Z = position_Z + displacement*sin(angle_total)\n",
    "        \n",
    "        sequence_GT[cont, :] = init_mat[0:3,:].flatten()\n",
    "        \n",
    "        sequence_GT[cont, 0] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 2] = -sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 3] = position_X\n",
    "        sequence_GT[cont, 8] = sin(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 10] = cos(angle_total-(pi/2))\n",
    "        sequence_GT[cont, 11] = position_Z\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "    np.savetxt(\"D:/KITTI/output_to_draw/DepthVO_6DOF_concatenate_Fully_Connected_thesis/val_loss/%s.txt\"%(sequence), np.array(sequence_GT), delimiter=\" \", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
